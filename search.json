[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Python/R for Data Science",
    "section": "",
    "text": "Preface\nThis is the lecture notes for STAT 2304 Programming languages for Data Science Fall 2023 at ATU. If you have any comments/suggetions/concerns about the notes please contact me at xxiao@atu.edu.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "Python/R for Data Science",
    "section": "References",
    "text": "References\n\n\n[1] Klosterman, S.\n(2021). Data\nscience projects with python: A case study approach to gaining valuable\ninsights from real data with machine learning. Packt\nPublishing, Limited.\n\n\n[2] McKinney, W.\n(2017). Python for data analysis: Data wrangling with pandas, NumPy,\nand IPython. O’Reilly Media.\n\n\n[3] Shaw, Z. A.\n(2017). Learn\npython 3 the hard way. Addison Wesley.\n\n\n[4] Sweigart, A.\n(2020). Automate the\nboring stuff with python, 2nd edition practical programming for total\nbeginners: Practical programming for total beginners. No Starch\nPress.\n\n\n[5] Prabhakaran, S.\n(2018). 101\nNumPy exercises for data analysis (python).\n\n\n[6] Grolemund, G.\n(2014). Hands-on programming with r: Write your own functions and\nsimulations. O’Reilly Media.\n\n\n[7] Prabhakaran, S.\n(2018). 101\npandas exercises for data analysis.\n\n\n[8] Beuzen, T. and\nTimbers, T. (2022). Python\npackages. Taylor & Francis Group.\n\n\n[9] Wickham, H. and\nGrolemund, G. (2017). R for data science: Import, tidy,\ntransform, visualize, and model data. O’Reilly Media.\n\n\n[10] Youens-Clark, K.\n(2020). Tiny python\nprojects. Manning Publications.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "contents/1/intro.html#why-python",
    "href": "contents/1/intro.html#why-python",
    "title": "1  Preliminaries",
    "section": "1.1 Why Python?",
    "text": "1.1 Why Python?\n\n1.1.1 Python is easy to learn and use\n\n\n\n1.1.2 Python is easy to read\n\n\n1.1.3 Python Community is mature and supportive",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preliminaries</span>"
    ]
  },
  {
    "objectID": "contents/1/intro.html#hello-world",
    "href": "contents/1/intro.html#hello-world",
    "title": "1  Preliminaries",
    "section": "1.2 Hello world!",
    "text": "1.2 Hello world!\n\n\n1.2.1 Setup the Python environment\nIn this section we are going to setup the Python developing environment.\n\n1.2.1.1 VS Code + Anaconda\nClick Appendix A.1 to see the detailed steps for VS Code and conda. You may also check out the official document. It contains more features but less details.\nWe will talk about the relation between Python and Anaconda and more about packages sometime later.\n\n\n1.2.1.2 Google Colab\nClick Appendix A.2 for more details.\n\n\n\n1.2.2 Hello World!\n\nTake VS Code as an example. In the editor window, type in the code, and run the file in the interactive window.\n\nprint('Hello World!')\n\n\n\n\n\n\nIf you see a small green check mark in the interactive window and also the output Hello World!, you are good to go!\n\n\n1.2.3 Python code cells and Notebooks\nIn VS Code you can run codes cell by cell. Each cell is separated by the symbol # %%. Each cell may contain multiple lines. You may click the small button on top of the cell or use keybindings.\n\n\n\n\n\nThis feature actually mimic the notebook. We may start a real Python Notebook file by directly creating a file with extension .ipynb.\n\n\n\n\n\nThe layout is straightforward.\n\n\n1.2.4 Linters\nA linter is a tool to help you improve your code by analyzing your source code looking for problems. Some popular choices for Python includes Flake8 and Pylint. It is highly recommended to use one that is compatible with your IDE which can help you to increase the quality of your codes from the begining.\nTo install Flake8 please go to its homepage. It works well with VS Code.",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preliminaries</span>"
    ]
  },
  {
    "objectID": "contents/1/intro.html#exercises",
    "href": "contents/1/intro.html#exercises",
    "title": "1  Preliminaries",
    "section": "1.3 Exercises",
    "text": "1.3 Exercises\n\nExercise 1.1 (Hello world!) Please set up a Python developing environment, for both .py file and .ipynb notebook file, that will be used across the semester. Then print Hello World!.\n\n\nExercise 1.2 (Define a function and play with time) Please play with the following codes in a Jupyter notebook. We haven’t talked about any of them right now. Try to guess what they do and write your guess in markdown cells.\n\nimport time\n\ndef multistr(x, n=2):\n    return x * n\n\nt0 = time.time()\nx = 'Python'\nprint(multistr(x, n=10))\nt1 = time.time()\nprint(\"Time used: \", t1-t0)\n\n\n\nExercise 1.3 (Fancy Basketball plot) Here is an example of the data analysis. We pull data from a dataset, filter the data according to our needs and plot it to visualize the data. This is just a show case. You are encouraged to play the code, make tweaks and see what would happen. You don’t have to turn in anything.\nThe data we choose is Stephen Curry’s shots data in 2021-2022 regular season. First we need to load the data. The data is obtained from nba.com using nba_api. To install this package please go to its PyPI page.\n\nfrom nba_api.stats.static import players\nfrom nba_api.stats.endpoints import shotchartdetail\nplayer_dict = players.get_players()\n\nThe shots data we need is in shotchartdetail. However to use it we need to know the id of Stephen Curry using the dataset player_dict.\n\nfor player in player_dict:\n    if player['full_name'] == 'Stephen Curry':\n        print(player['id'])\n\n201939\n\n\nSo the id of Stephen Curry is 201939. Let’s pull out his shots data in 2021-2022 season.\n\nresults = shotchartdetail.ShotChartDetail(\n            team_id = 0,\n            player_id = 201939,\n            context_measure_simple = 'FGA',\n            season_nullable = '2021-22',\n            season_type_all_star = 'Regular Season')\ndf = results.get_data_frames()[0]\ndf.head()\n\n\n\n\n\n\n\n\nGRID_TYPE\nGAME_ID\nGAME_EVENT_ID\nPLAYER_ID\nPLAYER_NAME\nTEAM_ID\nTEAM_NAME\nPERIOD\nMINUTES_REMAINING\nSECONDS_REMAINING\n...\nSHOT_ZONE_AREA\nSHOT_ZONE_RANGE\nSHOT_DISTANCE\nLOC_X\nLOC_Y\nSHOT_ATTEMPTED_FLAG\nSHOT_MADE_FLAG\nGAME_DATE\nHTM\nVTM\n\n\n\n\n0\nShot Chart Detail\n0022100002\n26\n201939\nStephen Curry\n1610612744\nGolden State Warriors\n1\n10\n9\n...\nLeft Side Center(LC)\n24+ ft.\n28\n-109\n260\n1\n0\n20211019\nLAL\nGSW\n\n\n1\nShot Chart Detail\n0022100002\n34\n201939\nStephen Curry\n1610612744\nGolden State Warriors\n1\n9\n41\n...\nCenter(C)\n24+ ft.\n26\n48\n257\n1\n0\n20211019\nLAL\nGSW\n\n\n2\nShot Chart Detail\n0022100002\n37\n201939\nStephen Curry\n1610612744\nGolden State Warriors\n1\n9\n10\n...\nLeft Side Center(LC)\n24+ ft.\n25\n-165\n189\n1\n1\n20211019\nLAL\nGSW\n\n\n3\nShot Chart Detail\n0022100002\n75\n201939\nStephen Curry\n1610612744\nGolden State Warriors\n1\n6\n17\n...\nCenter(C)\nLess Than 8 ft.\n1\n-13\n12\n1\n0\n20211019\nLAL\nGSW\n\n\n4\nShot Chart Detail\n0022100002\n130\n201939\nStephen Curry\n1610612744\nGolden State Warriors\n1\n3\n11\n...\nCenter(C)\nLess Than 8 ft.\n2\n-15\n22\n1\n0\n20211019\nLAL\nGSW\n\n\n\n\n5 rows × 24 columns\n\n\n\ndf is the results we get in terms of a DataFrame, and we show the first 5 records as an example.\nThese are all attempts. We are interested in all made. By looking at all the columns, we find a column called SHOT_MADE_FLAG which shows what we want. Therefore we will use it to filter the records.\n\ndf_made = df[df['SHOT_MADE_FLAG']==1]\ndf_made.head()\n\n\n\n\n\n\n\n\nGRID_TYPE\nGAME_ID\nGAME_EVENT_ID\nPLAYER_ID\nPLAYER_NAME\nTEAM_ID\nTEAM_NAME\nPERIOD\nMINUTES_REMAINING\nSECONDS_REMAINING\n...\nSHOT_ZONE_AREA\nSHOT_ZONE_RANGE\nSHOT_DISTANCE\nLOC_X\nLOC_Y\nSHOT_ATTEMPTED_FLAG\nSHOT_MADE_FLAG\nGAME_DATE\nHTM\nVTM\n\n\n\n\n2\nShot Chart Detail\n0022100002\n37\n201939\nStephen Curry\n1610612744\nGolden State Warriors\n1\n9\n10\n...\nLeft Side Center(LC)\n24+ ft.\n25\n-165\n189\n1\n1\n20211019\nLAL\nGSW\n\n\n6\nShot Chart Detail\n0022100002\n176\n201939\nStephen Curry\n1610612744\nGolden State Warriors\n1\n0\n27\n...\nCenter(C)\nLess Than 8 ft.\n2\n-7\n29\n1\n1\n20211019\nLAL\nGSW\n\n\n9\nShot Chart Detail\n0022100002\n352\n201939\nStephen Curry\n1610612744\nGolden State Warriors\n2\n1\n29\n...\nCenter(C)\nLess Than 8 ft.\n1\n-1\n10\n1\n1\n20211019\nLAL\nGSW\n\n\n16\nShot Chart Detail\n0022100002\n510\n201939\nStephen Curry\n1610612744\nGolden State Warriors\n3\n2\n23\n...\nCenter(C)\nLess Than 8 ft.\n1\n7\n8\n1\n1\n20211019\nLAL\nGSW\n\n\n18\nShot Chart Detail\n0022100002\n642\n201939\nStephen Curry\n1610612744\nGolden State Warriors\n4\n5\n34\n...\nCenter(C)\n24+ ft.\n26\n48\n260\n1\n1\n20211019\nLAL\nGSW\n\n\n\n\n5 rows × 24 columns\n\n\n\nWe also notice that there are two columns LOC_X and LOC_Y shows the coordinates of the attempts. We will use it to draw the heatmap. The full code for drawing out the court draw_court is folded below. It is from Bradley Fay GitHub.\n\n\n\n\n\n\nNote\n\n\n\nNote that, although draw_cort is long, it is not hard to understand. It just draws a court piece by piece.\n\n\n\n\nCode\nfrom matplotlib.patches import Circle, Rectangle, Arc\nimport matplotlib.pyplot as plt\n\n\ndef draw_court(ax=None, color='gray', lw=1, outer_lines=False):\n    \"\"\"\n    Returns an axes with a basketball court drawn onto to it.\n\n    This function draws a court based on the x and y-axis values that the NBA\n    stats API provides for the shot chart data.  For example, the NBA stat API\n    represents the center of the hoop at the (0,0) coordinate.  Twenty-two feet\n    from the left of the center of the hoop in is represented by the (-220,0)\n    coordinates.  So one foot equals +/-10 units on the x and y-axis.\n    \"\"\"\n    if ax is None:\n        ax = plt.gca()\n\n    # Create the various parts of an NBA basketball court\n\n    # Create the basketball hoop\n    hoop = Circle((0, 0), radius=7.5, linewidth=lw, color=color, fill=False)\n\n    # Create backboard\n    backboard = Rectangle((-30, -7.5), 60, -1, linewidth=lw, color=color)\n\n    # The paint\n    # Create the outer box 0f the paint, width=16ft, height=19ft\n    outer_box = Rectangle((-80, -47.5), 160, 190, linewidth=lw, color=color,\n                          fill=False)\n    # Create the inner box of the paint, widt=12ft, height=19ft\n    inner_box = Rectangle((-60, -47.5), 120, 190, linewidth=lw, color=color,\n                          fill=False)\n\n    # Create free throw top arc\n    top_free_throw = Arc((0, 142.5), 120, 120, theta1=0, theta2=180,\n                         linewidth=lw, color=color, fill=False)\n    # Create free throw bottom arc\n    bottom_free_throw = Arc((0, 142.5), 120, 120, theta1=180, theta2=0,\n                            linewidth=lw, color=color, linestyle='dashed')\n    # Restricted Zone, it is an arc with 4ft radius from center of the hoop\n    restricted = Arc((0, 0), 80, 80, theta1=0, theta2=180, linewidth=lw,\n                     color=color)\n\n    # Three point line\n    # Create the right side 3pt lines, it's 14ft long before it arcs\n    corner_three_a = Rectangle((-220, -47.5), 0, 140, linewidth=lw,\n                               color=color)\n    # Create the right side 3pt lines, it's 14ft long before it arcs\n    corner_three_b = Rectangle((220, -47.5), 0, 140, linewidth=lw, color=color)\n    # 3pt arc - center of arc will be the hoop, arc is 23'9\" away from hoop\n    three_arc = Arc((0, 0), 475, 475, theta1=22, theta2=158, linewidth=lw,\n                    color=color)\n\n    # Center Court\n    center_outer_arc = Arc((0, 422.5), 120, 120, theta1=180, theta2=0,\n                           linewidth=lw, color=color)\n    center_inner_arc = Arc((0, 422.5), 40, 40, theta1=180, theta2=0,\n                           linewidth=lw, color=color)\n\n    # List of the court elements to be plotted onto the axes\n    court_elements = [hoop, backboard, outer_box, inner_box, top_free_throw,\n                      bottom_free_throw, restricted, corner_three_a,\n                      corner_three_b, three_arc, center_outer_arc,\n                      center_inner_arc]\n\n    if outer_lines:\n        # Draw the half court line, baseline and side out bound lines\n        outer_lines = Rectangle((-250, -47.5), 500, 470, linewidth=lw,\n                                color=color, fill=False)\n        court_elements.append(outer_lines)\n\n    # Add the court elements onto the axes\n    for element in court_elements:\n        ax.add_patch(element)\n\n    return ax\n\n\n\n# Create figure and axes\nfig = plt.figure(figsize=(6, 6))\nax = fig.add_axes([0, 0, 1, 1])\n\n# Plot hexbin of shots\nax.hexbin(df['LOC_X'], df['LOC_Y'], gridsize=(30, 30), extent=(-300, 300, 0, 940), bins='log', cmap='Blues')\nax = draw_court(ax, 'black')\n\n# Annotate player name and season\nax.text(0, 1.05, 'Stephen Curry\\n2021-22 Regular Season', transform=ax.transAxes, ha='left', va='baseline')\n\n# Set axis limits\n_ = ax.set_xlim(-250, 250)\n_ = ax.set_ylim(0, 400)",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preliminaries</span>"
    ]
  },
  {
    "objectID": "contents/2/intro.html#sec-path",
    "href": "contents/2/intro.html#sec-path",
    "title": "2  Python Basics",
    "section": "2.1 numeric and str",
    "text": "2.1 numeric and str\nThis section is based on [1].\nThere are several built-in data structures in Python. Here is an (incomplete) list:\n\nNone\nBoolean – True, False\nNumeric Types — int, float, complex\nText Sequence Type — str\nSequence Types — list, tuple\nMap type - dict\n\nWe will cover numeric types and strings in this section. The rests are either simple that are self-explained, or not simple that will be discussed later.\n\n2.1.1 Numeric types and math expressions\nNumeric types are represented by numbers. If there are no confusions, Python will automatically detect the type.\n\nx = 1 # x is an int.\ny = 2.0 # y is a float.\n\nThere are several types of numeric types, like int, float, etc.. Usually Python will automatically determine the type of the data, but sometimes you may still want to declare them manually. To change types you may apply int(), float(), etc. to the values you want to change.\nPython can do math just like other programming languages. The basic math operations are listed as follows.\n\n+, -, *, /, &gt;, &lt;, &gt;=, &lt;= works as normal.\n** is the power operation.\n% is the mod operation.\n!= is not equal\n\n\n\n\n\n\n\n== and is\n\n\n\n\n\nPython is centered around objects. There are differences between two objects and the values of two objects.\n\n== is testing whehter these two objects have the same value.\nis is testing whether these two objects are exactly the same.\n\nYou may use id(x) to check the id of the object x. Two objects are identical if they have the same id. Please see the following example.\na and b are two lists. They are different objects, but their contents are the same.\n\na = [1, 2]\nb = [1, 2]\na == b\n\nTrue\n\n\n\na is b\n\nFalse\n\n\nYou may check their ids and find that their ids are different.\n\nid(a) == id(b)\n\nFalse\n\n\nFor beginners, in most cases, you should use == to check values of variables. The most common case to use is is to check whether something is a None object. In other words, you should use a is None other than a == None.\nMore details about objects will be discussed later in this course.\n\n\n\n\n\n2.1.2 str\nScalars are represented by numbers and strings are represented by quotes. Examples:\n\nx = 1       # x is a scalar.\ny = 's'     # y is a string with one letter.\nz = '0'     # z loos like a number, but it is a string.\nw = \"Hello\" # w is a string with double quotes.\n\nHere are some facts.\n\nFor strings, you can use either single quotes ' or double quotes \". The tricky part here is that you may use ' in \", or \" in '. If you want to use ' in ' or \" in \", use \\ below.\n\\ is used to denote escaped words. You may find the list here.\nYou can use str() to change other values to a string, if able.\nYou may use string[n] to read the nth letter of string. Note that the index starts from 0. This part is very similar to list. We will come back to it later after we talked about list.\n\n\ns = 'abcdef'\ns[3]\n\n'd'\n\n\n\nTo concatenate two strings, you may simply use +. See the following example.\n\n\ns = 'abc' + 'def'\ns\n\n'abcdef'\n\n\n\nWe can also multiply a string with a positive integer. What it does is to repeat the string multiple times. See the following example.\n\n\ns = 'abc'*5\ns\n\n'abcabcabcabcabc'\n\n\n\n\n\n\n\n\n.format() method\n\n\n\n\n\nThe built-in string class provides the ability to do complex variable substitutions and value formatting via the .format() method. The basic syntax is to use the inputed augments to fill in the blanks in the formatted string specified by {}. Please see the following examples.\n\n'I have {} {} and {} {}.'.format(1, 'apple', 2, 'bananas')\n\n'I have 1 apple and 2 bananas.'\n\n\nMore detailed usage is refered to the official documents here.\n\n\n\nAlthough str is a built-in type, there are tons of tricks with str, and there are tons of packages related to strings. Generally speaking, to play with strings, we are interested in two types of tasks.\n\nPut information together to form a string.\nExtract information from a string.\n\nA lot of tricks of strings are related to lists. We will talk about these two tasks later. The following example is just a showcase.\n\n\nExample 2.1 Here is an example of playing with strings. Please play with these codes and try to understand what they do.\n\nimport re\n\ndef clean_strings(strings):\n    result = []\n    for value in strings:\n        value = value.strip()\n        value = re.sub('[!#?]', '', value)\n        value = value.title()\n        result.append(value)\n    return result\n\nstates = [' Alabama ', 'Georgia!', 'Georgia', 'georgia', 'FlOrIda',\n          'south carolina##', 'West virginia?']\nclean_strings(states)\n\n['Alabama',\n 'Georgia',\n 'Georgia',\n 'Georgia',\n 'Florida',\n 'South Carolina',\n 'West Virginia']",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "contents/2/intro.html#fundamentals",
    "href": "contents/2/intro.html#fundamentals",
    "title": "2  Python Basics",
    "section": "2.2 Fundamentals",
    "text": "2.2 Fundamentals\nThis section is mainly based on [2].\n\n2.2.1 Indentation\nOne key feature about Python is that its structures (blocks) is determined by Indentation.\nLet’s compare with other languages. Let’s take C as an example.\n/*This is a C function.*/\nint f(int x){return x;}\nThe block is defined by {} and lines are separated by ;. space and newline are not important when C runs the code. It is recommended to write codes in a “beautiful, stylish” format for readibility, as follows. However it is not mandatory.\n/*This is a C function.*/\nint f(int x) {\n   return x;\n}\nIn Python, blocks starts from : and then are determined by indents. Therefore you won’t see a lot of {} in Python, and the “beautiful, stylish” format is mandatory.\n\n# This is a Python function.\ndef f(x):\n    return x\n\nThe default value for indentation is 4 spaces, which can be changed by users. We will just use the default value in this course.\n\n\n\n\n\n\nLine break\n\n\n\n\n\nIt is usually recommended that one line of code should not be very long. If you do have one, and it cannot be shortened, you may break it into multiline codes directly in Python. However, since indentation is super important in Python, when break one line code into multilines, please make sure that everything is aligned perfectly. Please see the following example.\n\nresults = shotchartdetail.ShotChartDetail(\n            team_id = 0,\n            player_id = 201939,\n            context_measure_simple = 'FGA',\n            season_nullable = '2021-22',\n            season_type_all_star = 'Regular Season')\n\nSimilarly for long strings, you may use \\ to break it into multiple lines. Here is one example.\n\nsentence = \"This is\\ngood enough\\nfor a exercise to\\nhave so many parts. \" \\\n           \"We would also want to try this symbol: '. \" \\\n           \"Do you know how to type \\\" in double quotes?\"\n\n\n\n\n\n\n2.2.2 import\nIn Python a module is simply a file with the .py extension containing Python code. Assume that we have a Python file example.py stored in the folder assests/codes/. The file is as follows.\n\n\nassests/codes/example.py\n\ndef f(x):\n    print(x)\n\nA = 'You found me!'\n\nYou may get access to this function and this string in the following way.\n\nfrom assests.codes import example\n\nexample.f(example.A)\n\nYou found me!\n\n\n\n\n2.2.3 Comments\nAny text preceded by the hash mark (pound sign) # is ignored by the Python interpreter. In many IDEs you may use hotkeys to directly toggle multilines as comments. For example, in VS Code the default setting for toggling comments is ctrl+/.\n\n\n2.2.4 Dynamic references, strong types\nIn some programming languages, you have to declare the variable’s name and what type of data it will hold. If a variable is declared to be a number, it can never hold a different type of value, like a string. This is called static typing because the type of the variable can never change.\nPython is a dynamically typed language, which means you do not have to declare a variable or what kind of data the variable will hold. You can change the value and type of data at any time. This could be either great or terrible news.\nOn the other side, “dynamic typed” doesn’t mean that types are not important in Python. You still have to make sure that the types of all variables meet the requirements of the operations used.\n\na = 1\nb = 2\nb = '2'\nc = a + b\n\nTypeError: unsupported operand type(s) for +: 'int' and 'str'\n\n\nIn this example, b was first assigned by a number, and then it was reassigned by a str. This is totally fine since Python is dynamically typed. However later when adding a and b, the type error occurs since you cannot add a number and a str.\n\n\n\n\n\n\nNote\n\n\n\nYou may always use type(x) to detect the type of the object x.\n\n\n\n\n2.2.5 Everything is an object\nEvery number, string, data structure, function, class, module, and so on exists in the Python interpreter in its own “box”, which is referred to as a Python object.\nEach object has an associated type (e.g., string or function) and internal data. In practice this makes the language very flexible, as even functions can be treated like any other object.\nEach object might have attributes and/or methods attached.\n\n\n2.2.6 Mutable and immutable objects\nAn object whose internal state can be changed is mutable. On the other hand, immutable doesn’t allow any change in the object once it has been created.\nSome objects of built-in type that are mutable are:\n\nLists\nDictionaries\nSets\n\nSome objects of built-in type that are immutable are:\n\nNumbers (Integer, Rational, Float, Decimal, Complex & Booleans)\nStrings\nTuples\n\nIn the following courses, you will learn some of these objects. You will see that for mutable objects, there are built-in methods to modify them, like .append() for list, which append element to the end of a list. There are none for immutable objects.\n\n\n\n\n\n\nA tricky case: Tuples are not really “immutable”\n\n\n\n\n\nYou can treat a tuple as a container, which contains some objects. The relations between the container and its contents are immutable, but the objects it holds might be mutable. Please check the following example.\n\ncontainer = ([1], [2])\nprint('This is `container`: ', container)\nprint('This is the id of `container`: ', id(container))\nprint('This is the id of the first list of `container`: ', id(container[0]))\n\nThis is `container`:  ([1], [2])\nThis is the id of `container`:  2088221702272\nThis is the id of the first list of `container`:  2088221574784\n\n\n\ncontainer[0].append(2)\nprint('This is the new `container`: ', container)\nprint('This is the id of the new `container`: ', id(container))\nprint('This is the id of the first list (which is updated) of the new `container`: ', id(container[0]))\n\nThis is the new `container`:  ([1, 2], [2])\nThis is the id of the new `container`:  2088221702272\nThis is the id of the first list (which is updated) of the new `container`:  2088221574784\n\n\nYou can see that the tuple container and its first object stay the same, although we add one element to the first object.\nYou may understand how objects are stored by considering this example.",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "contents/2/intro.html#flows-and-functions",
    "href": "contents/2/intro.html#flows-and-functions",
    "title": "2  Python Basics",
    "section": "2.3 Flows and Functions",
    "text": "2.3 Flows and Functions\n\n2.3.1 for loop\nA for loop is used for iterating over an iterator. Iterators can be gotten from lists, tuples, strings, etc.. The basic syntax of a for loop is as follows.\n\nfor i in aniterator:\n    do thing\n\nIn each iteration, the aniterator will produce a value and assign it to i. Then the code in the for loop will run with i being assigned to the specific value.\nLet’s look at some typical examples of iterators.\n\n\n\n\n\n\nrange()\n\n\n\n\n\nrange(N) is an iterator which will produce integers from 0 to N-1. This is the most basic way to use for loop that you may treat i as the index of an iteration. Note that similar to the list index rule (which will be discussed later), the right end point N is not included.\n\nfor i in range(3):\n    print(i)\n\n0\n1\n2\n\n\nThere are two more versions of range():\n\nrange(M, N) can generate integers from M to N-1.\nrange(M, N, s) can generate integers from M to N-1, with the step size s. Similarly, in both cases, the right end point N is not included.\n\n\nfor i in range(1, 3):\n    print(i)\n\n1\n2\n\n\n\nfor i in range(1, 5, 2):\n    print(i)\n\n1\n3\n\n\n\n\n\n\n\n\n\n\n\nStrings\n\n\n\n\n\nYou may use a string as an iterator. It will go through the string and generate the letter in it one by one from the beginning to the end. Note that escaped letters will be captured. Please see the following example.\n\ns = 'abc\\\"'\nfor i in s:\n    print(i)\n\na\nb\nc\n\"\n\n\n\n\n\n\n\n\n\n\n\nLists\n\n\n\n\n\nWe will talk about lists in details in next section. We will briefly mention it here since lists are the most common iterators in Python. Roughly speaking, a list is an ordered sequence of Python objects. As an iterator, it just goes through the sequence and generates the object in it one by one from the beginning to the end. Please see the following example.\n\ns = [1, 'a', -3.1, 'abc']\nfor i in s:\n    print(i)\n\n1\na\n-3.1\nabc\n\n\n\n\n\n\n\n\n\n\n\nzip()\n\n\n\n\n\nThe “Pythonic way” to write loops is to NOT use indexes. In this case how do we loop through two iterators if no indexes are used? We could use zip().\nzip() is used to “zip” two iterators together to form one. Then we can use the zipped one for the loop and elements from both iterators are zipped into tuples. Please see the following examples.\n\na = [1, 2, 3]\nb = ['a', 'b', 'c']\nfor item in zip(a, b):\n    print(item)\n\n(1, 'a')\n(2, 'b')\n(3, 'c')\n\n\n\nc = range(3)\nd = 'abc'\nfor item in zip(c, d):\n    print(item)\n\n(0, 'a')\n(1, 'b')\n(2, 'c')\n\n\n\n\n\n\n\n2.3.2 if statement\nThe if statement is straightforword. Here is a typical example.\n\nx = -1\n\nif x &lt; 0:\n    x = 0\n    print('Negative changed to zero')\nelif x == 0:\n    print('Zero')\nelif x == 1:\n    print('Single')\nelse:\n    print('More')\n\nNegative changed to zero\n\n\nThere can be zero or more elif parts, and the else part is optional.\n\n\n2.3.3 Functions\nFunctions are declared with the def keyword and returned from the return keyword. Here is a typical example of a function.\n\ndef my_function(x, y, z=1.5):\n    if z &gt; 1:\n        return z * (x + y)\n    else:\n        return z / (x + y)\n\nEach function can have positional arguments and keyword arguments.\n\nz=1.5 in above example means that the default value for z is 1.5. Keyword arguments are most commonly used to specify default values.\nIf no keywords are given, all arguments will be recognized by the positions.\nIf both positional arguments and keyword arguments are given, positional arguments have to be in front.\nThe order of keyword arguments are not important.\n\n\n\n\n\n\n\nNote\n\n\n\nAlthough there are global variable, it is always ecouraged to use local variables only. This means that the variables in and out of a function (as well as classes that we will talk about later) are not the same, even if they have the same name.\n\n\n\n\n\n\n\n\nLambda function\n\n\n\n\n\nlambda function is a way of writing functions consisting of a single statment. The format is lambda x: output of x.\nPlease see the following examples.\n\nf = lambda x: 2*x+1\n\nf(3)\n\n7\n\n\n\ndef apply_to_list(some_list, f):\n    return [f(x) for x in some_list]\n\nints = [4, 0, 1, 5, 6]\napply_to_list(ints, lambda x: x * 2)\n\n[8, 0, 2, 10, 12]\n\n\nTo fully understand the following example requires knowledge from Section 2.5.\n\nfruits = {'banana': 3, 'apple': 4, 'pear': 1, 'orange': 2}\n\nfruits_sorted = sorted(fruits.items(), key=lambda x: x[1])\nfruits_sorted\n\n[('pear', 1), ('orange', 2), ('banana', 3), ('apple', 4)]\n\n\nLambda function is always used as a input parameter when it is not worth to use extra space to write a one line function. You will see several examples in the Chapter of pandas.\n\n\n\n\n\n\n\n\n\nThis is a tricky but not very rare case: mutable objects as default values.\n\n\n\n\n\nIt is highly recommended NOT to set any mutatable objects as the default value of an input of a function. The reason is that this default object is initialized when the function is defined, not when the function is called. Then all function calls will share the same default object.\nA typical example is an empty list. If you use an empty list as the defaul value, that list will be passed to the next function call, which is no longer empty. Please see the following example.\n\ndef add(x=[]):\n    x.append(1)\n    return x\n\nadd()\n\n[1]\n\n\n\nadd()\n\n[1, 1]\n\n\n\nadd()\n\n[1, 1, 1]\n\n\nEvery time the function is called with no arguments, the default value is used, which is the same list initialized at the beginning. The list at the begining is an empty list. But after we put things inside, it is no longer empty.\nIf you want to set a mutable object as a default, the way is as follows:\n\ndef add(x=None):\n    if x is None:\n        x = list()\n    x.append(1)\n    return x\n\nadd()\n\n[1]\n\n\n\nadd()\n\n[1]\n\n\n\nadd()\n\n[1]",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "contents/2/intro.html#list",
    "href": "contents/2/intro.html#list",
    "title": "2  Python Basics",
    "section": "2.4 list",
    "text": "2.4 list\nlist is a basic Python data structure. It is an ordered sequence of object types, and it is denoted by []. A typical list example is [0, 1, 2], which is a 3-element list.\nMain questions in list contain creating, indexing and applications.\n\n2.4.1 Creating lists\nThere are two built-in methods to create lists.\n\n\n\n\n\n\nNaive way\n\n\n\n\n\nA list can be created simply by writing down all the elements in order and enclosed by []. Please see the following typical example.\n\nL = [0, 1, 2]\nL\n\n[0, 1, 2]\n\n\nAn empty list can be denoted by [].\n\n\n\n\n\n\n\n\n\nUse list() to convert objects into a list\n\n\n\n\n\nSimilar to the type change for numeric types and str, you may use list() to convert other objects into a list, if able. The typical example is to convert other iterators into lists.\n\ns = 'abc'\nlist(s)\n\n['a', 'b', 'c']\n\n\n\nr = range(1, 6, 2)\nlist(r)\n\n[1, 3, 5]\n\n\n\nlist(zip(s, r))\n\n[('a', 1), ('b', 3), ('c', 5)]\n\n\nEmpty list can be created by list().\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe real difference between this above two methods are very subtle. You may just focus on which one can create the list you want, for now.\n\n\n\n\n2.4.2 Indexing\nThere are two ways to get access to elements in a list: by position or by slice.\n\n\n\n\n\n\nBy position\n\n\n\n\n\nLet L be a list. Then L[i] will return the i-th element in the list.\n\nAll index in Python starts from 0. Therefore the first element is L[0], the second is L[1], etc..\nNegative position means go backwards. So L[-1] means the last element, L[-2] means the second last element, etc..\n\n\nL = [1, 2, 3]\nL[0]\n\n1\n\n\n\nL[-2]\n\n2\n\n\n\n\n\n\n\n\n\n\n\nBy slicing\n\n\n\n\n\nslice is a Python object. It looks like slice(start, stop, step). It represents an arithematic sequence, which starts from start, ends before stop with a step size step. The default step size is 1. For example, slice(0, 5, 1) represents an arithematic sequence 0, 1, 2, 3, 4. Note that slice(0, 5, 1) itself is a slice object, and it is NOT the list [0, 1, 2, 3, 4].\nLet L be a list, and s=slice(start, stop, step) be a slice. L[s] is the portion of the original list L given by the index indicated by the slice s, as a list. A common way to write slice is through :. When slicing a list, you may also use\n\nL[start:stop:step]\n\n\nThe slice ends before stop. Therefore the right end point stop is not in the slice.\nIf step is not specified, step=1 is the default value.\nIf start or stop is not specified, the default value is the first of the list or the last.\nstart and stop follows the rules of negative positions.\nWhen slicing, the result is always a list, even if it only contains one element.\n\n\nL = ['a', 'b', 'c', 'd', 'e']\nL[1:5:2]\n\n['b', 'd']\n\n\n\nL[1:3]\n\n['b', 'c']\n\n\n\nL[:-1]\n\n['a', 'b', 'c', 'd']\n\n\n\nL[-1:0:-1]\n\n['e', 'd', 'c', 'b']\n\n\n\n\n\n\n\n2.4.3 Methods\n\n\n\n\n\n\nin\n\n\n\n\n\nin is used to check whether one object is in a list. Please see the following example.\n\nL = ['1', '2', '3']\n'1' in L\n\nTrue\n\n\n\n1 in L\n\nFalse\n\n\n\n\n\n\n\n\n\n\n\n.append()\n\n\n\n\n\n.append() method is used to add one object to the list. The default setting is to add the object to the end of the list. Please see the following example.\n\nL = [1, 2, 3]\nL.append(4)\nL\n\n[1, 2, 3, 4]\n\n\nNote that you may input any Python object. If appending another list, that list will be treated as an object. Please see the following example.\n\nL = [1, 2, 3]\nL.append([4, 5])\nL\n\n[1, 2, 3, [4, 5]]\n\n\n\n\n\n\n\n\n\n\n\n.extend() and +\n\n\n\n\n\n.extend() method is used to extend the original list by another list. The input has to be a list. Please see the following example.\n\nL = [1, 2, 3]\nL.extend([4, 5])\nL\n\n[1, 2, 3, 4, 5]\n\n\n\nL = [1, 2, 3]\nL.extend(4)\nL\n\nTypeError: 'int' object is not iterable\n\n\nYou may use + to represent .extend(). Please see the following example. It is exactly the same as [1, 2, 3].extend(['a', 'b']).\n\n[1, 2, 3] + ['a', 'b']\n\n[1, 2, 3, 'a', 'b']\n\n\n\n\n\n\n\n\n\n\n\ndel, .remove() and .pop()\n\n\n\n\n\nThere are multiple ways to remove an element from a list.\n\n.remove() is a list method, that is used as L.remove(a). It removes element in-place and is based on values. In other words, it will remove the first element whose value equals to a.\n\n\nL = [2, 3, 1, 3, 1, 2]\nL.remove(1)\nL\n\n[2, 3, 3, 1, 2]\n\n\n\n.pop() is also a list method. It removes element in-place, is based on position index, and will return the element removed. The default choice is to pop the last element.\n\n\nL = [1, 2, 3, 4]\nelement_popped = L.pop()\nelement_popped\n\n4\n\n\n\nL\n\n[1, 2, 3]\n\n\n\nL = [1, 2, 3, 4]\nelement_popped = L.pop(2)\nelement_popped\n\n3\n\n\n\nL\n\n[1, 2, 4]\n\n\n\ndel is a Python command, that is used to delete elements in a list based on position index.\n\n\nL = [3, 1, 2, 1, 2, 3]\ndel L[3]\nL\n\n[3, 1, 2, 2, 3]\n\n\n\n\n\n\n\n\n\n\n\nsorted() and .sort()\n\n\n\n\n\nLet L be a list of numbers. We could use sorted(L) or L.sort() to sort this list L.\n\nsorted() is a Python built-in function. The syntax is straightforward.\n\n\na = [3, 1, 2]\nb = sorted(a)\nb\n\n[1, 2, 3]\n\n\n\n.sort() is a list method. It sorts the list in place.\n\n\na = [3, 1, 2]\na.sort()\na\n\n[1, 2, 3]\n\n\nNote that a.sort() doesn’t have any return values. a is altered during the process. If you want to catch the return value, you will get a None object.\n\nb = a.sort()\nb is None\n\nTrue\n\n\n\n\n\n\n\n\nThe importance of documents\n\n\n\nThis example shows that similar functions may behaves differently. It is actually very hard to predict what would happen since it all depends on how the developer of the function thinks about the problems.\nTherefore it is very important to know how to find references. Other than simply asking questions on StackOverflow or other forums, the official documents are always your good friend. For example, you may find how these two functions work from sorted() and .sort().\n\n\n\n\n\n\n\n2.4.4 Work with str\nThere are many operations of str are related to list.\n\n\n\n\n\n\nSlicing\n\n\n\n\n\nWe already mentioned that we could use s[n] to get the nth letter of a string s. Similarly we could use slice to get part of a string. Note that the index shares the same rule as lists.\n\ns = 'abcdef'\ns[1]\n\n'b'\n\n\n\ns[1:3]\n\n'bc'\n\n\n\ns[1:5:2]\n\n'bd'\n\n\n\n\n\n\n\n\n\n\n\n.split()\n\n\n\n\n\nsplit is used to split a string original_string by a given substring sep. The result is a list of the remaining parts. The syntax is\n\noriginal_string.split(sep)\n\nPlease see the following example.\n\ns = 'abcabcadedeb'\ns.split('b')\n\n['a', 'ca', 'cadede', '']\n\n\nNote that the last element of the result is an empty string '' since the last letter of s is b.\n\ns = 'abcabcadedeb'\ns.split('ca')\n\n['ab', 'b', 'dedeb']\n\n\n\n\n\n\n\n\nTip\n\n\n\nThis .split() is a very simple way to recognize patterns in a string. To fully explore this topic, the best practice is to use regular expressions.\n\n\n\n\n\n\n\n\n\n\n\n.join()\n\n\n\n\n\nLet L be a list of strings. We could connect them together to form a single string, by using .join(). We could put a separator string sep between each part in the list L. The result is the connected string. The syntax is\n\nsep.join(L)\n\nPlease see the following example.\n\nL = ['a', 'b', 'c', 'd']\n'+'.join(L)\n\n'a+b+c+d'\n\n\n\n''.join(L)\n\n'abcd'\n\n\nNote that in this example the separtor string is an empty string.",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "contents/2/intro.html#sec-dict",
    "href": "contents/2/intro.html#sec-dict",
    "title": "2  Python Basics",
    "section": "2.5 dict",
    "text": "2.5 dict\nDictionary dict is also very important built-in Python data structure. It is a flexibly sized collection of key-value pairs, where key and value are Python objects. One approach for creating a dictionary is to use {} and colons to separate keys and values.\n\nexample = {'a': 'value',\n           'b': 1,\n           3: 'a',\n           4: [1, 2 ,3],}\n\nYou can access, insert, or set elements using the same syntax as for accessing elements of a list.\n\nexample['a']\n\n'value'\n\n\n\nexample[4]\n\n[1, 2, 3]\n\n\n\n\n\n\n\n\nChecking keys\n\n\n\n\n\nWe can directly use in to check whether a dict contains a key.\n\n'a' in example\n\nTrue\n\n\n\n1 in example\n\nFalse\n\n\n\n\n\n\n\n\n\n\n\n.keys(), .values() and .items()\n\n\n\n\n\nWe could use .keys() to get all keys. The result is actually an iterator. We could either loop through it using for, or simply convert it to a list by list().\n\nlist(example.keys())\n\n['a', 'b', 3, 4]\n\n\nSimilarly, to get all values, we could use .values() method. What we get is an iterator, and we could convert it to a list.\n\nlist(example.values())\n\n['value', 1, 'a', [1, 2, 3]]\n\n\nSimilar to the previous two, .items() is used to get key-value pairs, in the same style.\n\nlist(example.items())\n\n[('a', 'value'), ('b', 1), (3, 'a'), (4, [1, 2, 3])]\n\n\n\n\n\n\n\n\n\n\n\nUpdate dictionaries\n\n\n\n\n\n\nTo update a key-value pair, you may directly write\n\n\ndictionary[key] = value\n\nIf this key exists, the key-value pair will be updated. If this key doesn’t exist, this key-value pair will be added to the dictionary. See the following examples.\n\nexample['a'] = 'newvalue'\nexample\n\n{'a': 'newvalue', 'b': 1, 3: 'a', 4: [1, 2, 3]}\n\n\n\nexample['newkey'] = 'good!'\nexample\n\n{'a': 'newvalue', 'b': 1, 3: 'a', 4: [1, 2, 3], 'newkey': 'good!'}\n\n\n\nTo merge with another dict, you may use .update() method. This is very similar to .extend() for list. Note that if the same key exists in both dictionaries, the old value will be updated by the new one. Please see the following example.\n\n\nexample.update({'a': 'new', 10: [1, 2], 11: 'test'})\nexample\n\n{'a': 'new',\n 'b': 1,\n 3: 'a',\n 4: [1, 2, 3],\n 'newkey': 'good!',\n 10: [1, 2],\n 11: 'test'}",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "contents/2/intro.html#more-advanced-topics",
    "href": "contents/2/intro.html#more-advanced-topics",
    "title": "2  Python Basics",
    "section": "2.6 More advanced topics",
    "text": "2.6 More advanced topics\n\n2.6.1 list/dict comprehension\nlist comprehension is a convenient way to create lists based on the values of an existing list. It cannot provide any real improvement to the performance of the codes, but it can make the codes shorter and easier to read.\nThe format of list comprehension is\n\nnewlist = [expression for item in iterable if condition == True]\n\nIt is equivalent to the folowing code:\n\nnewlist = []\nfor item in iterable:\n    if condition == True:\n        newlist.append(expression)\n\nSimilarly, there is a dict comprehension.\n\nnewdict = {key-expr: value-expr for item in iterable if condition == True}\n\n\n\n\n\n\n\nCaution\n\n\n\nlist/dict comprehension is very powerful, and it is able to create very complex nested list/dict comprehension to squeeze some complicated codes into one line. It is highly recommended NOT to do so.\nThe purpose of list/dict comprehension is to improve readablity. Complicated nested list/dict comprehension actually makes your code hard to read. You can make list/dict comprehension with more than one layer only if you have a very good reason.\n\n\n\nExample 2.2 Consider the following dict.\n\nexample_dict = {'key1': 'value1',\n                'key2': 'value2',\n                'key3': 'value3'}\n\n\nWe want to go through the keys and generate a list whose elements are gotten by concatnating the keys and a fixed prefix pre.\nWe want to go through the values and generate a list whose elements are gotten by concatnating the values and a fixed postfix post.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n.keys() can give an iterator which helps us to loop through all the keys.\nFor each key, we may add pre to the front of it, and then put the result into a list.\nThis process is exactly what list comprehension can do.\n\nHere is the sample code.\n\nprekeys = ['pre'+key for key in example_dict.keys()]\npostvalues = [value+'post' for value in example_dict.values()]\n\n\n\n\n\n\nExample 2.3 Given a string s=abcde, create a dict that relates a letter with its next (and the next of e is back to a).\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe problem actually creates a circle consisting of a, b, c, d and e. See the following diagram.\n\n\n\n\n\n\n\nG\n\n\n\na\n\ns[0]=a\n\n\n\nb\n\ns[1]=b\n\n\n\na-&gt;b\n\n\n\n\n\nc\n\ns[2]=c\n\n\n\nb-&gt;c\n\n\n\n\n\nd\n\ns[3]=d\n\n\n\nc-&gt;d\n\n\n\n\n\ne\n\ns[4]=e\n\n\n\nd-&gt;e\n\n\n\n\n\ne-&gt;a\n\n\n\n\n\n\n\n\n\n\nIf we focus on the index, the transformation can be formulated as “add 1 and then mod 5”. Therefore, every time when we get a letter s[i], its next is s[(i+1)%5]. Then our code is as follows.\n\ns = 'abcde'\ntransform_dict = {}\nfor i in range(len(s)):\n    transform_dict[s[i]] = s[(i+1)%5]\n\nNote that this process is exactly what a dict comprehension can do. Therefore we can simplify the above code as follows.\n\ns = 'abcde'\ntransform_dict = {s[i]: s[(i+1)%5] for i in range(len(s))}",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "contents/2/intro.html#examples",
    "href": "contents/2/intro.html#examples",
    "title": "2  Python Basics",
    "section": "2.7 Examples",
    "text": "2.7 Examples\n\n2.7.1 Monty Hall problem\nThe Monty Hall problem is a brain teaser, in the form of a probability puzzle, loosely based on the American television game show Let’s Make a Deal and named after its original host, Monty Hall. The problem is stated as follows:\nSuppose you’re on a game show, and you’re given the choice of three doors: Behind one door is a car; behind the others, goats. You pick a door, say No. 1, and the host, who knows what’s behind the doors, opens another door, say No. 3, which has a goat. He then says to you, “Do you want to pick door No. 2?” Is it to your advantage to switch your choice?\nHere is a YouTube video of the Monty Hall problem.\n\nWe would like to use code to simulate this process. Here are the steps.\n\n\n\n\n\n\nSetup\n\n\n\n\n\nWe use 1, 2, 3 to denote the three doors. We could put it in a list doors = [1, 2, 3]. Later after the game, we may record our result. There are only two possibilites: remains with the initial choice wins or switch to the new choice wins. We may record the result in a dictionary results={'remain': 0, 'switch': 0}, and update the corresponding key after one game.\n\ndoors = [1, 2, 3]\nresults = {'remain': 0, 'switch': 0}\n\n\n\n\n\n\n\n\n\n\n1. Put the car behind a door.\n\n\n\n\n\nWe randomly pick one door and put the car behind it.\n“Randomly pick” can be done by random.choice(). What it does is to take a sample chosen from the list. In our case, we would like to take a sample from doors. Therefore we want to use random.choice(doors). The output is the door we randomly pick to put the car. So we set it to a variable door_with_car to remind us.\n\nimport random\ndoor_with_car = random.choice(doors)\n\nThis is a function in the package random. So to use it you should first import random. You may get more information from the official document.\n\n\n\n\n\n\n\n\n\n2. Make the initial choice.\n\n\n\n\n\nWe make our initial choice. We could also randomly pick one door as our initial choice. The code is similar to the previous one.\n\ninitial_choice = random.choice(doors)\n\n\n\n\n\n\n\n\n\n\n3. The host opens another door.\n\n\n\n\n\nBased on the door with car and our inital choice, the host chooses a door without car to open. This door is denoted by door_host_open.\nThere are two possibility here:\n\nIf we haapen to pick the door with car, the host will randomly open one of the other two doors, since neither of them has car inside. In other words, we remove door_with_car from doors, and randomly pick one from the rest.\nIf we didn’t pick the door with car, the car is in one of the other two doors, and the host has to open the other door. In other words, this door is the door that is neither door_with_car nor initial_choice.\n\nThe above analysis can be translated directly into the following code.\n\nrest_doors = doors[:]\nif door_with_car == initial_choice:\n    rest_doors.remove(door_with_car)\n    door_host_open = random.choice(rest_doors)\nelif door_with_car != initial_choice:\n    rest_doors.remove(door_with_car)\n    rest_doors.remove(initial_choice)\n    door_host_open = random.choice(rest_doors)\n\nNote that in this part, we directly remove elements from doors. Since we don’t want to alter the original variable doors, and also .remove() works in-place, we make a copy of doors and call it rest_doors for us to remove doors.\nThe code [:] is used to make copies of list. This may be the fastest way to copy plain list in Python.\n\n\n\n\n\n\n\n\n\n4. Check the result.\n\n\n\n\n\nAfter the host opens door_host_open, two doors are left: our initial choice and the door unopened. The door unopened is actually the door that is neither our initial choice or the door host opens. It is the only element in tmpdoors after removing initial_choice and door_host_open. So we could directly get it by calling index 0. The code is as follows. Note that we make another copy of doors at the beginning due to the same reason as the previous step.\n\ntmpdoors = doors[:]\ntmpdoors.remove(door_host_open)\ntmpdoors.remove(initial_choice)\ndoor_unopened = tmpdoors[0]\n\nThen we could start the check the result.\n\nIf door_with_car equals initial_choice, remaining with the initial choice wins.\nIf door_with_car equals door_unopened, switching to the new door wins. We could update the result dictionary accordingly.\n\n\nif door_with_car == initial_choice:\n    winner = 'remain'\nelif door_with_car == door_unopened:\n    winner = 'switch'\n\nresults[winner] = results[winner] + 1\n\n\n\n\n\n\n\n\n\n\nPut things together\n\n\n\n\n\nWe now put the above steps together.\n\nimport random\ndoors = [1, 2, 3]\nresults = {'remain': 0, 'switch': 0}\n\ndoor_with_car = random.choice(doors)\ninitial_choice = random.choice(doors)\n\nrest_doors = doors[:]\nif door_with_car == initial_choice:\n    rest_doors.remove(door_with_car)\n    door_host_open = random.choice(rest_doors)\nelif door_with_car != initial_choice:\n    rest_doors.remove(door_with_car)\n    rest_doors.remove(initial_choice)\n    door_host_open = random.choice(rest_doors)\n\ntmpdoors = doors[:]\ntmpdoors.remove(door_host_open)\ntmpdoors.remove(initial_choice)\ndoor_unopened = tmpdoors[0]\n\nif door_with_car == initial_choice:\n    winner = 'remain'\nelif door_with_car == door_unopened:\n    winner = 'switch'\n\nresults[winner] = results[winner] + 1\n\nThe code can be simplified in multiple ways. However here I would like to show how to translate something directly into codes. So I will just keep it as it is.\n\n\n\n\n\n\n\n\n\nWrapped in a function\n\n\n\n\n\nThe above game process can be wrapped in a function.\n\nimport random\n\ndef MontyHall():\n    doors = [1, 2, 3]\n\n    door_with_car = random.choice(doors)\n    initial_choice = random.choice(doors)\n\n    rest_doors = doors[:]\n    if door_with_car == initial_choice:\n        rest_doors.remove(door_with_car)\n        door_host_open = random.choice(rest_doors)\n    elif door_with_car != initial_choice:\n        rest_doors.remove(door_with_car)\n        rest_doors.remove(initial_choice)\n        door_host_open = random.choice(rest_doors)\n\n    tmpdoors = doors[:]\n    tmpdoors.remove(door_host_open)\n    tmpdoors.remove(initial_choice)\n    door_unopened = tmpdoors[0]\n\n    if door_with_car == initial_choice:\n        winner = 'remain'\n    elif door_with_car == door_unopened:\n        winner = 'switch'\n    return winner\n\n\n\n\nNow we may play the game by calling the function MontyHall(). The return value is the winner, which can be used to update results.\n\nresults = {'remain': 0, 'switch': 0}\nwinner = MontyHall()\nresults[winner] = results[winner] + 1\n\nThen we may play the game multiple times, and see which strategy wins more. The following is the result of 100 games.\n\nresults = {'remain': 0, 'switch': 0}\n\nfor i in range(100):\n    winner = MontyHall()\n    results[winner] = results[winner] + 1\n\nresults\n\n{'remain': 31, 'switch': 69}\n\n\nFrom this result, you may guess that switch might be the better strategy.\n\n\n2.7.2 N-door Monty Hall problem\nThe Monty Hall problem can be modified to N doors. The host will open N-2 doors which don’t have the car behind, and only leave one door left for us to choose. What will you choose?\nWe only need to modify our codes a little bit for the change. You may bring the idea “there are N doors” to the process mentioned above to see what should be modified. However when writing the code, you may still set N=3 and change it later after you finish.\n\n\n\n\n\n\n1. Change doors\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2. The host opens multiple doors\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3. Remove multiple door_host_open\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPut things together\n\n\n\n\n\n\n\n\n\n\nNow we can start to play the game. We may test our code by using the default N which is 3.\n\nresults = {'remain': 0, 'switch': 0}\n\nfor i in range(100):\n    winner = MontyHall()\n    results[winner] = results[winner] + 1\n\nresults\n\n{'remain': 34, 'switch': 66}\nYou will see that we get a similar result as our previous version.\nNow we will try 10-door version.\n\nresults = {'remain': 0, 'switch': 0}\n\nfor i in range(100):\n    winner = MontyHall(10)\n    results[winner] = results[winner] + 1\n\nresults\n\n{'remain': 9, 'switch': 91}\nThe result also shows that switch is a better strategy. This is the simulation approach for this classic problem. You may compare it with theorical calculations using Probability theory.\n\n\n2.7.3 Color the Gnomic data\nWe can use ASCII color codes in the string to change the color of strings. As an example, \\033[91m is for red and \\033[94m is for blue. See the following example.\n\nprint('\\033[91m'+'red'+'\\033[92m'+'green'+'\\033[94m'+'blue'+'\\033[93m'+'yellow')\n\nThis example works in IPython console or Jupyter notebook.\nConsider an (incomplete) Gnomic data given below which is represented by a long sequence of A, C, T and G. Please color it using ASCII color codes.\n\ngnomicdata = 'TCGATCTCTTGTAGATCTGTTCTCTAAACGAACTTTAAAATCTGTGTGGCTGTCACTCGG'\\\n             'CTGCATGCTTAGTGCACTCACGCAGTATAATTAATAACTAATTACTGTCGTTGACAGGAC'\\\n             'ACGAGTAACTCGTCTATCTTCTGCAGGCTGCTTACGGTTTCGTCCGTGTTGCAGCCGATC'\\\n             'ATCAGCACATCTAGGTTTTGTCCGGGTGTGACCGAAAGGTAAGATGGAGAGCCTTGTCCC'\\\n             'TGGTTTCAACGAGAAAACACACGTCCAACTCAGTTTGCCTGTTTTACAGGTTCGCGACGT'\\\n             'GCTCGTACGTGGCTTTGGAGACTCCGTGGAGGAGGTCTTATCAGAGGCACGTCAACATCT'\\\n             'TAAAGATGGCACTTGTGGCTTAGTAGAAGTTGAAAAAGGCGTTTTGCCTCAACTTGAACA'\\\n             'GCCCTATGTGTTCATCAAACGTTCGGATGCTCGAACTGCACCTCATGGTCATGTTATGGT'\\\n             'TGAGCTGGTAGCAGAACTCGAAGGCATTCAGTACGGTCGTAGTGGTGAGACACTTGGTGT'\\\n             'CCTTGTCCCTCATGTGGGCGAAATACCAGTGGCTTACCGCAAGGTTCTTCTTCGTAAGAA'\\\n             'CGGTAATAAAGGAGCTGGTGGCCATAGTTACGGCGCCGATCTAAAGTCATTTGACTTAGG'\\\n             'CGACGAGCTTGGCACTGATCCTTATGAAGATTTTCAAGAAAACTGGAACACTAAACATAG'\n\nThe way to color A as a red A is to change the character into \\033[91mA. Then using in IPython console or Jupyter notebook after you print it, you can see a red A. Therefore the core idea to solve this problem is to replace A in the string by \\033[91mA, etc..\nThere are multiple ways to implement this idea.\n\n\n\n\n\n\nif-elif-else\n\n\n\n\n\nWe loop through the whole string. Every time when we get an A, we replace it with \\033[91mA. The same applies to C, T and G.\nTo implement this idea, we actually make another list newlist. Every time we read A from gnomicdata, we add 033[91mA to the newlist. Then at the end we could combine all strings in newlist to get the string we need.\nHere is the code.\n\nnewlist = []\nfor letter in gnomicdata:\n    if letter == 'A':\n        newlist.append('\\033[91mA')\n    elif letter == 'C':\n        newlist.append('\\033[92mC')\n    elif letter == 'T':\n        newlist.append('\\033[93mT')\n    elif letter == 'G':\n        newlist.append('\\033[94mG')\ngnomicstring = ''.join(newlist)\n\n\n\n\n\n\n\n\n\n\nUpgrade using dict\n\n\n\n\n\nIn the previous method, the big if...elif... doesn’t look very good. We could use dict to simplify the code.\nThe key idea of the if...elif... statement is to make a relation between A and \\033[91mA, etc.. This is exactly what a dict can do.\nHere is the sample code.\n\ncolor_pattern = {\n    'A': '\\033[91mA',\n    'C': '\\033[92mC',\n    'T': '\\033[93mT',\n    'G': '\\033[94mG',\n}\n\nnewlist = []\nfor letter in gnomicdata:\n    newlist.append(color_pattern[letter])\ngnomicstring = ''.join(newlist)\n\n\n\n\n\n\n\n\n\n\nUpgrade using list comprehension\n\n\n\n\n\nIn the previous method, there is a new list, for...list.append() structure. This is exactly what list compreshension can do.\nHere is the sample code.\n\ncolor_pattern = {\n    'A': '\\033[91mA',\n    'C': '\\033[92mC',\n    'T': '\\033[93mT',\n    'G': '\\033[94mG',\n}\n\ngnomicstring = ''.join([color_pattern[letter] for letter in gnomicdata])\n\nThe last piece of code is the best of the three. On the one side it is more condense and easy to read. On the other side, it is actually split into two pieces explicitly: the sytle part (color_pattern) and the code part (gnomicstring). The code part only controls changing colors, but the colors of the letters are controlled by the style part. This split make the code easier to maintain.",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "contents/2/intro.html#exercises",
    "href": "contents/2/intro.html#exercises",
    "title": "2  Python Basics",
    "section": "2.8 Exercises",
    "text": "2.8 Exercises\nMost problems are based on [3], [1], [4], [2] and [5].\n\nExercise 2.1 (Indentation) Please tell the differences between the following codes. Write your answers in the Markdown cells.\n\nfor i in range(5):\n    print('Hello world!')\nprint('Hello world!')\n\n\nfor i in range(5):\n    print('Hello world!')\n    print('Hello world!')\n\n\nfor i in range(5):\nprint('Hello world!')\nprint('Hello world!')\n\n\nfor i in range(5):\n    pass\nprint('Hello world!')\nprint('Hello world!')\n\n\n\nExercise 2.2 (Play with built-in data types) Please first guess the results of all expressions below, and then run them to check your answers.\n\nTrue and True\nTrue or True\nFalse and True\n(1+1&gt;2) or (1-1&lt;1)\n\n\n\nExercise 2.3 (== vs is) Please explain what happens below.\n\na = 1\nb = 1.0\ntype(a)\n\nint\n\n\n\ntype(b)\n\nfloat\n\n\n\na == b\n\nTrue\n\n\n\na is b\n\nFalse\n\n\n\n\nExercise 2.4 (Play with strings)  \n\nPlease use .format() to generate the following sentences.\n\n\n\"The answer to this question is 1. If you got 2, you are wrong.\"\n\"The answer to this question is 2. If you got x, you are wrong.\"\n\"The answer to this question is True. If you got 23, you are wrong.\"\n\"The answer to this question is 4. If you got 32, you are wrong.\"\n\n\nPlease use .format() and for loop to generate the following sentence and replace the number 1 inside with all positive odd numbers under 10.\n\n\n\"I like 1 most among all numbers.\"\n\n\n\nExercise 2.5 (Toss a coin)  \n\nPlease write a function tossacoin() to simulate tossing a coin. The output is H or T, and each call of the function has a 50/50 chance of getting H or T. Please use the following code to get a random number between 0 and 1.\n\n\nimport numpy as np\nnp.random.rand()\n\n\nPlease simulate tossing a coin 20 times, and print out the results.\nThe coin might be uneven. In this case the probability to get H is no longer 0.5. We would like to use an argument p to represent the probability of getting H. Please upgrade your function tossacoin() to be compatible with uneven coins. Then please simulate tossing a coin (with p=0.1, for example) 20 times, and print out the results.\nTossing a coin 100 times, and record the results in a list.\n\n\n\nExercise 2.6 (split and join)  \n\nPlease get the list of words wordlist of the following sentence.\n\n\nsentence = 'This is an example of a sentence that I expect you to split.'\n\n\nPlease combine the wordlist gotten from part 1 to get a string newsentence, where all spaces are replaced by \\n.\n\n\n\nExercise 2.7 (List reference) Please finish the following tasks.\n\nGiven the list a, make a new reference b to a. Update the first entry in b to be 0. What happened to the first entry in a? Explain your answer in a text block.\nGiven the list a, make a new copy b of the list a using the function list. Update the first entry in b to be 0. What happened to the first entry in a? Explain your answer in a text block.\n\n\n\nExercise 2.8 Please tell the differences of the following objects.\n\n[1, 2, 3, 4, 5, 6]\n[[1, 2], [3, 4], [5, 6]]\n{1: 2, 3: 4, 5: 6}\n{1: [2], 3: [4], 5: [6]}\n[{1: 2}, {3: 4}, {5: 6}]\n\n\n\nExercise 2.9 (List comprehension)  \n\nGiven a list of numbers, use list comprehension to remove all odd numbers from the list:\n\n\nnumbers = [3,5,45,97,32,22,10,19,39,43]\n\n\nUse list comprehension to find all of the numbers from 1-1000 that are divisible by 7.\nUse list comprehension to get the index and the value as a tuple for items in the list ['hi', 4, 8.99, 'apple', ('t,b', 'n')]. Result would look like [(index, value), (index, value), ...].\nUse list comprehension to find the common numbers in two lists (without using a tuple or set) list_a = [1, 2, 3, 4], list_b = [2, 3, 4, 5].\n\n\n\nExercise 2.10  \n\nGiven a string, use list comprehension to count the number of spaces in it.\nWrite a function that counts the number of spaces in a string.\n\n\n\nExercise 2.11 (Probability) Compute the probability that two people out of 23 share the same birthday. The math formula for this is \\[1-\\frac{365!/(365-23)!}{365^{23}}=1-\\frac{365}{365}\\cdot\\frac{365-1}{365}\\cdot\\frac{365-2}{365}\\cdot\\ldots\\cdot\\frac{365-22}{365}.\\]\n\nTo directly use the formula we have to use a high performance math package, e.g. math. Please use math.factorial() to compute the left hand side of the above formula. You should import math to use the function since it is in the math package.\nPlease use the right hand side of the above formula to compute the probability using the following steps.\n\nPlease use the list comprehension to create a list \\(\\left[\\frac{365}{365},\\frac{365-1}{365},\\frac{365-2}{365},\\ldots,\\frac{365-22}{365}\\right]\\).\nUse math.prod() to compute the product of elements of the above list. You should import math to use the function since it is in the math package.\nCompute the probability by finishing the formula.\n\nPlease use time to test which method mentioned above is faster.\n\n\n\nExercise 2.12 (Determine the indefinite article) Please finish the following tasks.\n\nPlease construct a list aeiou that contains all vowels.\nGiven a word word, we would like to find the indefinite article article before word. (Hint: the article should be an if the first character of word is a vowel, and a if not.)\n\n\n\n\nClick for Hint.\n\n\nSolution. Consider in, .lower() and if structure.\n\n\n\nExercise 2.13 (File names)  \n\nPlease use Python code to generate the following list of file names: file0.txt, file1.txt, file2.txt, … file9.txt.\nPlease use Python code to generate the following list of file names: file0.txt, file1.txt, file2.txt, … file10.txt, file11.txt, …, file99.txt, file100.txt.\nPlease use Python code to generate the following list of file names: file000.txt, file001.txt, file002.txt, … file100.txt. You may consider .zfill() to fill the zeros.\n\n\n\nExercise 2.14 (Datetime and files names) We would like to write a program to quickly generate many files. (For example, we want to take random samples multiple times and we want to keep all our samples. Another example is to generate AI pictures.) Every time we run the code, many files will be generated. We hope to store all files generated and organize them in a neat way. To achieve this, one way is to create a subfolder for each run and store all files generated during that run in the particular subfolder. Since we would like to make it fast, the real point of this task is to find a way to automatically generate the filenames for the files generated and the folder names for the subfolders generated.\nOne way to automatically generate file names and folder names is to use the date and the time when the code is run. Please check datetime package for getting and formatting date/time, and os packages for playing with files and folders. Here are some suggested steps.\n\nUse datetime packages to get the current date and time. You may read this article to learn how to use datetime package.\nUse the current date and time to form two strings currentdate and currenttime.\nAssume that we would like to generate 100 files. Then please generate a list of strings that each one is string that represents a path with folder currentdate, subfolder currenttime and file name X.txt where X is a number from 0 to 99.\n\n\n\n\nClick for Hint.\n\nYou may try datetime.datetime.now() and .strftime() method for the datetime object.\n\n\nExercise 2.15 (Caesar cipher) In cryptography, a Caesar cipher is one of the simplest and most widely known encryption techniques. It is a type of substitution cipher in which each letter in the plaintext is replaced by a letter some fixed number of positions down the alphabet. For example, with a left shift of 3, D would be replaced by A, E would become B, and so on. The method is named after Julius Caesar, who used it in his private correspondence.\nPlease write two functions to implement Caesar cipher and decipher. To make things easier, we implement the following two rules.\n\nSpaces, ,, numbers or other non-alphabic letters will NOT be changed.\nUpper case and lower case will NOT be changed.\n\nNote that you may add the number of shifts as a parameter in your function.\n\n\nExercise 2.16 (sorted) Please read through the Key Funtions section in this article, and sort the following two lists.\n\nSort list1 = [[11,2,3], [2, 3, 1], [5,-1, 2], [2, 3,-8]] according to the sum of each list.\nSort list2 = [{'a': 1, 'b': 2}, {'a': 3, 'b': 4},{'a': 5, 'b': 2}] according to the b value of each dictionary.\n\n\n\nExercise 2.17 (Fantasy Game Inventory) You are creating a fantasy video game. The data structure to model the player’s inventory will be a dictionary where the keys are string values describing the item in the inventory and the value is an integer value detailing how many of that item the player has. For example, the dictionary value {'rope': 1, 'torch': 6, 'gold coin': 42, 'dagger': 1, 'arrow': 12} means the player has 1 rope, 6 torches, 42 gold coins, and so on.\n\nWrite some code to take any possible inventory and display it like the following. Note that the order of items doesn’t matter. The purpose of this exercise is to read information from a dict and translate it into a format you need.\n\n\nInventory:\n12 arrow\n42 gold coin\n1 rope\n6 torch\n1 dagger\nTotal number of items: 62\n\n\nWrite a function named displayInventory() that would take any possible inventory and display it in the above way.\n\n\n\nExercise 2.18 (N-door Monty Hall problem) Please finish the function MontyHall() for the N-door Monty Hall problem described in Section 2.7.2.\n\n\n\n\n\n[1] Youens-Clark, K. (2020). Tiny python projects. Manning Publications.\n\n\n[2] McKinney, W. (2017). Python for data analysis: Data wrangling with pandas, NumPy, and IPython. O’Reilly Media.\n\n\n[3] Shaw, Z. A. (2017). Learn python 3 the hard way. Addison Wesley.\n\n\n[4] Sweigart, A. (2020). Automate the boring stuff with python, 2nd edition practical programming for total beginners: Practical programming for total beginners. No Starch Press.\n\n\n[5] Klosterman, S. (2021). Data science projects with python: A case study approach to gaining valuable insights from real data with machine learning. Packt Publishing, Limited.",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "contents/3/intro.html#basics",
    "href": "contents/3/intro.html#basics",
    "title": "3  Package: numpy",
    "section": "3.1 Basics",
    "text": "3.1 Basics\nThe core data structure for numpy is numpy.ndarray. It is called NumPy Nd array. In most cases we will use its alias array for simplicity. You may treat it as a generalized version of list. However it can do so much more than the built-in list.\nTo use numpy, we just import it. In most cases you would like to use the alias np.\n\nimport numpy as np\n\n\n\n3.1.1 Understanding ndarray\nThe simplest way to look at an ndarray is to think it as lists of list. Here are some examples.\n\nThis is an example of a 1d array. Note that it can be treated as a list. You may get access to its entries by 1 index, e.g. a[0]. This means that: we have a list, and we want to get the 0th element in the list.\n\n\na = np.array([1, 2])\na\n\narray([1, 2])\n\n\n\nThis is an example of a 2d array. Note that it can be treated as a list of lists. You may get access to its entries by 2 indexes, e.g. b[0, 0]. This means that: we have a list of lists. We first get the 0th element (which is a list), and then get the 0th element from this 0th list (which is a number).\n\n\nb = np.array([[1, 2], [3,4]])\nb\n\narray([[1, 2],\n       [3, 4]])\n\n\n\nThis is an example of a 3d array. Note that it can be treated as a list of lists of lists. You may get access to its entries by 3 indexes, e.g. c[0, 0, 0]. This means that: we have a list of lists of lists. We first get the 0th element (which is a list of lists), and then get the 0th element (which is a list) from this 0th list of lists, and then get the 0th element (which is a number) from the previous list.\n\n\nc = np.array([[[1, 2], [3,4]], [[1, 2], [3,4]]])\nc\n\narray([[[1, 2],\n        [3, 4]],\n\n       [[1, 2],\n        [3, 4]]])\n\n\n\n3.1.1.1 The dimension of ndarray\nThere is a very confusing terminology for ndarray: dimension. The actual word using in documents is actually axes. It refers to the number of coordinates required to describe the location.\nIn the previous example, a is a 1d array since you only need 1 index to get entries, b is a 2d array since you need 2 indexes to get entries, and c is a 3d array since you need 3 indexes to get entries.\nWe could use .ndim to check the dimension of a ndarray.\n\nd = np.array([[1, 2, 3], [4, 5, 6]])\nd.ndim\n\n2\n\n\n\n\n\n\n\n\nComparing to Linear algebras\n\n\n\nThe dimension of an ndarray and the dimenion of a vector in Linear algebras are totally different. In this example, as a ndarray, a=np.array([1, 2]) is a 1d ndarray, of length 2. As a vector, it is a 2d vector.\n\n\nTo describe the length of each axes, we could use .shape. It will tells us the length of each axis. In other words, it tells us the maximal index of each axis.\n\nExample 3.1  \n\nd = np.array([[1, 2, 3], [4, 5, 6]])\nd.shape\n\n(2, 3)\n\n\nThe shape of d is (2, 3), which means that the length of axis 0 is 2 and the length of axis 1 is 3.\n\nAxis 0 is the vertical axis, and its index is corresponding to rows. The length of axis 0 is actually the number of rows.\nAxis 1 is the horizental axis, and its index is corresponding to columns. The length of axis 1 is actually the number of columns.\n\nSo a 2d array can be treated as a matrix, and the shape being (2, 3) means that the matrix has 2 rows and 3 columns.\n\n\n\n\n\n\n\nCaution\n\n\n\n.ndim and .shape are not methods. There is no () behind.\n\n\n\n\n3.1.1.2 Moving along axis\nA lot of numpy methods has an argument axis=, which let you to specify performing the action along which axis. You may understand this “along axis” in the following way. axis=i means that when we perform the action, we keep all other indexes the same, only changing the index on axis i.\nFor example, b.sum(axis=0) means that we want to add all entries along axis 0. So we start from a certain entry, keeping all other index the same when changing index on axis 0 only, and add all these entries together. Since axis 0 is corresponding to rows index, only changing row index means we are moving vertically. So if b is a 2d array, b.sum(axis=0) means we are adding all column together.\nWe will do more examples later this section.\n\n\n\n3.1.2 Create ndarrays\nThere are many ways to create ndarrays. We list some basic ways below.\n\n\n\n\n\n\nConverting from a Python list\n\n\n\n\n\nYou may apply np.array() to a list to convert it into a ndarray.\n\nA list of numbers will create a 1d ndarray.\nA list of lists will create a 2d ndarray.\nFurther nested lists will create a higher-dimensional ndarray.\n\nAll arrays in the previous sections are created in this way.\n\n\n\n\n\n\n\n\n\nIntrinsic numpy array creation functions\n\n\n\n\n\nHere is an incomplete list of such functions.\n\nnp.ones() and np.zeros()\n\nBoth of them will create ndarrays with the specified shape.\n\nnp.eye() and np.diag()\n\nBoth will create 2d array. So they can also be treated as creating matrices.\n\nnp.arange(start, stop, step)\n\nIt will only create 1d array, which start from start to stop with the step size step.\nstart is by default 0 and step is by default 1.\nIn most cases the stop is NOT included, which is similar to Python list.\nThe syntax is very similar to range(). The main difference between them is the object type of the output.\n\nnp.linspace(start, stop, num)\n\nIt will only create 1d array, which starts from start, stops at stop with totally num of points in the array, each of which are equally spread.\nstart and stop are always INCLUDED in the array.\n\nnp.random.rand() and many other functions in np.random package.\n\nThese functions are straightforward. You may go to the official documents for more details. For example this is the page for np.arange(). You may find other functions on the left navigation bar, or you may use the search function to locate them.\n\n\n\n\n\n\n\n\n\nReading from files\n\n\n\n\n\nnumpy provides several functions to read and write files. We discuss the most commonly used one: np.genfromtxt().\nnp.genfromtxt() is used to load data from a text file, with missing values handled as specified. The idea of this function is to first read the file as a string and then parse the structure of the string, automatically.\nThere are many arguments. Here are a few commonly used. For more details please read the official tutorial.\n\ndtype: Data type of the resulting array. If None, the dtypes will be determined by the contents of each column, individually.\ndelimiter: The string used to separate values. By default, any consecutive whitespaces act as delimiter.\nusecols: Which columns to read, with 0 being the first.\nencoding: This is used to decode the inputfile. The default setting for encoding is bytes. If it is set to None the system default is used. Please pay attention to the differences between these two.\n\nNote that when choosing dtype, if the type is NOT a single type, the output will be a 1d array with each entry being a tuple. If it is a single type, the output will be a 2d array. Please see the following example.\n\nimport numpy as np\n\nurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\niris_1d = np.genfromtxt(url, delimiter=',', dtype=None, encoding=None)\niris_2d = np.genfromtxt(url, delimiter=',', dtype='float', encoding=None)\niris_2d_str = np.genfromtxt(url, delimiter=',', dtype='str', encoding=None)\niris_1d[:10]\n\narray([(5.1, 3.5, 1.4, 0.2, 'Iris-setosa'),\n       (4.9, 3. , 1.4, 0.2, 'Iris-setosa'),\n       (4.7, 3.2, 1.3, 0.2, 'Iris-setosa'),\n       (4.6, 3.1, 1.5, 0.2, 'Iris-setosa'),\n       (5. , 3.6, 1.4, 0.2, 'Iris-setosa'),\n       (5.4, 3.9, 1.7, 0.4, 'Iris-setosa'),\n       (4.6, 3.4, 1.4, 0.3, 'Iris-setosa'),\n       (5. , 3.4, 1.5, 0.2, 'Iris-setosa'),\n       (4.4, 2.9, 1.4, 0.2, 'Iris-setosa'),\n       (4.9, 3.1, 1.5, 0.1, 'Iris-setosa')],\n      dtype=[('f0', '&lt;f8'), ('f1', '&lt;f8'), ('f2', '&lt;f8'), ('f3', '&lt;f8'), ('f4', '&lt;U15')])\n\n\n\niris_2d[:10]\n\narray([[5.1, 3.5, 1.4, 0.2, nan],\n       [4.9, 3. , 1.4, 0.2, nan],\n       [4.7, 3.2, 1.3, 0.2, nan],\n       [4.6, 3.1, 1.5, 0.2, nan],\n       [5. , 3.6, 1.4, 0.2, nan],\n       [5.4, 3.9, 1.7, 0.4, nan],\n       [4.6, 3.4, 1.4, 0.3, nan],\n       [5. , 3.4, 1.5, 0.2, nan],\n       [4.4, 2.9, 1.4, 0.2, nan],\n       [4.9, 3.1, 1.5, 0.1, nan]])\n\n\n\niris_2d_str[:10]\n\narray([['5.1', '3.5', '1.4', '0.2', 'Iris-setosa'],\n       ['4.9', '3.0', '1.4', '0.2', 'Iris-setosa'],\n       ['4.7', '3.2', '1.3', '0.2', 'Iris-setosa'],\n       ['4.6', '3.1', '1.5', '0.2', 'Iris-setosa'],\n       ['5.0', '3.6', '1.4', '0.2', 'Iris-setosa'],\n       ['5.4', '3.9', '1.7', '0.4', 'Iris-setosa'],\n       ['4.6', '3.4', '1.4', '0.3', 'Iris-setosa'],\n       ['5.0', '3.4', '1.5', '0.2', 'Iris-setosa'],\n       ['4.4', '2.9', '1.4', '0.2', 'Iris-setosa'],\n       ['4.9', '3.1', '1.5', '0.1', 'Iris-setosa']], dtype='&lt;U15')\n\n\nWe only show the first 10 rows to save some display room.\nYou may also download the datafile from the url provided in the code. The file can be opened with any editor. It is displayed below for reference.\n\n\nb'5.1,3.5,1.4,0.2,Iris-setosa\\n4.9,3.0,1.4,0.2,Iris-setosa\\n4.7,3.2,1.3,0.2,Iris-setosa\\n4.6,3.1,1.5,0.2,Iris-setosa\\n5.0,3.6,1.4,0.2,Iris-setosa\\n5.4,3.9,1.7,0.4,Iris-setosa\\n4.6,3.4,1.4,0.3,Iris-setosa\\n5.0,3.4,1.5,0.2,Iris-setosa\\n4.4,2.9,1.4,0.2,Iris-setosa\\n4.9,3.1,1.5,0.1,Iris-setosa\\n5.4,3.7,1.5,0.2,Iris-setosa\\n4.8,3.4,1.6,0.2,Iris-setosa\\n4.8,3.0,1.4,0.1,Iris-setosa\\n4.3,3.0,1.1,0.1,Iris-setosa\\n5.8,4.0,1.2,0.2,Iris-setosa\\n5.7,4.4,1.5,0.4,Iris-setosa\\n5.4,3.9,1.3,0.4,Iris-setosa\\n5.1,3.5,1.4,0.3,Iris-setosa\\n5.7,3.8,1.7,0.3,Iris-setosa\\n5.1,3.8,1.5,0.3,Iris-setosa\\n5.4,3.4,1.7,0.2,Iris-setosa\\n5.1,3.7,1.5,0.4,Iris-setosa\\n4.6,3.6,1.0,0.2,Iris-setosa\\n5.1,3.3,1.7,0.5,Iris-setosa\\n4.8,3.4,1.9,0.2,Iris-setosa\\n5.0,3.0,1.6,0.2,Iris-setosa\\n5.0,3.4,1.6,0.4,Iris-setosa\\n5.2,3.5,1.5,0.2,Iris-setosa\\n5.2,3.4,1.4,0.2,Iris-setosa\\n4.7,3.2,1.6,0.2,Iris-setosa\\n4.8,3.1,1.6,0.2,Iris-setosa\\n5.4,3.4,1.5,0.4,Iris-setosa\\n5.2,4.1,1.5,0.1,Iris-setosa\\n5.5,4.2,1.4,0.2,Iris-setosa\\n4.9,3.1,1.5,0.1,Iris-setosa\\n5.0,3.2,1.2,0.2,Iris-setosa\\n5.5,3.5,1.3,0.2,Iris-setosa\\n4.9,3.1,1.5,0.1,Iris-setosa\\n4.4,3.0,1.3,0.2,Iris-setosa\\n5.1,3.4,1.5,0.2,Iris-setosa\\n5.0,3.5,1.3,0.3,Iris-setosa\\n4.5,2.3,1.3,0.3,Iris-setosa\\n4.4,3.2,1.3,0.2,Iris-setosa\\n5.0,3.5,1.6,0.6,Iris-setosa\\n5.1,3.8,1.9,0.4,Iris-setosa\\n4.8,3.0,1.4,0.3,Iris-setosa\\n5.1,3.8,1.6,0.2,Iris-setosa\\n4.6,3.2,1.4,0.2,Iris-setosa\\n5.3,3.7,1.5,0.2,Iris-setosa\\n5.0,3.3,1.4,0.2,Iris-setosa\\n7.0,3.2,4.7,1.4,Iris-versicolor\\n6.4,3.2,4.5,1.5,Iris-versicolor\\n6.9,3.1,4.9,1.5,Iris-versicolor\\n5.5,2.3,4.0,1.3,Iris-versicolor\\n6.5,2.8,4.6,1.5,Iris-versicolor\\n5.7,2.8,4.5,1.3,Iris-versicolor\\n6.3,3.3,4.7,1.6,Iris-versicolor\\n4.9,2.4,3.3,1.0,Iris-versicolor\\n6.6,2.9,4.6,1.3,Iris-versicolor\\n5.2,2.7,3.9,1.4,Iris-versicolor\\n5.0,2.0,3.5,1.0,Iris-versicolor\\n5.9,3.0,4.2,1.5,Iris-versicolor\\n6.0,2.2,4.0,1.0,Iris-versicolor\\n6.1,2.9,4.7,1.4,Iris-versicolor\\n5.6,2.9,3.6,1.3,Iris-versicolor\\n6.7,3.1,4.4,1.4,Iris-versicolor\\n5.6,3.0,4.5,1.5,Iris-versicolor\\n5.8,2.7,4.1,1.0,Iris-versicolor\\n6.2,2.2,4.5,1.5,Iris-versicolor\\n5.6,2.5,3.9,1.1,Iris-versicolor\\n5.9,3.2,4.8,1.8,Iris-versicolor\\n6.1,2.8,4.0,1.3,Iris-versicolor\\n6.3,2.5,4.9,1.5,Iris-versicolor\\n6.1,2.8,4.7,1.2,Iris-versicolor\\n6.4,2.9,4.3,1.3,Iris-versicolor\\n6.6,3.0,4.4,1.4,Iris-versicolor\\n6.8,2.8,4.8,1.4,Iris-versicolor\\n6.7,3.0,5.0,1.7,Iris-versicolor\\n6.0,2.9,4.5,1.5,Iris-versicolor\\n5.7,2.6,3.5,1.0,Iris-versicolor\\n5.5,2.4,3.8,1.1,Iris-versicolor\\n5.5,2.4,3.7,1.0,Iris-versicolor\\n5.8,2.7,3.9,1.2,Iris-versicolor\\n6.0,2.7,5.1,1.6,Iris-versicolor\\n5.4,3.0,4.5,1.5,Iris-versicolor\\n6.0,3.4,4.5,1.6,Iris-versicolor\\n6.7,3.1,4.7,1.5,Iris-versicolor\\n6.3,2.3,4.4,1.3,Iris-versicolor\\n5.6,3.0,4.1,1.3,Iris-versicolor\\n5.5,2.5,4.0,1.3,Iris-versicolor\\n5.5,2.6,4.4,1.2,Iris-versicolor\\n6.1,3.0,4.6,1.4,Iris-versicolor\\n5.8,2.6,4.0,1.2,Iris-versicolor\\n5.0,2.3,3.3,1.0,Iris-versicolor\\n5.6,2.7,4.2,1.3,Iris-versicolor\\n5.7,3.0,4.2,1.2,Iris-versicolor\\n5.7,2.9,4.2,1.3,Iris-versicolor\\n6.2,2.9,4.3,1.3,Iris-versicolor\\n5.1,2.5,3.0,1.1,Iris-versicolor\\n5.7,2.8,4.1,1.3,Iris-versicolor\\n6.3,3.3,6.0,2.5,Iris-virginica\\n5.8,2.7,5.1,1.9,Iris-virginica\\n7.1,3.0,5.9,2.1,Iris-virginica\\n6.3,2.9,5.6,1.8,Iris-virginica\\n6.5,3.0,5.8,2.2,Iris-virginica\\n7.6,3.0,6.6,2.1,Iris-virginica\\n4.9,2.5,4.5,1.7,Iris-virginica\\n7.3,2.9,6.3,1.8,Iris-virginica\\n6.7,2.5,5.8,1.8,Iris-virginica\\n7.2,3.6,6.1,2.5,Iris-virginica\\n6.5,3.2,5.1,2.0,Iris-virginica\\n6.4,2.7,5.3,1.9,Iris-virginica\\n6.8,3.0,5.5,2.1,Iris-virginica\\n5.7,2.5,5.0,2.0,Iris-virginica\\n5.8,2.8,5.1,2.4,Iris-virginica\\n6.4,3.2,5.3,2.3,Iris-virginica\\n6.5,3.0,5.5,1.8,Iris-virginica\\n7.7,3.8,6.7,2.2,Iris-virginica\\n7.7,2.6,6.9,2.3,Iris-virginica\\n6.0,2.2,5.0,1.5,Iris-virginica\\n6.9,3.2,5.7,2.3,Iris-virginica\\n5.6,2.8,4.9,2.0,Iris-virginica\\n7.7,2.8,6.7,2.0,Iris-virginica\\n6.3,2.7,4.9,1.8,Iris-virginica\\n6.7,3.3,5.7,2.1,Iris-virginica\\n7.2,3.2,6.0,1.8,Iris-virginica\\n6.2,2.8,4.8,1.8,Iris-virginica\\n6.1,3.0,4.9,1.8,Iris-virginica\\n6.4,2.8,5.6,2.1,Iris-virginica\\n7.2,3.0,5.8,1.6,Iris-virginica\\n7.4,2.8,6.1,1.9,Iris-virginica\\n7.9,3.8,6.4,2.0,Iris-virginica\\n6.4,2.8,5.6,2.2,Iris-virginica\\n6.3,2.8,5.1,1.5,Iris-virginica\\n6.1,2.6,5.6,1.4,Iris-virginica\\n7.7,3.0,6.1,2.3,Iris-virginica\\n6.3,3.4,5.6,2.4,Iris-virginica\\n6.4,3.1,5.5,1.8,Iris-virginica\\n6.0,3.0,4.8,1.8,Iris-virginica\\n6.9,3.1,5.4,2.1,Iris-virginica\\n6.7,3.1,5.6,2.4,Iris-virginica\\n6.9,3.1,5.1,2.3,Iris-virginica\\n5.8,2.7,5.1,1.9,Iris-virginica\\n6.8,3.2,5.9,2.3,Iris-virginica\\n6.7,3.3,5.7,2.5,Iris-virginica\\n6.7,3.0,5.2,2.3,Iris-virginica\\n6.3,2.5,5.0,1.9,Iris-virginica\\n6.5,3.0,5.2,2.0,Iris-virginica\\n6.2,3.4,5.4,2.3,Iris-virginica\\n5.9,3.0,5.1,1.8,Iris-virginica\\n\\n'\n\n\nThe file can be understood as follows. \\n separates rows and , separates columns. Each row contains five columns, where the last one is definitely a string, and the first four are numeric. Therefore the whole dataset is a mixed type dataset.\n\nIn the first command, dtype=None. Since any types are accepted, it returns an 1d array with each row being a tuple.\nIn the second command, dtype='float'. Then only float data is accepted. Then we have a 2d array with the last column (string data that cannot be tranlated into a float) being np.nan.\nIn the third command, dtype='string'. Then all data are tranlated into strings, and we get a 2d array.\n\n\n\n\n\n\n\n\n\n\n\nChanging the shape of other ndarrays\n\n\n\n\n\nThere are multiple ways to manipulate the shapes of ndarrays. We will only mention some commonly used ones in this section.\n\nnp.concatenate()\n\nnp.concatenate() is used to join a sequence of ndarrays along an existing axis. Therefore the major input arugments including:\n\nA tuple which represents the sequence of ndarrays.\nThe axis for the ndarrays to be concatenated. The default is axis=0.\n\nThe setting for axis is the same as in Section 3.1.1.2. That is, axis=i along the axis i means that all we collect all the entries with the same other indexes and different ith index.\nA quick example is about a 2d ndarrays. When talking about axis=0, we are looking at entries that have the same 1st index and different 0th index. This refers to all the entries in one column. So if we want to do something vertically, we need to set axis=0.\nSimilarly, axis=1 means that we are looking at the entries wich the same 0th index and different 1st index. These are entries in the same row. So axis=1 menas horizontally. Please see the following example.\n\nExample 3.2 (Axis) Given A = np.array([[1,2],[3,4]]) and B = np.array([[5,6],[7,8]]), please use np.concatenate to concatencate these two matrices to get a new matrix, in the order:\n\nA left, B right\n\n\nnp.concatenate((A, B), axis=1)\n\narray([[1, 2, 5, 6],\n       [3, 4, 7, 8]])\n\n\n\nA right, B left\n\n\nnp.concatenate((B, A), axis=1)\n\narray([[5, 6, 1, 2],\n       [7, 8, 3, 4]])\n\n\n\nA up, B down\n\n\nnp.concatenate((A, B), axis=0)\n\narray([[1, 2],\n       [3, 4],\n       [5, 6],\n       [7, 8]])\n\n\n\nA down, B up\n\n\nnp.concatenate((B, A), axis=0)\n\narray([[5, 6],\n       [7, 8],\n       [1, 2],\n       [3, 4]])\n\n\n\n\nReshape\n\nnp.reshape() functions and .reshape() methods are equivalent. They are used to change the shape of the original ndarray. Please see the following example.\n\nA = np.array([[1, 2, 3], [4, 5, 6]])\nA.reshape((6, 1))\n\narray([[1],\n       [2],\n       [3],\n       [4],\n       [5],\n       [6]])\n\n\n\nTranspose\n\nThere are three ways to perform transpose.\n\nnp.transpose() function\n.transpose() method\n.T attribute Please see the following example.\n\n\nA = np.array([[1, 2, 3], [4, 5, 6]])\nA.T\n\narray([[1, 4],\n       [2, 5],\n       [3, 6]])\n\n\nNote that in the third method, .T is NOT a function that there are no () at the end.\n\n\n\n\n\n\n\n\n\nPay attention to the format of inputs\n\n\n\n\n\nPlease be very careful about the format of the input. For example, when you want to specify the dimension of the array, using np.zeros, you need to input a tuple. On the other hand, when using np.random.rand, you just directly input the dimensions one by one.\n\nimport numpy as np\n\nnp.zeros((3, 2))\nnp.random.rand(3, 2)\n\nIn this case, the official documents are always your friend.\n\n\n\n\n\n3.1.3 Mathematical and Statistical Methods\nMany functions performs element-wise operations on data in ndarrays, and supports array broadcasting, type casting, and several other standard features. This type of functions is called a universal function (or ufunc for short).\nWith ufuncs, using ndarrays enables you to express many kinds of data processing tasks as concise array expressions that might otherwise require writing loops. This practice of replacing explicit loops with array expressions is commonly referred to as vectorization.\nPlease see the following example.\n\nExample 3.3  \n\nimport numpy as np\nx = np.linspace(0, 1, 101)\ny = np.sin(x)\nz = y**2 + 2*y-3\n\nThis example defines two functions \\(y=\\sin(x)\\) and \\(z=y^2+2y-3\\). The syntax is very similar to the math language.\n\n\n\n\n\n\n\nCaution\n\n\n\nPlease pay attention to the difference between numpy functions and ndarray methods. numpy functions are functions defined in the numpy package that you use it by applying it to the arguments. ndarray methods are function defined specific for one ndarray, and it is used by calling it after the ndarray with . symbol. In the official documents, a numpy function looks like numpy.XXX() while a ndarray method looks like numpy.ndarray.XXX(). Please see the following example.\n\nnp.amax() is a numpy function. It is used to find the maximum of an array. Assuming a is a np.array, then the syntax is np.amax(a).\n.max() is a np.array method. It is used to find the maximum of an array. Assuming a is a np.array, then the syntax is a.max().\n\n\n\nHere is an incomplete list of ufuncs. Some functions come with brief introductions. For more details please read the official documents.\n\nnumpy functions\n\n+, -, *, /, **, etc..\n&gt;, &lt;, &gt;=, &lt;=, ==, !=, etc..\nnp.sin(), np.exp(), np.sqrt(), etc..\nnp.dot(): Matrix multiplication.\nnp.unique(): Find out all unique values from the array.\nnp.maximum() and np.minimum(): These are used to find the maximum/minimum between two np.array.\nnp.argmax() and np.argmin(): Return the indices of the maximum/minimum values. There are also .argmin() and .argmax() methods.\nnp.sort(): Sort the array. There is also a .sort() method.\n\n\nndarray methods\n\n.mean(), .sum(), .std(), .var(): Array methods that are used to compute corresponding properties of the array.\n.cumsum(): Return the cumulative sum of the elements along a given axis.\n.max() and .min(): This is used to find the maximal/minimal entry of one np.array.\n\n.argmax() and .argmin(): Return the indices of the maximum/minimum values. There are also np.argmax() and np.argmin() functions.\n.sort(): Sort the array. There is also a np.sort() function.\n\n\n\n\n\n\n\n\nTip\n\n\n\nDon’t forget that most functions and methods have axis arguments to specify which axis you want to move along with.\n\n\n\n3.1.3.1 Broadcasting\nAlthough most numpy functions and ndarray methods are computing entry-wise, when we perform binary operations, the size of the two arrays don’t have to be the same. If they are not the same, the Broadcasting Rule applies, and some entries will be filled automatically by repeating themselves.\n\n\n\n\n\n\nThe Broadcasting Rule\n\n\n\nTwo arrays are compatible for broadcasting if for each dimension the axis lengths match or if either of the lengths is 1. Broadcasting is then performed over the missing or length 1 dimensions.\n\n\nPlease see the following examples.\n\nimport numpy as np\na = np.array([1, 2])\na + 1\n\narray([2, 3])\n\n\n\nb = np.array([[3, 4], [5, 6]])\na + b\n\narray([[4, 6],\n       [6, 8]])\n\n\n\nc = np.array([[1], [2]])\nb + c\n\narray([[4, 5],\n       [7, 8]])",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Package: `numpy`</span>"
    ]
  },
  {
    "objectID": "contents/3/intro.html#indexing",
    "href": "contents/3/intro.html#indexing",
    "title": "3  Package: numpy",
    "section": "3.2 Indexing",
    "text": "3.2 Indexing\n\n3.2.1 Basic indexing\nBasic indexing is very similar to indexing and slicing for list. Please see the following examples.\n\nExample 3.4  \n\nimport numpy as np\narr = np.arange(10)\narr\n\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n\n\narr[5]\n\n5\n\n\n\narr[5:8]\n\narray([5, 6, 7])\n\n\n\narr[5:8:2]\n\narray([5, 7])\n\n\n\narr[8:5:-1]\n\narray([8, 7, 6])\n\n\n\narr[::-1]\n\narray([9, 8, 7, 6, 5, 4, 3, 2, 1, 0])\n\n\n\narr[5:8] = 12\narr\n\narray([ 0,  1,  2,  3,  4, 12, 12, 12,  8,  9])\n\n\n\nTo do slicing in higher dimensional case, you may directly work with it with multiindexes.\n\nExample 3.5  \n\nimport numpy as np\narr3d = np.arange(12).reshape(2, 2, 3)\narr3d\n\narray([[[ 0,  1,  2],\n        [ 3,  4,  5]],\n\n       [[ 6,  7,  8],\n        [ 9, 10, 11]]])\n\n\n\narr3d[0, 1, 2]\n\n5\n\n\n\narr3d[:, 0: 2, 1]\n\narray([[ 1,  4],\n       [ 7, 10]])\n\n\n\narr3d[:, 0: 2, 1:2]\n\narray([[[ 1],\n        [ 4]],\n\n       [[ 7],\n        [10]]])\n\n\n\n\n\n\n\n\n\nNested indexes\n\n\n\nIn theory, since ndarrys can be treated as lists of list, it is possible to use nested index to get access to entries. For example, assuming a is a 2d ndarray, we might use a[0][0] to get access to a[0, 0]. This is a legal syntax.\nHowever it is almost required NOT to do so. The main reason is due to the copy/view rules that will be described later. Nested indexes might cause many confusions and it is highly possible to casue unexpected errors.\n\n\n\n\n3.2.2 Advanced Indexing\nAdvanced indexing is triggered when the selection object satisfies some conditions. The concrete definition is technical and abstract. You may (not entirely correctly) understand it as “everything other than basic indexing (concrete coordinates or slicing)”. Please read the official document for more details.\nHere we mainly focus on some typical advaced indexing methods.\n\n\n\n\n\n\nCaution\n\n\n\nThere are some very exotic examples that are very hard to tell whether they belong to basic indexing or advanced indexing. Our suggestion is to avoid this type of code, and try to code in the most straight forward way. You could come back to understand this problem later when you are more expericened, but it is more of a Programming Language problem, instead of a Data Science problem.\n\n\n\n\n\n\n\n\nFancy indexing\n\n\n\n\n\nFancy indexing is a term adopted by numpy to describe indexing using integer arrays.\nThe basic idea is to use a list of indexes to select entries. The general rule is relative complicated. Here we will only talk about 1d and 2d cases.\n\n\n\n\n\n\n1d case\n\n\n\n\n\n\nWhen dealing with a 1d ndarray, indexing by a list is straight forward. Please see the following example.\n\nimport numpy as np\narr = np.arange(16)\n\narr[[1, 3, 0, 2]]\n\narray([1, 3, 0, 2])\n\n\n\n\n\n\n\n\nA trick example\n\n\n\n\n\nPlease consider the following two indexings.\n\narr[1:2]\n\narray([1])\n\n\n\narr[[1]]\n\narray([1])\n\n\nFrom the first glance, the two outputs look the same. However they are from two different techniques.\n\nThe 1:2 in arr[1:2] is a slice. Therefore the first indexing is basic indexing.\nThe [1] in arr[[1]] is a list. Therefore the second indexing is advanced indexing.\n\nThe main reason to distinguish these two indexings is about view and copy, which will be discussed in the next section.\n\n\n\n\n\n\n\n\n\n2d case\n\n\n\n\n\n\nWhen dealing with a 2d ndarray, there are multiple possibilities. In the following discussion we will use the following example.\n\nA = np.arange(16).reshape((4, 4))\nA\n\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11],\n       [12, 13, 14, 15]])\n\n\n\n\n\n\n\n\n1. If only one list is given\n\n\n\n\n\nIf only one list is given, this list is considered as the list of row indexes. The resulted ndarray is always 2d.\n\nA[[3, 1]]\n\narray([[12, 13, 14, 15],\n       [ 4,  5,  6,  7]])\n\n\n\n\n\n\n\n\n\n\n\n2. If two arguments are given, one is a list, the other is :\n\n\n\n\n\nIf two arguments are given, one is a list, the other is :, this list refers to row indexes if it is in the first argument place, and refers to column indexes if it is in the second argument place. The resulted ndarray is always 2d.\n\nA[[3, 1], :]\n\narray([[12, 13, 14, 15],\n       [ 4,  5,  6,  7]])\n\n\n\nA[:, [3, 1]]\n\narray([[ 3,  1],\n       [ 7,  5],\n       [11,  9],\n       [15, 13]])\n\n\n\n\n\n\n\n\n\n\n\n3. If both two arguments are lists of the same length\n\n\n\n\n\nIf both two arguments are lists of the same length, it is considered as the list of axis 0 coordinates and the list of axis 1 coordinates. In this case, the resulted ndarray is 1d.\n\nA[[0, 1], [3, 1]]\n\narray([3, 5])\n\n\nIn this example, the two lists together gives two entries.\n\nThe coordinate of the first entry is (0, 3) since they are the first entry of each list. The (0, 3) entry in A is 3.\nThe coordinate of the second entry is (1, 1) since they are the second entry of each list. The (1, 1) entry in A is 5.\n\nThen the result is array([3, 5]), as shown above.\n\n\n\n\n\n\n\n\n\n4. If both two arguments are lists, and one of the lists is of length 1\n\n\n\n\n\nIf both two arguments are lists, and one of the lists is of length 1, it is the same as the previous case, with the list of length 1 being broadcasted.\n\nA[[0], [3, 1]]\n\narray([3, 1])\n\n\nIn this example, after broadcasting, the result is the same as A[[0,0], [3,1]].\n\n\n\nFor higher dimensions, please read the documents to understand how it actually works.\nNote that ndarray can also be used as indexes and it behaves very similar to list.\n\n\n\n\n\n\n\n\n\nBoolean Indexing\n\n\n\n\n\nndarray can accept index in terms of ndarrays with boolean indexing.\n\nExample 3.6  \n\nimport numpy as np\na = np.arange(4)\nb = np.array([True, True, False, True])\na\n\narray([0, 1, 2, 3])\n\n\n\nb\n\narray([ True,  True, False,  True])\n\n\n\na[b]\n\narray([0, 1, 3])\n\n\n\nWe could combine this way with the logic computation to filter out the elements we want/don’t want.\n\nExample 3.7 Please find the odd numbers in arr.\n\narr = np.arange(10)\nodd = (arr %2 == 1)\narr[odd] \n\narray([1, 3, 5, 7, 9])\n\n\n\n\n\n\n\n\n3.2.3 Copies and views\nThe view of an ndarray is a way to get access to the array without copying internel data. When operating with a view, the original data as well as all other views of the original data will be modified simutanously.\n\nExample 3.8  \n\nimport numpy as np\narr = np.arange(10)\nb = arr[5:8]\nprint('arr is {}'.format(arr))\nprint('b is {}'.format(b))\n\narr is [0 1 2 3 4 5 6 7 8 9]\nb is [5 6 7]\n\n\n\nb[0] = -1\nprint('arr is {}'.format(arr))\nprint('b is {}'.format(b))\n\narr is [ 0  1  2  3  4 -1  6  7  8  9]\nb is [-1  6  7]\n\n\n\narr[6] = -2\nprint('arr is {}'.format(arr))\nprint('b is {}'.format(b))\n\narr is [ 0  1  2  3  4 -1 -2  7  8  9]\nb is [-1 -2  7]\n\n\n\nThe default setting for copies and views is that, basic indexing will always make views, and advanced indexing (e.g. boolean indexing, fancy indexing, etc.) will make copies. For other operations, you need to check the documents to know how they work. For example, np.reshape() creates a view where possible, and np.flatten() always creates a copy.\nThe way to check whether something is a view or not is the attribute .base. If it is a view of another ndarray, you may see that ndarray in the attribute .base. If it is not a view, in other words, if it is a copy, the .base attribute is None.\n\nExample 3.9  \n\nA = np.random.rand(3, 3)\nA\n\narray([[0.56383989, 0.64727413, 0.91154088],\n       [0.66873588, 0.29338032, 0.22314897],\n       [0.0552867 , 0.57712631, 0.14543216]])\n\n\n\nA[1:2].base\n\narray([[0.56383989, 0.64727413, 0.91154088],\n       [0.66873588, 0.29338032, 0.22314897],\n       [0.0552867 , 0.57712631, 0.14543216]])\n\n\nBasic indexing creates views. In this example, the base of A[1:2] is A, which means that A[1:2] is a view of A.\n\nprint(A[[1]].base)\n\nNone\n\n\nAdvanced indexing creates copys. In this example, the base is None. So A[[1]] is NOT a view of anything.\n\nYou may use np.view() or np.copy() to make views or copies explicitly.\n\nExample 3.10  \n\narr = np.arange(10)\nb = arr[5:8].copy()\nprint('arr is {}'.format(arr))\nprint('b is {}'.format(b))\n\narr is [0 1 2 3 4 5 6 7 8 9]\nb is [5 6 7]\n\n\n\nb[0] = -1\nprint('arr is {}'.format(arr))\nprint('b is {}'.format(b))\n\narr is [0 1 2 3 4 5 6 7 8 9]\nb is [-1  6  7]\n\n\n\narr[6] = -2\nprint('arr is {}'.format(arr))\nprint('b is {}'.format(b))\n\narr is [ 0  1  2  3  4  5 -2  7  8  9]\nb is [-1  6  7]\n\n\n\nprint('The base of b is {}'.format(b.base))\n\nThe base of b is None",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Package: `numpy`</span>"
    ]
  },
  {
    "objectID": "contents/3/intro.html#more-functions",
    "href": "contents/3/intro.html#more-functions",
    "title": "3  Package: numpy",
    "section": "3.3 More functions",
    "text": "3.3 More functions\nWe introduce a few more advanced functions here. All the following functions are somehow related to the indexes of entries.\n\n\n\n\n\n\nnp.where()\n\n\n\n\n\nnp.where() is a very powerful function. The basic usage is np.where(A satisfies condition). The output is an ndarray of indexes of entries of A that satisfies the condition.\n\nWhen the ndarray in question is 1d, the output is a 1d ndarray of indexes.\n\n\nimport numpy as np\na = np.random.randint(10, size=10)\na\n\narray([3, 0, 8, 7, 7, 4, 7, 7, 4, 4])\n\n\n\nnp.where(a%3 == 1)\n\n(array([3, 4, 5, 6, 7, 8, 9], dtype=int64),)\n\n\nSince the output is the ndarray of indexes, it is possible to directly use it to get those entries.\n\na[np.where(a%3 == 1)]\n\narray([7, 7, 4, 7, 7, 4, 4])\n\n\nNote that this is a fancy indexing, so the result is a copy.\n\nWhen the ndarray in question is 2d, the output is a tuple which consists of two 2d ndarray of indexes. The two ndarrays are the arrays of the axis 0 indexes and the axis 1 indexes of the very entries.\n\n\nb = np.random.randint(10, size=(3, 3))\nb\n\narray([[6, 3, 9],\n       [5, 7, 0],\n       [3, 4, 4]])\n\n\n\nnp.where(b%2 == 0)\n\n(array([0, 1, 2, 2], dtype=int64), array([0, 2, 1, 2], dtype=int64))\n\n\nSimilar to the previous case, we may directly using fancy indexing to get an ndarray of the entries, and what we get is a copy.\n\nb[np.where(b%2 == 0)]\n\narray([6, 0, 4, 4])\n\n\n\nnp.where() has two more optional arguments.\n\n\nnp.where(arr satisfies condition, x, y)\n\nThe output is an ndarray of the same shape as arr. For each entry, if it satisfies the condition, the entry is x. Otherwise it is y.\n\narr = np.arange(10)\nnp.where(arr&lt;5, 0, 1)\n\narray([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n\n\nnumpy will go over all entries in arr, and check whether they are smaller than 5. If an entry is smaller than 5, it is set to 0. If an entry is not smaller than 5, it is set to 1.\nThis is a very convenient way to do some aggragation operations.\n\n\n\n\n\n\n\n\n\nnp.any() and np.all()\n\n\n\n\n\nBoth of them will check each entry of an ndarray satisfies certain conditions. np.any() will return True if any one entry satisfies the condition. np.all() will return True if all entries satisfy the condition.\nBoth of them also accept axis argument. In this case output will be an ndarray which gives results along the specific axis.\nPlease see the following examples.\n\na = np.array([[1,2],[2,4], [3,5]])\nnp.any(a%2==0)\n\nTrue\n\n\n\nnp.any(a%2==0, axis=0)\n\narray([ True,  True])\n\n\n\nnp.any(a%2==0, axis=1)\n\narray([ True,  True, False])\n\n\n\nnp.all(a%2==0)\n\nFalse\n\n\n\nnp.all(a%2==0, axis=0)\n\narray([False, False])\n\n\n\nnp.all(a%2==0, axis=1)\n\narray([False,  True, False])\n\n\n\n\n\n\n\n\n\n\n\nnp.argsort()\n\n\n\n\n\nnp.argsort() returns the indices that would sort an array. It is easy to think of that indexing using this output indices can resulted a sorted ndarray, which is a copy of the original one since this indexing is a fancy indexing.\n\nimport numpy as np\na = np.random.randint(100, size=10)\na\n\narray([90, 56, 79, 93, 52, 29, 61, 46, 93, 51])\n\n\n\na[np.argsort(a)]\n\narray([29, 46, 51, 52, 56, 61, 79, 90, 93, 93])\n\n\n\n\n\n\n3.3.1 Some examples\n\nExample 3.11 Get the position where elements of a and b match.\n\na = np.array([1,2,3,2,3,4,3,4,5,6])\nb = np.array([7,2,10,2,7,4,9,4,9,8])\n\nnp.where(a == b)\n\n(array([1, 3, 5, 7], dtype=int64),)\n\n\n\n\nExample 3.12  \n\na = np.array([1,2,3,2,3,4,3,4,5,6])\nb = np.array([7,2,10,2,7,4,9,4,9,8])\n\nnp.where(a == b, a*2, b+1)\n\narray([ 8,  4, 11,  4,  8,  8, 10,  8, 10,  9])\n\n\n\n\nExample 3.13 (Playing with axis) Please think through the example and understand what actually happens in each case.\n\nimport numpy as np\na = np.array([[[1,2],[3,4]],[[5,6],[7,8]]])\na\n\narray([[[1, 2],\n        [3, 4]],\n\n       [[5, 6],\n        [7, 8]]])\n\n\n\nnp.any(a==1, axis=0)\n\narray([[ True, False],\n       [False, False]])\n\n\n\nnp.any(a==1, axis=1)\n\narray([[ True, False],\n       [False, False]])\n\n\n\nnp.any(a==1, axis=2)\n\narray([[ True, False],\n       [False, False]])\n\n\n\nnp.any(a==2, axis=0)\n\narray([[False,  True],\n       [False, False]])\n\n\n\nnp.any(a==2, axis=1)\n\narray([[False,  True],\n       [False, False]])\n\n\n\nnp.any(a==2, axis=2)\n\narray([[ True, False],\n       [False, False]])\n\n\n\nnp.any(a==5, axis=0)\n\narray([[ True, False],\n       [False, False]])\n\n\n\nnp.any(a==5, axis=1)\n\narray([[False, False],\n       [ True, False]])\n\n\n\nnp.any(a==5, axis=2)\n\narray([[False, False],\n       [ True, False]])",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Package: `numpy`</span>"
    ]
  },
  {
    "objectID": "contents/3/intro.html#projects-examples",
    "href": "contents/3/intro.html#projects-examples",
    "title": "3  Package: numpy",
    "section": "3.4 Projects Examples",
    "text": "3.4 Projects Examples\n\n3.4.1 Toss a coin\nTossing a coin can be modeled by picking a random number between 0 and 1. If the number is &lt;0.5, we call it H (head). If the number is &gt;=0.5, we call it T (tail).\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nimport numpy as np\n\ndef tossacoin():\n    r = np.random.rand()\n    if r &lt; 0.5:\n        result = 'H'\n    else:\n        result = 'T'\n    return result\n\n\n\n\nIf we want to do it 10 times, we may use a for loop.\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nresults = []\nfor i in range(10):\n    results.append(tossacoin())\n\n\n\n\nThe above code can be written in terms of list comprehension.\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nresults = [tossacoin() for _ in range(10)]\n\nNote that since the loop parameter i is actually not used in the loop body, we could replace it by _ to indicate that it is not used.\n\n\n\nNow we would like to rewrite these code using np.where(). Consider all tossing actions simutanously. So we generate an ndarray of random numbers to model all tossing actions.\n\n\n\n\n\n\nTip\n\n\n\n\n\n\ntoss = np.random.rand(10)\n\n\n\n\nThen using np.where() to check each whether it is H or T.\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nresults = np.where(toss&lt;0.5, 'H', 'T')\n\n\n\n\nSince now results is an ndarray, we could directly use it to count the number of H.\n\n\n\n\n\n\nTip\n\n\n\n\n\n\n(results=='H').sum()\n\n5\n\n\n\n\n\n\n\n3.4.2 Random walks\nAdam walks randomly along the axis. He starts from 0. Every step he has equal possibility to go left or right. Please simulate this process.\nUse choices to record the choice of Adam at each step. We may generate a random array where 0 represents left and 1 represents right.\nUse positions to record the position of Adam at each step. Using choices, the position is +1 if we see a 1 and the position is -1 if we see a 0. So the most elegent way to perform this is to\n\nConvert choices from {0, 1} to {-1, 1}.\nTo record the starting position, we attach 0 to the beginning of the new choices.\nApply .cumsum() to choices to get positions.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nimport numpy as np\n\nstep = 30\nchoices = np.random.randint(2, size=step)\nchoices = choices * 2 - 1\nchoices = np.concatenate(([0], choices))\npositions = choices.cumsum()\n\nimport matplotlib.pyplot as plt\nplt.plot(positions)\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.3 Many random walks\nWe mainly use numpy.ndarray to write the code in the previous example. The best part here is that it can be easily generalized to many random walks.\nStill keep choices and positions in mind. Now we would like to deal with multiple people simutanously. Each row represents one person’s random walk. All the formulas stay the same. We only need to update the dimension setting in the previous code.\n\nUpdate size in np.random.randint.\nUpdate [0] to np.zeros((N, 1)) in concatenate.\nFor cumsum and concatenate, add axis=1 to indicate that we perform the operations along axis 1.\nWe plot each row in the same figure. plt.legend is used to show the label for each line.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nimport numpy as np\n\nstep = 30\nN = 3\nchoices = np.random.randint(2, size=(N, step))\nchoices = choices * 2 - 1\nchoices = np.concatenate((np.zeros((N, 1)), choices), axis=1)\npositions = choices.cumsum(axis=1)\n\nimport matplotlib.pyplot as plt\nfor row in positions:\n    plt.plot(row)\nplt.legend([1, 2, 3])\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.4 Analyze positions\nWe play with the numpy array positions to get some information about the random walks of three generated in the previous example.\n\nThe maximal position:\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\npositions.max()\n\n6.0\n\n\n\n\n\n\nThe maximal position for each one:\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\npositions.max(axis=1)\n\narray([4., 6., 5.])\n\n\n\n\n\n\nThe maximal position across all three for each step:\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\npositions.max(axis=0)\n\narray([0., 1., 2., 1., 2., 1., 0., 1., 2., 3., 2., 3., 2., 3., 2., 3., 4.,\n       3., 4., 3., 4., 5., 4., 3., 4., 5., 4., 5., 6., 5., 4.])\n\n\n\n\n\n\nCheck whether anyone once got to the position 3:\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\n(positions&gt;=3).any(axis=1)\n\narray([ True,  True,  True])\n\n\n\n\n\n\nThe number of people who once got to the position 3:\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\n(positions&gt;=3).any(axis=1).sum()\n\n3\n\n\n\n\n\n\nWhich step for each one gets to the right most position:\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\npositions.argmax(axis=1)\n\narray([18, 28, 21], dtype=int64)",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Package: `numpy`</span>"
    ]
  },
  {
    "objectID": "contents/3/intro.html#exercises",
    "href": "contents/3/intro.html#exercises",
    "title": "3  Package: numpy",
    "section": "3.5 Exercises",
    "text": "3.5 Exercises\nMany exercises are from [2].\n\nExercise 3.1  \n\nCreate a \\(3\\times3\\) matrix with values ranging from 2 to 10.\nCreate a \\(10\\times10\\) 2D-array with 1 on the border and 0 inside.\nCreate a 2D array of shape 5x3 to contain random decimal numbers between 5 and 10.\nCreate a 1D zero ndarray of size 10 and update sixth value to 11.\n\n\n\nExercise 3.2 Write a function to reverse a 1d ndarray (first element becomes last).\n\n\nExercise 3.3 Given a = np.array([1,2,3]), please get the desired output array([1, 1, 1, 2, 2, 2, 3, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3]). You may use np.repeat() and np.tile().\n\n\nExercise 3.4 (Compare two ndarrays) Consider two ndarrays of the same length x and y. Compare them entry by entry. We would like to know the percentage of the entries that are the same.\nPlease wrap your code into a function that return the above percentage.\n\n\nExercise 3.5 (Manipulate matries) Please finish the following tasks. Let arr = np.arange(9).reshape(3,3).\n\nSwap rows 1 and 2 in the array arr.\nReverse the rows of a 2D array arr.\nReverse the columns of a 2D array arr.\n\n\n\nExercise 3.6 Consider a 2d ndarray.\n\narr = np.random.rand(4, 4)\n\n\nPlease compute the mean of each column.\nPlease compute the sum of each row.\nPlease compute the maximum of the whole array.\n\n\n\nExercise 3.7 (Adding one axis) Please download this file.\n\nPlease use matplotlib.pyplot.imread() to read the file as a 3d ndarray. You may need to use matplotlib package. It will be introduced later this course. You may go to its homepage to install it.\nCheck the shape of the array.\nAdd one additional axis to it as axis 0 to make it into a 4d ndarray.\n\n\n\nExercise 3.8 (Understanding colored pictures) Please download this file and use matplotlib.pyplot.imread() to read the file as a 3d ndarray. You may need to use matplotlib package. It will be introduced later this course. You may go to its homepage to install it.\nA colored picture is stored as a 3d ndarray. axis 0 and axis 1 is about the vertical and horizontal coordinates and can help us to locate a sepecific point in the picture. axis 2 is an array with 3 elements. It is the color vector which represents the three principal colors: red, green and blue.\n\nFind the maximum and minimum of the values in the array.\nCompute the mean of the three colors at each point to get a 2d ndarray where each entry represents the mean of the three colors at each point of the picture.\n\n\n\nExercise 3.9 (Queries)  \n\nGet all items between 5 and 10 from an array a = np.array([2, 6, 1, 9, 10, 3, 27]).\nConsider x = np.array([1, 2, 1, 1, 3, 4, 3, 1, 1, 2, 1, 1, 2]). Please find the index of 5th repetition of number 1 in x.\n\n\n\nExercise 3.10 Use the following code to get the dataset iris and three related np.array: iris_1d, iris_2d and sepallength.\n\nimport numpy as np\n\nurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\niris_1d = np.genfromtxt(url, delimiter=',', dtype=None, encoding=None)\niris_2d = np.genfromtxt(url, delimiter=',', dtype='float', encoding=None,\n                        usecols=[0, 1, 2, 3])\niris_2d[np.random.randint(150, size=20), np.random.randint(4, size=20)] = np.nan\nsepallength = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0],\n                            encoding=None)\n\n\niris_1d is a 1D numpy array that each item is a tuple. Please construct a new 1D numpy array that each item is the last componenet of each tuple in iris_1d.\nConvert iris_1d into a 2D array iris_2d by omitting the last field of each item.\nnp.isnan() is a function to check whether each entry of a ndarray is nan or not. Please use np.isnan() as well as np.where() to find all nan entries in iris_2d.\nSelect the rows of iris_2d that does not have any nan value.\nReplace all nan with 0 in iris_2d.\n\n\n\nExercise 3.11 (Random) Please finish the following tasks.\n\nUse the package np.random to flip a coin 100 times and record the result in a 1d ndarray coin.\nAssume that the coin is not fair, and the probability to get H is p. Write a code to flip the coin 100 times and record the result in a list coin, with a given parameter p. You may use p=.4 as the first choice.\nFor each list coin created above, write a code to find the longest H streak. We only need the biggest number of consecutive H we get during this 100 tosses. It is NOT necessary to know when we start the streak.\nPlease write functions to perform the above operations.\n\n\n\nExercise 3.12 (Bins) Please read the document of np.digitize(), and use it to do the following task.\nSet the following bins:\n\nLess than or equal to 3: small\nBigger than 3 but less than or equal to 5: medium\nBigger than 5: large\n\nPlease transform the following data iris_2c into texts using the given bins.\n\nimport numpy as np\nurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\niris_2c = np.genfromtxt(url, delimiter=',', dtype='object')[:, 2].astype('float')\n\n\n\nExercise 3.13 Consider a 2d ndarray a.\n\nimport numpy as np\na = np.random.rand(5, 5)\n\n\nPlease sort it along the 3rd column.\nPlease sort it along the 2nd row.\n\nYou may use np.argsort() for the problem.\n\n\nExercise 3.14 (One-hot vector) Compute the one-hot encodings of a given array. You may use the following array as a test example. In this example, there are 3 labels. So the one-hot vectors are 3 dimensional vectors.\nFor more infomation about one-hot encodings, you may check the Wiki page. You are not allowed to use packages that can directly compute the one-hot encodings for this problem.\n\nimport numpy as np\narr = np.random.randint(1,4, size=6)\n\n\n\nExercise 3.15 Consider arr = np.arange(8). A stride of arr with a window length of 4 and strides of 2 is a 2d ndarray that looks like:\n\n\narray([[0, 1, 2, 3],\n       [2, 3, 4, 5],\n       [4, 5, 6, 7]])\n\n\nPlease write a function that takes arr and length and strides as inputs, and its stride as outputs.\n\n\n\n\n\n[1] McKinney, W. (2017). Python for data analysis: Data wrangling with pandas, NumPy, and IPython. O’Reilly Media.\n\n\n[2] Prabhakaran, S. (2018). 101 NumPy exercises for data analysis (python).",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Package: `numpy`</span>"
    ]
  },
  {
    "objectID": "contents/4/intro.html#basic-pandas",
    "href": "contents/4/intro.html#basic-pandas",
    "title": "4  Package: pandas",
    "section": "4.1 Basic pandas",
    "text": "4.1 Basic pandas\n\n4.1.1 Series and DataFrame\nA Series is a 1-d array-like object which has index. The default index is starting from 0. You may change the index to be something assigned by you. Thus it can be treated as a generalization of a dict.\n\nobj = pd.Series([3, 1, 2, 4])\nobj\n\n0    3\n1    1\n2    2\n3    4\ndtype: int64\n\n\n\nobj2 = pd.Series([3, 1, 2, 4], index=['a', 'b', 'c', 'd'])\nobj2\n\na    3\nb    1\nc    2\nd    4\ndtype: int64\n\n\n\ndata3 = {'a': 3, 'b': 1, 'c': 2, 'd': 4}\nobj3 = pd.Series(data3)\nobj3\n\na    3\nb    1\nc    2\nd    4\ndtype: int64\n\n\nA DataFrame represents a rectangular table of data and contains an ordered collection of columns, each of which can be a different value type. The DataFrame has both a row and column index; it can be thought of as a dict of Series all sharing the same index. When displaying a DataFrame, we may use .head() to just display the first few rows for efficicy.\n\nimport pandas as pd\n\ndata = {'a': [1, 2, 3, 4, 5, 6, 7],\n        'b': [1.1, 2.1, 3.1, 4.1, 5.1, 6.1, 7.1],\n        'c': ['a', 'b', 'c', 'd', 'e', 'f', 'g']}\ndf = pd.DataFrame(data)\ndf.head()\n\n\n\n\n\n\n\n\na\nb\nc\n\n\n\n\n0\n1\n1.1\na\n\n\n1\n2\n2.1\nb\n\n\n2\n3\n3.1\nc\n\n\n3\n4\n4.1\nd\n\n\n4\n5\n5.1\ne\n\n\n\n\n\n\n\n\n\n4.1.2 Decorations\nA Series or a DataFrame might have named row indexes and column names. I collect some tools for you to play with them and list them below.\n\n\n\n\n\n\nSetting when creating\n\n\n\n\n\nWe may use the setting columns= or index= to change the column names and the index names. See the following example.\n\nimport numpy as np\nimport pandas as pd\ndata = pd.DataFrame(np.arange(16).reshape((4, 4)),\n                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n                    columns=['one', 'two', 'three', 'four'])\ndata\n\n\n\n\n\n\n\n\none\ntwo\nthree\nfour\n\n\n\n\nOhio\n0\n1\n2\n3\n\n\nColorado\n4\n5\n6\n7\n\n\nUtah\n8\n9\n10\n11\n\n\nNew York\n12\n13\n14\n15\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.rename()\n\n\n\n\n\nWe may use the .rename() method. Note that by default the return value of this method is a copy and it won’t affect the original DataFrame. The arguments can be in many different formats. Please see the official document for more details.\nIf you want to directly make the change, please use the argument inplace=True.\nThe following example shows the standard way to rename.\n\ndf = pd.DataFrame(np.arange(16).reshape((4, 4)))\ndf.rename(columns={0: 'zero'}, index={2: 'two'})\n\n\n\n\n\n\n\n\nzero\n1\n2\n3\n\n\n\n\n0\n0\n1\n2\n3\n\n\n1\n4\n5\n6\n7\n\n\ntwo\n8\n9\n10\n11\n\n\n3\n12\n13\n14\n15\n\n\n\n\n\n\n\nHowever the orginal df is not affected.\n\ndf\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n\n\n\n\n0\n0\n1\n2\n3\n\n\n1\n4\n5\n6\n7\n\n\n2\n8\n9\n10\n11\n\n\n3\n12\n13\n14\n15\n\n\n\n\n\n\n\nIf you would like to change the original df, you may either set df = df.rename(columns={0: 'zero'}, index={2: 'two'}), or\n\ndf.rename(columns={0: 'zero'}, index={2: 'two'}, inplace=True)\ndf\n\n\n\n\n\n\n\n\nzero\n1\n2\n3\n\n\n\n\n0\n0\n1\n2\n3\n\n\n1\n4\n5\n6\n7\n\n\ntwo\n8\n9\n10\n11\n\n\n3\n12\n13\n14\n15\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSet a column to be the index by .set_index()\n\n\n\n\n\nThe title is all. A few remarks:\n\nYou may set multiple columns to be the index. In this case, what you get is a multi-index system (which is also called Hierarchical indexing). We will talk about this later in Section 4.4.2.\nThe argument drop is used to control whether the column is deleted after you set it to be the index. The default setting is True.\nThe argument append is used to control whether the column you choose is appended to the exsiting index to form a multi-index system. The default is False.\nThe argument inplace is used to control whether you want to make the change inplace. The default is False.\n\n\n\n\n\n\n\n\n\n\nReset the index by .reset_index()\n\n\n\n\n\nThe title is all. A few remarks:\n\nThe new index is integers starting from 0.\ndrop is an argument to control whether the original index is dropped or added back to the DataFrame as a column. The default is False, which means that by default the original index will be added back to the DataFrame.\n\n\n\n\n\n\n4.1.3 Look at the DataFrame\nThe following methods can be used to look at the DataFrame. Their syntax is very simple. Please try them by yourselves.\n\n.head(): show the first few rows.\n.tail(): show the last few rows.\n.describe(): show the basic statistics of each columns.\n\nThese are methods for Series which might be helpful to understand the data.\n\n.unique()\n.value_counts()\n\n\n\n\n\n\n\nAn example\n\n\n\n\n\n\nimport pandas as pd\n\ndf = pd.DataFrame({'a': [1, 2, 3, 1, 2, 2, 1, 1, 1],\n                   'b': [3, 1, 1, 2, 4, 5, 2, 1, 3]})\ndf.head(3)\n\n\n\n\n\n\n\n\na\nb\n\n\n\n\n0\n1\n3\n\n\n1\n2\n1\n\n\n2\n3\n1\n\n\n\n\n\n\n\n\ndf.tail()\n\n\n\n\n\n\n\n\na\nb\n\n\n\n\n4\n2\n4\n\n\n5\n2\n5\n\n\n6\n1\n2\n\n\n7\n1\n1\n\n\n8\n1\n3\n\n\n\n\n\n\n\n\ndf.describe()\n\n\n\n\n\n\n\n\na\nb\n\n\n\n\ncount\n9.000000\n9.000000\n\n\nmean\n1.555556\n2.444444\n\n\nstd\n0.726483\n1.424001\n\n\nmin\n1.000000\n1.000000\n\n\n25%\n1.000000\n1.000000\n\n\n50%\n1.000000\n2.000000\n\n\n75%\n2.000000\n3.000000\n\n\nmax\n3.000000\n5.000000\n\n\n\n\n\n\n\n\ndf['a'].unique()\n\narray([1, 2, 3], dtype=int64)\n\n\n\ndf['b'].value_counts()\n\nb\n1    3\n3    2\n2    2\n4    1\n5    1\nName: count, dtype: int64",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Package: `pandas`</span>"
    ]
  },
  {
    "objectID": "contents/4/intro.html#indexing",
    "href": "contents/4/intro.html#indexing",
    "title": "4  Package: pandas",
    "section": "4.2 Indexing",
    "text": "4.2 Indexing\nThe act of selecting rows or columns to access from a dataframe or series is called indexing. There are many different ways to index in pandas. We will only cover the most popular ones.\n\n\n\n\n\n\nCaution\n\n\n\n\n\nThere is the same copy and view issue with pandas as in numpy. However it is more complicated and more inconsistent. Please check the official documents for more details and do more experiments before implementing the codes. Usually if your code is ambiguous, you might see the infamous SettingWithCopyWarning warning.\n\ndf = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})\ndf[df['a']==3]['b'] = 3\n\nC:\\Users\\Xinli\\AppData\\Local\\Temp\\ipykernel_27964\\4018622545.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[df['a']==3]['b'] = 3\n\n\nNote that pandas is testing a copy-on-write feature to fix the issue. The feature can be simlified as “any DataFrame or Series derived from another in any way always behaves as a copy”. Please keep an eye on the updates about when the feature will be fully implemented in pandas.\n\n\n\n\n4.2.1 []\n\n\n\n\n\n\nSeries[]\n\n\n\n\n\n\n\n\n\n\nInput value type\nReturn Value Type\n\n\n\n\nSeries[label]\nscalar value\n\n\nSeries[list of labels]\nSeries corresponding to labels\n\n\nSeries[slice]\nSeries corresponding to the slice\n\n\nSeries[boolean vector]\nSeries corresponding to the boolean vector\n\n\n\n\n\n\nFor Series, values are accessed by labels, not positions. Since Series are usually considered as a column, you may think these labels as row indexes.\nWhen using slice, things becomes more complicated. There are two ways of using slice. You may either slice by positions, or slice by labels. The main differences between them is that:\n\n\nslice by positions Series[i:j] doesn’t contain the last index Series[j];\nslice by labels Sereies[I:J] contains the last label Series[J].\n\n\nSometimes the labels of a series are integers, but different than the position indexes. In pandas 1.5.1, slice by positions takes priority. However the whole scenario is very confusing, and this will be changed in future versions. In this cases it is recommanded to use .loc and .iloc.\nWhen indexing using boolean vector, the vector should be of the same length as the Series. In other words, it works as the boolean bector shows which row is selected.\n\nSee some examples below.\n\nExample 4.1  \n\nimport pandas as pd\n\nexample = pd.Series({'a': 1.1, 'b': 2.2, 'c': 3.3, 'd': 4.4})\nexample\n\na    1.1\nb    2.2\nc    3.3\nd    4.4\ndtype: float64\n\n\n\nexample['b']\n\n2.2\n\n\n\nexample[['b', 'a']]\n\nb    2.2\na    1.1\ndtype: float64\n\n\n\nexample[0:2]\n\na    1.1\nb    2.2\ndtype: float64\n\n\n\nexample['a':'c']\n\na    1.1\nb    2.2\nc    3.3\ndtype: float64\n\n\n\nexample[[True, False, True, False]]\n\na    1.1\nc    3.3\ndtype: float64\n\n\n\n\n\n\n\n\n\n\n\n\nDataFrame[]\n\n\n\n\n\n\n\n\n\n\nInput value type\nReturn Value Type\n\n\n\n\nDataFrame[colname]\nThe column corresponding to colname as a Series\n\n\nDataFrame[list-of-colnames]\nThe columns of DataFrame corresponding to colnames\n\n\nDataFrame[slice]\nThe rows of DataFrame corresponding to the slice\n\n\nDataFrame[boolean list]\nDataFrame corresponding to the boolean list\n\n\n\n\n\n\nSlice for DataFrame behaves exactly like slice for Series, that it is selecting rows, and it works for both labels and positions. Similarly, slicing by positions are not recommended and might be deprecated in the future.\nOn the other hand side, selecting rows are usually related to querying. Therefore it is better not to focus on slicing.\nInside [], one column name and a list of columna names will result totally different objects: one is a Series and the other is a DataFrame.\nIn prior versions, using [list-of-colnames] would work as long as at least 1 of the keys was found (otherwise it would raise a KeyError). This behavior was changed and will now raise a KeyError if at least one label is missing. The recommended alternative is to use .reindex().\nWhen indexing using boolean vector, the vector should be of the same length as the number of rows of the DataFrame. In other words, it works as the boolean bector shows which row is selected.\nUsing [] for DataFrame cannot give you a single value, since what are inside [] is always treated as a row index or a column index. If you want to get access to the value of a single cell by both row index and column index, use other method like .loc[].\nIf the column name is eligible for attributes, you may also use df.a to represent df['a'] for simplicity.\n\n\nExample 4.2  \n\nimport pandas as pd\n\nexample = pd.DataFrame({'a': [1.1, 2.2], 'b': [2.2, 3.3], 'c': [3.3, 4.4]})\nexample\n\n\n\n\n\n\n\n\na\nb\nc\n\n\n\n\n0\n1.1\n2.2\n3.3\n\n\n1\n2.2\n3.3\n4.4\n\n\n\n\n\n\n\n\nexample['a']\n\n0    1.1\n1    2.2\nName: a, dtype: float64\n\n\n\nexample.a\n\n0    1.1\n1    2.2\nName: a, dtype: float64\n\n\n\nexample[['a']]\n\n\n\n\n\n\n\n\na\n\n\n\n\n0\n1.1\n\n\n1\n2.2\n\n\n\n\n\n\n\n\nexample[0:1]\n\n\n\n\n\n\n\n\na\nb\nc\n\n\n\n\n0\n1.1\n2.2\n3.3\n\n\n\n\n\n\n\n\nexample[[False, True]]\n\n\n\n\n\n\n\n\na\nb\nc\n\n\n\n\n1\n2.2\n3.3\n4.4\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.2.2 .loc[] and .iloc[]\n[] contains several different types of ways to access data. .loc[] and .iloc[] are more specific.\n\n.loc[] is to use labels to access data.\n.iloc[] is to use positions to access data.\n\n\n\n\n\n\n\nNotes for .loc[] and .iloc[]\n\n\n\n\n\n\nWhen there is only one index is specified, it is refered to rows.\nWhen using both indexes, the first is row index and the second is column index.\nWhen selecting all rows/columns, you may put : in the corresponding place.\ndf.loc[1, 'a'] refers to the cell in the DataFrame df whose row index is 1 and column index is a. df[1, 'a'] refers to the column in the DataFrame df whose column name is (1, 'a').\nMany other small details are very similar to []. For example, pay attention to the differences between df.loc[:, 'a'] and df.loc[:, ['a']].\n\n\nExample 4.3  \n\nimport pandas as pd\nexample = pd.DataFrame({'a': [1.1, 2.2], 'b': [2.2, 3.3], 'c': [3.3, 4.4]})\nexample\n\n\n\n\n\n\n\n\na\nb\nc\n\n\n\n\n0\n1.1\n2.2\n3.3\n\n\n1\n2.2\n3.3\n4.4\n\n\n\n\n\n\n\n\nexample.loc[1]\n\na    2.2\nb    3.3\nc    4.4\nName: 1, dtype: float64\n\n\n\nexample.loc[:, 'a']\n\n0    1.1\n1    2.2\nName: a, dtype: float64\n\n\n\nexample.loc[1, 'a']\n\n2.2\n\n\n\nexample.iloc[0:1, 0:2]\n\n\n\n\n\n\n\n\na\nb\n\n\n\n\n0\n1.1\n2.2\n\n\n\n\n\n\n\n\nexample.iloc[1, 0:2]\n\na    2.2\nb    3.3\nName: 1, dtype: float64\n\n\n\nexample.iloc[[1], 0:2]\n\n\n\n\n\n\n\n\na\nb\n\n\n\n\n1\n2.2\n3.3\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.2.3 Boolean indexing\nLet df be a DataFrame. Assume that boo is boolean vector of the dimension same to the number of rows of df, then we can use df[boo] to filter data: all rows with True will be selected. The syntax is similar to the boolean indexing in numpy.\n\n\n\n\n\n\nThe basic usage of boolean indexing\n\n\n\n\n\n\nimport pandas as pd\nimport numpy as np\ndf = pd.DataFrame(np.random.randn(8, 4),\n                  index=pd.date_range('1/1/2023', periods=8),\n                  columns=['A', 'B', 'C', 'D'])\ndf\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n2023-01-01\n-0.924672\n0.700773\n-0.283759\n2.076926\n\n\n2023-01-02\n1.385489\n0.471777\n-0.917834\n-0.074997\n\n\n2023-01-03\n-0.367268\n-0.107916\n0.659714\n1.150114\n\n\n2023-01-04\n-0.461778\n-0.080428\n1.008448\n-2.242881\n\n\n2023-01-05\n-2.413682\n0.481119\n-0.737922\n-0.113087\n\n\n2023-01-06\n-0.065780\n-0.018715\n-1.329096\n1.792588\n\n\n2023-01-07\n1.879864\n0.977547\n0.234683\n2.243364\n\n\n2023-01-08\n0.196514\n-0.534863\n-1.191005\n-0.419622\n\n\n\n\n\n\n\n\ndf[df['A']&gt;0]\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n2023-01-02\n1.385489\n0.471777\n-0.917834\n-0.074997\n\n\n2023-01-07\n1.879864\n0.977547\n0.234683\n2.243364\n\n\n2023-01-08\n0.196514\n-0.534863\n-1.191005\n-0.419622\n\n\n\n\n\n\n\nTo get the boolean vector, we may directly compute logic expression using columns of df. The previous example is of this kind.\nYou may write complicated expressions. The operators are:\n\n| for or\n& for and\n~ for not\n\nNote that parentheses must be used to ensure a correct result. Please see the following example.\n\ndf[(df['A'] &gt; 1) & (df['B'] &lt; 3)]\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n2023-01-02\n1.385489\n0.471777\n-0.917834\n-0.074997\n\n\n2023-01-07\n1.879864\n0.977547\n0.234683\n2.243364\n\n\n\n\n\n\n\n\n\n\n\nThere are many methods and functions that can create boolean vectors. We will introduce them when we need them.\n\n\n4.2.4 .query()\nDataFrame has a .query() method that allows filtering using an expression instead of a boolean vector. This method uses a different approach from the point of programming language. From the point of users, you are free to choose between .query() and boolean indexing to filter data.\n\n\n\n\n\n\nHere are examples of .query().\n\n\n\n\n\n\ndf = pd.DataFrame({'A': [1,2,3], 'B': [3,2,1], 'C': [5,4,3]})\ndf\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n0\n1\n3\n5\n\n\n1\n2\n2\n4\n\n\n2\n3\n1\n3\n\n\n\n\n\n\n\n\ndf.query('A&lt;B and B&lt;C')\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n0\n1\n3\n5\n\n\n\n\n\n\n\nIt can be simplified as follows:\n\ndf.query('A&lt;B&lt;C')\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n0\n1\n3\n5\n\n\n\n\n\n\n\nThis is the same as the following code.\n\ndf[(df['A']&lt;df['B']) & (df['B']&lt;df['C'])]\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n0\n1\n3\n5\n\n\n\n\n\n\n\nNote that .query() does not require the usage of parentheses. It also use English like or/and/not for |/&/~.\n\ndf.query('A in C')\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n2\n3\n1\n3\n\n\n\n\n\n\n\n\ndf.query('A not in C')\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n0\n1\n3\n5\n\n\n1\n2\n2\n4\n\n\n\n\n\n\n\n\ndf.query('A not in C and A&lt;B')\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n0\n1\n3\n5\n\n\n\n\n\n\n\n\ndf.query('[1,2] in B')\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n1\n2\n2\n4\n\n\n2\n3\n1\n3\n\n\n\n\n\n\n\n\n\n\n\n\n4.2.5 Reindex\n.reindex() is a data alignment method in pandas. To reindex means to conform the data to match a given set of labels along a particular axis. This accomplishes several things:\n\nReordering the existing data to match a new set of labels\nInserting missing value (NaN) markers in label locations where no data for that label existed\n\nHere is a simple example:\n\nimport pandas as pd\ndata = pd.DataFrame(np.arange(16).reshape((4, 4)),\n                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n                    columns=['one', 'two', 'three', 'four'])\ndata\n\n\n\n\n\n\n\n\none\ntwo\nthree\nfour\n\n\n\n\nOhio\n0\n1\n2\n3\n\n\nColorado\n4\n5\n6\n7\n\n\nUtah\n8\n9\n10\n11\n\n\nNew York\n12\n13\n14\n15\n\n\n\n\n\n\n\n\ndata.reindex(index = ['Colorado', 'Arkansas', 'New York'],\n             columns = ['three', 'five', 'one'])\n\n\n\n\n\n\n\n\nthree\nfive\none\n\n\n\n\nColorado\n6.0\nNaN\n4.0\n\n\nArkansas\nNaN\nNaN\nNaN\n\n\nNew York\n14.0\nNaN\n12.0\n\n\n\n\n\n\n\nFrom the first glance, .reindex() behave the same as other indexing methods. Here are a few differences:\n\nThe purpose of indexing methods is to select/filter data, while the purpose of reindex is to make the data in a very specific form.\nWhen dealing with non-existent indexes/columns, most other indexing methods will return error or warning, while .reindex() can handle it automatically.\nThe default setting of .reindex() is to return a copy. This setting can be changed by the argument copy=False.\n\nFor more details please see the official guide.\n\n\n\n4.2.6 Updating data\n\nAssign values to a column of a DataFrame will update that column. If the column doesn’t exist, new column will be created. This is called enlargement.\nWhen assign values with non-existent row index, that part of the data will be discarded.\nWhen using .loc, a DataFrame can be enlarged on either axis.\nAny time if there are no values with a specific column and row, it will show as NaN. \n\n\nExample 4.4  \n\nimport pandas as pd\n\ndata = {'a': [1, 2, 3, 4],\n        'b': [1.1, 2.1, 3.1, 4.1],\n        'c': ['a', 'b', 'c', 'd']}\ndf = pd.DataFrame(data)\n\nnewcol = {1: 'good', 3: 'better', 5: 'best'}\ndf['d'] = pd.Series(newcol)\ndf\n\n\n\n\n\n\n\n\na\nb\nc\nd\n\n\n\n\n0\n1\n1.1\na\nNaN\n\n\n1\n2\n2.1\nb\ngood\n\n\n2\n3\n3.1\nc\nNaN\n\n\n3\n4\n4.1\nd\nbetter",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Package: `pandas`</span>"
    ]
  },
  {
    "objectID": "contents/4/intro.html#data-cleaning",
    "href": "contents/4/intro.html#data-cleaning",
    "title": "4  Package: pandas",
    "section": "4.3 Data cleaning",
    "text": "4.3 Data cleaning\n\n4.3.1 Handling Missing Data\n\nnp.nan, pd.NA\npd.isnull(), np.isnan()\n.dropna(), .fillna()\n\n\n\n\n\n\n\n.dropna() example\n\n\n\n\n\n\nimport pandas as pd\nimport numpy as np\n\ndata = pd.DataFrame([[1., 6.5, 3.], [1., np.nan, np.nan], \n                     [np.nan, np.nan, np.nan], [np.nan, 6.5, 3.]])\ndata\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n1.0\n6.5\n3.0\n\n\n1\n1.0\nNaN\nNaN\n\n\n2\nNaN\nNaN\nNaN\n\n\n3\nNaN\n6.5\n3.0\n\n\n\n\n\n\n\n\ndata.dropna()\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n1.0\n6.5\n3.0\n\n\n\n\n\n\n\n\ndata.dropna(how='all')\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n1.0\n6.5\n3.0\n\n\n1\n1.0\nNaN\nNaN\n\n\n3\nNaN\n6.5\n3.0\n\n\n\n\n\n\n\n\ndata[4] = np.nan\ndata\n\n\n\n\n\n\n\n\n0\n1\n2\n4\n\n\n\n\n0\n1.0\n6.5\n3.0\nNaN\n\n\n1\n1.0\nNaN\nNaN\nNaN\n\n\n2\nNaN\nNaN\nNaN\nNaN\n\n\n3\nNaN\n6.5\n3.0\nNaN\n\n\n\n\n\n\n\n\ndata.dropna(axis=1, how='all')\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n1.0\n6.5\n3.0\n\n\n1\n1.0\nNaN\nNaN\n\n\n2\nNaN\nNaN\nNaN\n\n\n3\nNaN\n6.5\n3.0\n\n\n\n\n\n\n\n\ndata.dropna(thresh=2)\n\n\n\n\n\n\n\n\n0\n1\n2\n4\n\n\n\n\n0\n1.0\n6.5\n3.0\nNaN\n\n\n3\nNaN\n6.5\n3.0\nNaN\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.fillna() example\n\n\n\n\n\n\ndata.fillna(0)\n\n\n\n\n\n\n\n\n0\n1\n2\n4\n\n\n\n\n0\n1.0\n6.5\n3.0\n0.0\n\n\n1\n1.0\n0.0\n0.0\n0.0\n\n\n2\n0.0\n0.0\n0.0\n0.0\n\n\n3\n0.0\n6.5\n3.0\n0.0\n\n\n\n\n\n\n\n\ndata.fillna({1: 0.5, 2: -0.1})\n\n\n\n\n\n\n\n\n0\n1\n2\n4\n\n\n\n\n0\n1.0\n6.5\n3.0\nNaN\n\n\n1\n1.0\n0.5\n-0.1\nNaN\n\n\n2\nNaN\n0.5\n-0.1\nNaN\n\n\n3\nNaN\n6.5\n3.0\nNaN\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArithmetic and Data Alignment\n\n\n\n\n\nElements of the same index and columns will be computed. By default, if any entry is nan, the answer will be nan. You may use fill_value argument to fill the empty slots. Please see the following example.\n\nimport pandas as pd\nimport numpy as np\ndf1 = pd.DataFrame(np.arange(12.).reshape((3, 4)), columns=list('abcd'))\ndf2 = pd.DataFrame(np.arange(20.).reshape((4, 5)), columns=list('abcde'))\ndf2.loc[1, 'b'] = np.nan\n\ndf1.add(df2, fill_value=0)\n\n\n\n\n\n\n\n\na\nb\nc\nd\ne\n\n\n\n\n0\n0.0\n2.0\n4.0\n6.0\n4.0\n\n\n1\n9.0\n5.0\n13.0\n15.0\n9.0\n\n\n2\n18.0\n20.0\n22.0\n24.0\n14.0\n\n\n3\n15.0\n16.0\n17.0\n18.0\n19.0\n\n\n\n\n\n\n\nRelatedly, when reindexing a Series or DataFrame, you can also specify a fill_value.\n\n\n\n\n\n4.3.2 Handling duplicates\n\n\n\n\n\n\n.drop_duplicates() example\n\n\n\n\n\n\nimport numpy as np\nimport pandas as pd\n\ndata = pd.DataFrame({'k1': ['one', 'two'] * 3 + ['two'], \n                     'k2': [1, 1, 2, 3, 3, 4, 4]})\ndata.drop_duplicates(['k1'], keep='last')\n\n\n\n\n\n\n\n\nk1\nk2\n\n\n\n\n4\none\n3\n\n\n6\ntwo\n4\n\n\n\n\n\n\n\n\n\n\n\n\n4.3.3 Drop data\nYou may use .drop() to drop columns or rows.\n\nIf you directly apply .drop() to an index, that index is considered as a row index.\nTo drop a column, you need to specify the argument columns=.\nThere is still the inplace= issue.\n\n\n\n4.3.4 String Manipulation\nWhen the column Series is of type str, all methods in pd.Series.str will be applied to each entry of the Series.\n\n\n\n\n\n\nSome basic examples\n\n\n\n\n\n\nimport pandas as pd\nimport numpy as np\ns = pd.Series([\"A \", \" B \", \"C\", \"Aaba\", \" Baca \", np.nan, \"CABA\", \"dog\", \"cat\"])\ns\n\n0        A \n1        B \n2         C\n3      Aaba\n4     Baca \n5       NaN\n6      CABA\n7       dog\n8       cat\ndtype: object\n\n\n\ns.str.lower()\n\n0        a \n1        b \n2         c\n3      aaba\n4     baca \n5       NaN\n6      caba\n7       dog\n8       cat\ndtype: object\n\n\n\ns.str.split('a')\n\n0          [A ]\n1         [ B ]\n2           [C]\n3      [A, b, ]\n4    [ B, c,  ]\n5           NaN\n6        [CABA]\n7         [dog]\n8        [c, t]\ndtype: object\n\n\n\ns.str.len()\n\n0    2.0\n1    3.0\n2    1.0\n3    4.0\n4    6.0\n5    NaN\n6    4.0\n7    3.0\n8    3.0\ndtype: float64\n\n\n\ns.str.strip()\n\n0       A\n1       B\n2       C\n3    Aaba\n4    Baca\n5     NaN\n6    CABA\n7     dog\n8     cat\ndtype: object\n\n\n\ns.str.replace(\"A\", '1')\n\n0        1 \n1        B \n2         C\n3      1aba\n4     Baca \n5       NaN\n6      C1B1\n7       dog\n8       cat\ndtype: object\n\n\n\n\n\n\nExample 4.5 We could also use .str to play with column names and row indexes.\n\nimport pandas as pd\nimport numpy as np\ndf = pd.DataFrame(np.random.randn(3, 2),\n                  columns=[\" Column A \", \" Column B \"], index=range(3))\n\ndf.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\ndf\n\n\n\n\n\n\n\n\ncolumn_a\ncolumn_b\n\n\n\n\n0\n2.546960\n0.973856\n\n\n1\n-0.076523\n0.333522\n\n\n2\n0.638197\n0.154044\n\n\n\n\n\n\n\n\nString methods are usually used with regular expressions. For more details please see Appendix F.",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Package: `pandas`</span>"
    ]
  },
  {
    "objectID": "contents/4/intro.html#data-wrangling",
    "href": "contents/4/intro.html#data-wrangling",
    "title": "4  Package: pandas",
    "section": "4.4 Data Wrangling",
    "text": "4.4 Data Wrangling\n\n4.4.1 Tidy data\nThe same underlying data can be represented in multiple ways. To better study the data, it is better to make these data tidy.\n\nDefinition 4.1 A dataset is tidy if\n\nEach variable have its own column.\nEach observation have its own row.\nEach value have its oven cell.\n\n\n\n\n\n\n\n\nTypical examples of tidydata\n\n\n\n\n\nThese DataFrame are provided by tidyr. We will talk about them again when we get to R. These tables can be downloaded by clicking the names.\n\ntable1\n\n\nimport pandas as pd\ntable1 = pd.read_csv('assests/datasets/table1.csv', index_col='Unnamed: 0')\ntable1\n\n\n\n\n\n\n\n\ncountry\nyear\ncases\npopulation\n\n\n\n\n1\nAfghanistan\n1999\n745\n19987071\n\n\n2\nAfghanistan\n2000\n2666\n20595360\n\n\n3\nBrazil\n1999\n37737\n172006362\n\n\n4\nBrazil\n2000\n80488\n174504898\n\n\n5\nChina\n1999\n212258\n1272915272\n\n\n6\nChina\n2000\n213766\n1280428583\n\n\n\n\n\n\n\n\ntable2\n\n\nimport pandas as pd\ntable2 = pd.read_csv('assests/datasets/table2.csv', index_col='Unnamed: 0')\ntable2\n\n\n\n\n\n\n\n\ncountry\nyear\ntype\ncount\n\n\n\n\n1\nAfghanistan\n1999\ncases\n745\n\n\n2\nAfghanistan\n1999\npopulation\n19987071\n\n\n3\nAfghanistan\n2000\ncases\n2666\n\n\n4\nAfghanistan\n2000\npopulation\n20595360\n\n\n5\nBrazil\n1999\ncases\n37737\n\n\n6\nBrazil\n1999\npopulation\n172006362\n\n\n7\nBrazil\n2000\ncases\n80488\n\n\n8\nBrazil\n2000\npopulation\n174504898\n\n\n9\nChina\n1999\ncases\n212258\n\n\n10\nChina\n1999\npopulation\n1272915272\n\n\n11\nChina\n2000\ncases\n213766\n\n\n12\nChina\n2000\npopulation\n1280428583\n\n\n\n\n\n\n\n\ntable3\n\n\nimport pandas as pd\ntable3 = pd.read_csv('assests/datasets/table3.csv', index_col='Unnamed: 0')\ntable3\n\n\n\n\n\n\n\n\ncountry\nyear\nrate\n\n\n\n\n1\nAfghanistan\n1999\n745/19987071\n\n\n2\nAfghanistan\n2000\n2666/20595360\n\n\n3\nBrazil\n1999\n37737/172006362\n\n\n4\nBrazil\n2000\n80488/174504898\n\n\n5\nChina\n1999\n212258/1272915272\n\n\n6\nChina\n2000\n213766/1280428583\n\n\n\n\n\n\n\n\nSpread across two DataFrames: table4a and table4b:\n\n\nimport pandas as pd\ntable4a = pd.read_csv('assests/datasets/table4a.csv', index_col='Unnamed: 0')\ntable4b = pd.read_csv('assests/datasets/table4b.csv', index_col='Unnamed: 0')\ntable4a\n\n\n\n\n\n\n\n\ncountry\n1999\n2000\n\n\n\n\n1\nAfghanistan\n745\n2666\n\n\n2\nBrazil\n37737\n80488\n\n\n3\nChina\n212258\n213766\n\n\n\n\n\n\n\n\ntable4b\n\n\n\n\n\n\n\n\ncountry\n1999\n2000\n\n\n\n\n1\nAfghanistan\n19987071\n20595360\n\n\n2\nBrazil\n172006362\n174504898\n\n\n3\nChina\n1272915272\n1280428583\n\n\n\n\n\n\n\nAmong all these DataFrames, only table1 is tidy.\n\n\n\nThese three conditions are interrelated because it is impossible to only satisfy two of the three. In pratical, we need to follow the instructions:\n\nPut each dataset in a DataFrame.\nPut each variable in a column.\nEvery row is about one obeservation.\n\nTidy data is a consistent way to organize your data. The main advantages are:\n\nIt is one consistent way of storing data. In other words, this is a consistent data structure that can be used in many cases.\nTo placing variables in columns enables Python to do vectorized operations.\n\nMost datasets are untidy, since tidy data is usually not intuitive for collecting. Therefore raw data which are collected by some naive ideas are usually not tidy.\nUntidy data are usually:\n\nOne variable might be spread across multiple columns.\nOne observation might be scattered across multiple rows.\n\n\n\n\n\n\n\n.melt() method\n\n\n\n\n\nA common problem is that the column names are not names of variables, but values of a variable. For example, table4a above has columns 1999 and 2000. These two names are actually the values of a variable year. In addition, each row represents two observations, not one.\n\n\n\n\n\n\n\n\n\ncountry\n1999\n2000\n\n\n\n\n1\nAfghanistan\n745\n2666\n\n\n2\nBrazil\n37737\n80488\n\n\n3\nChina\n212258\n213766\n\n\n\n\n\n\n\nTo tidy this type of dataset, we need to gather those columns into a new pair of variables. We need three parameters:\n\nThe set of columns that represent values. In this case, those are 1999 and 2000.\nThe name of the variable. In this case, it is year. -The name of the variable whose values are spread over the cells. In this case, it is the number of cases.\n\nThen we apply .melt().\n\ntable4a.melt(id_vars=['country'],\n             value_vars=['1999', '2000'],\n             var_name='year',\n             value_name='cases')\n\n\n\n\n\n\n\n\ncountry\nyear\ncases\n\n\n\n\n0\nAfghanistan\n1999\n745\n\n\n1\nBrazil\n1999\n37737\n\n\n2\nChina\n1999\n212258\n\n\n3\nAfghanistan\n2000\n2666\n\n\n4\nBrazil\n2000\n80488\n\n\n5\nChina\n2000\n213766\n\n\n\n\n\n\n\nWe can do the similar thing to table4b.\n\ntable4b.melt(id_vars=['country'],\n             value_vars=['1999', '2000'],\n             var_name='year',\n             value_name='population')\n\n\n\n\n\n\n\n\ncountry\nyear\npopulation\n\n\n\n\n0\nAfghanistan\n1999\n19987071\n\n\n1\nBrazil\n1999\n172006362\n\n\n2\nChina\n1999\n1272915272\n\n\n3\nAfghanistan\n2000\n20595360\n\n\n4\nBrazil\n2000\n174504898\n\n\n5\nChina\n2000\n1280428583\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIn Python there are multiple different ways to change a wide DataFrame to be longer like .melt(). Among all of them, .melt() is the most common one.\n\n\n\n\n\n\n\n\n\n\n\n.pivot() method\n\n\n\n\n\nAnother issuse is that an observation is scattered across multiple rows. Take table2 as an example.\nAn observation is a country in a year, but each observation is spread across two rows.\n\ntable2\n\n\n\n\n\n\n\n\ncountry\nyear\ntype\ncount\n\n\n\n\n1\nAfghanistan\n1999\ncases\n745\n\n\n2\nAfghanistan\n1999\npopulation\n19987071\n\n\n3\nAfghanistan\n2000\ncases\n2666\n\n\n4\nAfghanistan\n2000\npopulation\n20595360\n\n\n5\nBrazil\n1999\ncases\n37737\n\n\n6\nBrazil\n1999\npopulation\n172006362\n\n\n7\nBrazil\n2000\ncases\n80488\n\n\n8\nBrazil\n2000\npopulation\n174504898\n\n\n9\nChina\n1999\ncases\n212258\n\n\n10\nChina\n1999\npopulation\n1272915272\n\n\n11\nChina\n2000\ncases\n213766\n\n\n12\nChina\n2000\npopulation\n1280428583\n\n\n\n\n\n\n\nWe could apply .pivot() to make it tidy. Here we need two arguments.\n\nThe column that contains variable names. Here, it’s type.\nThe column that contains values forms multiple variables. Here, it’s count.\n\n\ntable2.pivot(index=['country', 'year'], columns='type', values='count')\n\n\n\n\n\n\n\n\ntype\ncases\npopulation\n\n\ncountry\nyear\n\n\n\n\n\n\nAfghanistan\n1999\n745\n19987071\n\n\n2000\n2666\n20595360\n\n\nBrazil\n1999\n37737\n172006362\n\n\n2000\n80488\n174504898\n\n\nChina\n1999\n212258\n1272915272\n\n\n2000\n213766\n1280428583\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSplit and combine columns\n\n\n\n\n\nIf we would like to split one columns into multiple columns since there are more than one values in a cell, we could use Series string method to split it.\n\ntable3['newrate'] = table3['rate'].str.split('/')\ntable3\n\n\n\n\n\n\n\n\ncountry\nyear\nrate\nnewrate\n\n\n\n\n1\nAfghanistan\n1999\n745/19987071\n[745, 19987071]\n\n\n2\nAfghanistan\n2000\n2666/20595360\n[2666, 20595360]\n\n\n3\nBrazil\n1999\n37737/172006362\n[37737, 172006362]\n\n\n4\nBrazil\n2000\n80488/174504898\n[80488, 174504898]\n\n\n5\nChina\n1999\n212258/1272915272\n[212258, 1272915272]\n\n\n6\nChina\n2000\n213766/1280428583\n[213766, 1280428583]\n\n\n\n\n\n\n\nIf we prepare two columns from the beginning, we could directly get two columns. Note that the argument expand=True means that we want to get a DataFrame by expanding dimensionality. More details can be found here.\n\ntable3[['cases', 'population']] = table3['rate'].str.split('/', expand=True)\ntable3.drop(columns=['rate', 'newrate'], inplace=True)\ntable3\n\n\n\n\n\n\n\n\ncountry\nyear\ncases\npopulation\n\n\n\n\n1\nAfghanistan\n1999\n745\n19987071\n\n\n2\nAfghanistan\n2000\n2666\n20595360\n\n\n3\nBrazil\n1999\n37737\n172006362\n\n\n4\nBrazil\n2000\n80488\n174504898\n\n\n5\nChina\n1999\n212258\n1272915272\n\n\n6\nChina\n2000\n213766\n1280428583\n\n\n\n\n\n\n\nSimilarly we could also combine columns just as they are strings.\n\ntable3['another_rate'] = table3['cases']+'/'+table3['population']\ntable3\n\n\n\n\n\n\n\n\ncountry\nyear\ncases\npopulation\nanother_rate\n\n\n\n\n1\nAfghanistan\n1999\n745\n19987071\n745/19987071\n\n\n2\nAfghanistan\n2000\n2666\n20595360\n2666/20595360\n\n\n3\nBrazil\n1999\n37737\n172006362\n37737/172006362\n\n\n4\nBrazil\n2000\n80488\n174504898\n80488/174504898\n\n\n5\nChina\n1999\n212258\n1272915272\n212258/1272915272\n\n\n6\nChina\n2000\n213766\n1280428583\n213766/1280428583\n\n\n\n\n\n\n\n\n\n\n\n\n4.4.2 Hierarchical indexing\nPandas support a more complex indexing system, that the index may have multiple levels. See the following example.\n\n\n\n\n\n\nAn example\n\n\n\n\n\n\nimport pandas as pd\nimport numpy as np\n\ndata = pd.Series(np.random.randn(9),\n                 index = [['a', 'a', 'a', 'b', 'b', 'c', 'c', 'd', 'd'],\n                          [1, 2, 3, 1, 2, 3, 1, 2, 3]])\ndata\n\na  1   -0.444115\n   2    0.824980\n   3   -2.253706\nb  1   -0.888051\n   2   -0.489267\nc  3    0.304066\n   1   -1.326632\nd  2   -0.429425\n   3   -2.533916\ndtype: float64\n\n\nYou may look at the Series using different levels of indexes.\n\ndata['a']\n\n1   -0.444115\n2    0.824980\n3   -2.253706\ndtype: float64\n\n\n\ndata.loc[:, 2]\n\na    0.824980\nb   -0.489267\nd   -0.429425\ndtype: float64\n\n\nYou may use groupby to group by levels and do calculations related to levels. More .groupby() will be discussed in the next section.\n\ndata.groupby(level=1).sum()\n\n1   -2.658798\n2   -0.093713\n3   -4.483557\ndtype: float64\n\n\n\n\n\nFrom the example above, you may notice that the 2-level hierarchical indexing for a Series works very similar to a DataFrame. In fact, you may translate it back and forth between a 2-level indexing Series and a DataFrame.\n\ndf = data.unstack()\ndf\n\n\n\n\n\n\n\n\n1\n2\n3\n\n\n\n\na\n-0.444115\n0.824980\n-2.253706\n\n\nb\n-0.888051\n-0.489267\nNaN\n\n\nc\n-1.326632\nNaN\n0.304066\n\n\nd\nNaN\n-0.429425\n-2.533916\n\n\n\n\n\n\n\n\ndf.stack()\n\na  1   -0.444115\n   2    0.824980\n   3   -2.253706\nb  1   -0.888051\n   2   -0.489267\nc  1   -1.326632\n   3    0.304066\nd  2   -0.429425\n   3   -2.533916\ndtype: float64\n\n\nFor DataFrame the index for both axes can be multiindex. The usual indexing way can be used if you want to start from the first level of the index. The more specific method to extract data is .xs.\n\n\n\n\n\n\nAn example\n\n\n\n\n\n\nimport pandas as pd\n\ndf1 = pd.DataFrame(\n    {\n        \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n        \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n        \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n        \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n    },\n    index=[0, 1, 2, 3],\n)\n\ndf2 = pd.DataFrame(\n    {\n        \"A\": [\"A4\", \"A5\", \"A6\", \"A7\"],\n        \"B\": [\"B4\", \"B5\", \"B6\", \"B7\"],\n        \"C\": [\"C4\", \"C5\", \"C6\", \"C7\"],\n        \"D\": [\"D4\", \"D5\", \"D6\", \"D7\"],\n    },\n    index=[4, 5, 6, 7],\n)\n\ndf = pd.concat([df1, df2], keys=['x', 'y'])\n\n\ndf\n\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\nx\n0\nA0\nB0\nC0\nD0\n\n\n1\nA1\nB1\nC1\nD1\n\n\n2\nA2\nB2\nC2\nD2\n\n\n3\nA3\nB3\nC3\nD3\n\n\ny\n4\nA4\nB4\nC4\nD4\n\n\n5\nA5\nB5\nC5\nD5\n\n\n6\nA6\nB6\nC6\nD6\n\n\n7\nA7\nB7\nC7\nD7\n\n\n\n\n\n\n\n\ndf['A']\n\nx  0    A0\n   1    A1\n   2    A2\n   3    A3\ny  4    A4\n   5    A5\n   6    A6\n   7    A7\nName: A, dtype: object\n\n\n\ndf.loc['x']\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n0\nA0\nB0\nC0\nD0\n\n\n1\nA1\nB1\nC1\nD1\n\n\n2\nA2\nB2\nC2\nD2\n\n\n3\nA3\nB3\nC3\nD3\n\n\n\n\n\n\n\n\ndf.loc['x',3]\n\nA    A3\nB    B3\nC    C3\nD    D3\nName: (x, 3), dtype: object\n\n\n\ndf.xs(3, level=1, drop_level=False)\n\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\nx\n3\nA3\nB3\nC3\nD3\n\n\n\n\n\n\n\n\n\n\n\n\n4.4.3 Combining and Merging Datasets\nmerge and concat are the two most common ways to combine datasets.\n\n\n\n\n\n\npd.merge() function\n\n\n\n\n\nMerge combines datasets by linking rows using one or more keys. This is from relational databases (e.g., SQL-based).\nHere are some examples.\n\nExample 4.6  \n\nimport pandas as pd\ndf1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n                    'data1': range(7)})\ndf2 = pd.DataFrame({'key': ['a', 'b', 'd'], 'data2': range(3)})\n\nThe two DataFrames are displayed as follows.\n\ndf1\n\n\n\n\n\n\n\n\nkey\ndata1\n\n\n\n\n0\nb\n0\n\n\n1\nb\n1\n\n\n2\na\n2\n\n\n3\nc\n3\n\n\n4\na\n4\n\n\n5\na\n5\n\n\n6\nb\n6\n\n\n\n\n\n\n\n\ndf2\n\n\n\n\n\n\n\n\nkey\ndata2\n\n\n\n\n0\na\n0\n\n\n1\nb\n1\n\n\n2\nd\n2\n\n\n\n\n\n\n\n\npd.merge(df1, df2, on='key')\n\n\n\n\n\n\n\n\nkey\ndata1\ndata2\n\n\n\n\n0\nb\n0\n1\n\n\n1\nb\n1\n1\n\n\n2\nb\n6\n1\n\n\n3\na\n2\n0\n\n\n4\na\n4\n0\n\n\n5\na\n5\n0\n\n\n\n\n\n\n\nIf the column names are different in each object, you can specify them separately.\n\ndf3 = pd.DataFrame({'lkey': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n                    'data1': range(7)})\ndf4 = pd.DataFrame({'rkey': ['a', 'b', 'd'],\n                    'data2': range(3)})\npd.merge(df3, df4, left_on='lkey', right_on='rkey')\n\n\n\n\n\n\n\n\nlkey\ndata1\nrkey\ndata2\n\n\n\n\n0\nb\n0\nb\n1\n\n\n1\nb\n1\nb\n1\n\n\n2\nb\n6\nb\n1\n\n\n3\na\n2\na\n0\n\n\n4\na\n4\na\n0\n\n\n5\na\n5\na\n0\n\n\n\n\n\n\n\n\nBy default merge does an inner join, that the keys in the result are the interesection found in both tables. Below are different types of merge. To specify the method for merge, the option is how.\n\ninner\nleft\nright\nouter\n\nLet’s see the following examples.\n\n\n\ndf1 = pd.DataFrame({'Key': [1, 2], 'A': [0, 2], 'B': [1, 3]})\ndf1\n\n\n\n\n\n\n\n\nKey\nA\nB\n\n\n\n\n0\n1\n0\n1\n\n\n1\n2\n2\n3\n\n\n\n\n\n\n\n\n\n\ndf2 = pd.DataFrame({'Key': [1, 3], 'C': [0, 2], 'D': [1, 3]})\ndf2\n\n\n\n\n\n\n\n\nKey\nC\nD\n\n\n\n\n0\n1\n0\n1\n\n\n1\n3\n2\n3\n\n\n\n\n\n\n\n\n\n\n\n\npd.merge(df1, df2, on='Key', how='inner')\n\n\n\n\n\n\n\n\nKey\nA\nB\nC\nD\n\n\n\n\n0\n1\n0\n1\n0\n1\n\n\n\n\n\n\n\n\n\n\npd.merge(df1, df2, on='Key', how='outer')\n\n\n\n\n\n\n\n\nKey\nA\nB\nC\nD\n\n\n\n\n0\n1\n0.0\n1.0\n0.0\n1.0\n\n\n1\n2\n2.0\n3.0\nNaN\nNaN\n\n\n2\n3\nNaN\nNaN\n2.0\n3.0\n\n\n\n\n\n\n\n\n\n\n\n\npd.merge(df1, df2, on='Key', how='left')\n\n\n\n\n\n\n\n\nKey\nA\nB\nC\nD\n\n\n\n\n0\n1\n0\n1\n0.0\n1.0\n\n\n1\n2\n2\n3\nNaN\nNaN\n\n\n\n\n\n\n\n\n\n\npd.merge(df1, df2, on='Key', how='right')\n\n\n\n\n\n\n\n\nKey\nA\nB\nC\nD\n\n\n\n\n0\n1\n0.0\n1.0\n0\n1\n\n\n1\n3\nNaN\nNaN\n2\n3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf a key combination appears more than once in both tables, the resulting table will have the Cartesian product of the associated data. Here is a very basic example with one unique key combination.\n\ndf1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'b'],\n                    'data1': range(6)})\ndf2 = pd.DataFrame({'key': ['a', 'b', 'a', 'b', 'd'],\n                    'data2': range(5)})\npd.merge(df1, df2, on='key', how='left')\n\n\n\n\n\n\n\n\nkey\ndata1\ndata2\n\n\n\n\n0\nb\n0\n1.0\n\n\n1\nb\n0\n3.0\n\n\n2\nb\n1\n1.0\n\n\n3\nb\n1\n3.0\n\n\n4\na\n2\n0.0\n\n\n5\na\n2\n2.0\n\n\n6\nc\n3\nNaN\n\n\n7\na\n4\n0.0\n\n\n8\na\n4\n2.0\n\n\n9\nb\n5\n1.0\n\n\n10\nb\n5\n3.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf the merge keys in a DataFrame is in its index instead of column(s), we could pass left_index=True or right_index=True or both instead of setting left_on/right_on/on.\n\n\n\nExample 4.7 If we want to really create a Cartesian product, we may use the option how='cross'. For example, we would like to generate a deck of cards, we may use the following codes.\n\nsuit = pd.DataFrame({'suit': ['spades', 'hearts', 'clubs', 'diamonds']})\nface = pd.DataFrame({'face': list(range(1, 14))})\ndeck = pd.merge(suit, face, how='cross')\n\n\n\n\n\n\n\n\n\n\n\npd.concat() function\n\n\n\n\n\nThe concat() function (in the main pandas namespace) performs concatenation operations along an axis while performing optional set logic (union or intersection) of the indexes (if any) on the other axes.\n\nimport pandas as pd\n\ndf1 = pd.DataFrame(\n    {\n        \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n        \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n        \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n        \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n    },\n    index=[0, 1, 2, 3],\n)\n\ndf2 = pd.DataFrame(\n    {\n        \"A\": [\"A4\", \"A5\", \"A6\", \"A7\"],\n        \"B\": [\"B4\", \"B5\", \"B6\", \"B7\"],\n        \"C\": [\"C4\", \"C5\", \"C6\", \"C7\"],\n        \"D\": [\"D4\", \"D5\", \"D6\", \"D7\"],\n    },\n    index=[4, 5, 6, 7],\n)\n\ndf3 = pd.DataFrame(\n    {\n        \"A\": [\"A8\", \"A9\", \"A10\", \"A11\"],\n        \"B\": [\"B8\", \"B9\", \"B10\", \"B11\"],\n        \"C\": [\"C8\", \"C9\", \"C10\", \"C11\"],\n        \"D\": [\"D8\", \"D9\", \"D10\", \"D11\"],\n    },\n    index=[8, 9, 10, 11],\n)\n\npd.concat([df1, df2, df3], keys=['x', 'y', 'z'])\n\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\nx\n0\nA0\nB0\nC0\nD0\n\n\n1\nA1\nB1\nC1\nD1\n\n\n2\nA2\nB2\nC2\nD2\n\n\n3\nA3\nB3\nC3\nD3\n\n\ny\n4\nA4\nB4\nC4\nD4\n\n\n5\nA5\nB5\nC5\nD5\n\n\n6\nA6\nB6\nC6\nD6\n\n\n7\nA7\nB7\nC7\nD7\n\n\nz\n8\nA8\nB8\nC8\nD8\n\n\n9\nA9\nB9\nC9\nD9\n\n\n10\nA10\nB10\nC10\nD10\n\n\n11\nA11\nB11\nC11\nD11\n\n\n\n\n\n\n\nThe default way of pd.concat() is vertically. Note that it will check the column names. If the column names don’t match, new columns will be created and nan values will be assigned.\nIf you want to concatenate the DataFrame horizontally you need to add axis=1 option. Similarly, row index will be checked before concatenating. See the following example.\n\nExample 4.8  \n\npd.concat([df1, df2, df3], axis=1)\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nA\nB\nC\nD\nA\nB\nC\nD\n\n\n\n\n0\nA0\nB0\nC0\nD0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\nA1\nB1\nC1\nD1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\nA2\nB2\nC2\nD2\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n3\nA3\nB3\nC3\nD3\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\nNaN\nNaN\nNaN\nNaN\nA4\nB4\nC4\nD4\nNaN\nNaN\nNaN\nNaN\n\n\n5\nNaN\nNaN\nNaN\nNaN\nA5\nB5\nC5\nD5\nNaN\nNaN\nNaN\nNaN\n\n\n6\nNaN\nNaN\nNaN\nNaN\nA6\nB6\nC6\nD6\nNaN\nNaN\nNaN\nNaN\n\n\n7\nNaN\nNaN\nNaN\nNaN\nA7\nB7\nC7\nD7\nNaN\nNaN\nNaN\nNaN\n\n\n8\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nA8\nB8\nC8\nD8\n\n\n9\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nA9\nB9\nC9\nD9\n\n\n10\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nA10\nB10\nC10\nD10\n\n\n11\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nA11\nB11\nC11\nD11\n\n\n\n\n\n\n\n\n\nExample 4.9 Consider the deck example from Example 4.7. This time we would like to use pd.concat() to get the result.\n\nsuitlist = ['spades', 'hearts', 'clubs', 'diamonds']\nfacelist = list(range(1, 14))\ndecklist = [pd.DataFrame({'suit': suit, 'face': facelist}) for suit in suitlist]\ndeck = pd.concat(decklist, ignore_index=True)",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Package: `pandas`</span>"
    ]
  },
  {
    "objectID": "contents/4/intro.html#data-aggregation-and-group-operations",
    "href": "contents/4/intro.html#data-aggregation-and-group-operations",
    "title": "4  Package: pandas",
    "section": "4.5 Data Aggregation and Group Operations",
    "text": "4.5 Data Aggregation and Group Operations\n\n4.5.1 split-apply-combine model\nWe would like to apply group operations based on the split-apply-combine model.\n\nIn the first stage of the process, data contained in a pandas object is split into groups based on one or more keys that you provide. We then use .groupby(keys) to perform the split step. The result is a grouped groupby object.\nOnce this is done, a function is applied to each group, producing a new value.\nFinally the results of all those function applications are combined into a result object. We may apply groupby functions directly as methods to groupby objects.The result is the combined result object.\n\n\n\n\n\n\n\nAn example\n\n\n\n\n\n\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({'key1' : ['a', 'a', 'b', 'b', 'a'],\n                   'key2' : ['one', 'two', 'one', 'two', 'one'],\n                   'data1' : np.random.randn(5),\n                   'data2' : np.random.randn(5)})\ndf\n\n\n\n\n\n\n\n\nkey1\nkey2\ndata1\ndata2\n\n\n\n\n0\na\none\n0.337494\n0.221321\n\n\n1\na\ntwo\n0.231200\n-0.380031\n\n\n2\nb\none\n-1.443860\n-1.159261\n\n\n3\nb\ntwo\n-0.171958\n0.105262\n\n\n4\na\none\n-0.829197\n-0.696895\n\n\n\n\n\n\n\nNow we want to group data1 in df by key1.\n\ngrouped = df['data1'].groupby(df['key1'])\ngrouped\n\n&lt;pandas.core.groupby.generic.SeriesGroupBy object at 0x000001E4A1C3AAD0&gt;\n\n\nWhat we get is a groupby object and we could apply group functions to it.\nThe method to look at each group is .get_group().\n\ngrouped.get_group('a')\n\n0    0.337494\n1    0.231200\n4   -0.829197\nName: data1, dtype: float64\n\n\nWe may directly apply some group functions to the groupby object.\n\ngrouped.mean()\n\nkey1\na   -0.086834\nb   -0.807909\nName: data1, dtype: float64\n\n\n\ngrouped.size()\n\nkey1\na    3\nb    2\nName: data1, dtype: int64\n\n\nWe could iterate over groups.\n\nfor name, group in grouped:\n    print('name', name)\n    print('group', group)\n\nname a\ngroup 0    0.337494\n1    0.231200\n4   -0.829197\nName: data1, dtype: float64\nname b\ngroup 2   -1.443860\n3   -0.171958\nName: data1, dtype: float64\n\n\nWe could convert the group object into list and dictionary.\n\nlist(grouped)\n\n[('a',\n  0    0.337494\n  1    0.231200\n  4   -0.829197\n  Name: data1, dtype: float64),\n ('b',\n  2   -1.443860\n  3   -0.171958\n  Name: data1, dtype: float64)]\n\n\n\ndict(list(grouped))\n\n{'a': 0    0.337494\n 1    0.231200\n 4   -0.829197\n Name: data1, dtype: float64,\n 'b': 2   -1.443860\n 3   -0.171958\n Name: data1, dtype: float64}\n\n\n\n\n\n\n\n4.5.2 Built-in aggregation functions\nThe following functions directly work with groupby objects. You may try them by yourselves.\n\n.describe()\n.count()\n.sum()\n.mean()\n.median\n.std(), .var()\n.min(), .max()\n.prod()\n.first(), .last() \n\n\n\n4.5.3 Function Application and Mapping\nWe may apply functions to each row/column of a DataFrame. If the function is a built-in function that is compatible with DataFrame, you can directly call the function that it will be applied automatically to each row/column. If it is not, we can call apply to get the desired result.\n\n\n\n\n\n\nmap\n\n\n\n\n\nTo understand the behaviour of map, you may treat it as a loop, through a Series. pandas goes through each item in the Series and perform operations as instructed. If there is a returned value, it will be recorded along the Sereis.\n\nimport pandas as pd\n\nind = pd.Series(['Ohio', 'Colorado', 'New York'])\nind\n\n0        Ohio\n1    Colorado\n2    New York\ndtype: object\n\n\n\nind.map(lambda x: x[:4].upper())\n\n0    OHIO\n1    COLO\n2    NEW \ndtype: object\n\n\nIn the example we go through each item in ind. Each item is a string. We pick the first 4 characters, and change them to be upper case.\nNote that this operation can also be done by string method. These are two different methods but the results are the same.\n\nind.str[:4].str.upper()\n\n0    OHIO\n1    COLO\n2    NEW \ndtype: object\n\n\n\n\n\n\n\n\n\n\n\napply\n\n\n\n\n\napply is very similar to map, but for DataFrame. The default setting is to go through each column of a DataFrame, and the input is the column. You may use the argument axis=1 to change it to go through each row. Please see the following example.\n\nExample 4.10  \n\nimport pandas as pd\ndata = pd.DataFrame(np.random.rand(4, 4),\n                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n                    columns=['one', 'two', 'three', 'four'])\ndata\n\n\n\n\n\n\n\n\none\ntwo\nthree\nfour\n\n\n\n\nOhio\n0.280279\n0.964668\n0.917025\n0.808800\n\n\nColorado\n0.191700\n0.585183\n0.368357\n0.522114\n\n\nUtah\n0.805022\n0.735904\n0.905712\n0.731672\n\n\nNew York\n0.851517\n0.704203\n0.242845\n0.321028\n\n\n\n\n\n\n\n\nf = lambda x: x.max() - x.min()\n\ndata.apply(f)\n\none      0.659817\ntwo      0.379485\nthree    0.674180\nfour     0.487772\ndtype: float64\n\n\nChange axis to find the range for each row.\n\ndata.apply(f, axis=1)\n\nOhio        0.684389\nColorado    0.393483\nUtah        0.174040\nNew York    0.608672\ndtype: float64\n\n\n\nWe can use more complicated function to get more complicated result.\n\nExample 4.11  \n\ndata = pd.DataFrame(np.random.rand(4, 4),\n                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n                    columns=['one', 'two', 'three', 'four'])\n\nf = lambda x: pd.Series([x.max(), x.min()], index=['max', 'min'])\n\ndata.apply(f)\n\n\n\n\n\n\n\n\none\ntwo\nthree\nfour\n\n\n\n\nmax\n0.837382\n0.245228\n0.581156\n0.868964\n\n\nmin\n0.098547\n0.080676\n0.093411\n0.320024\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.5.4 Some examples\n\nExample 4.12 Consider the following DataFrame.\n\nimport pandas as pd\nimport numpy as np\ndf = pd.DataFrame({'location': ['East', 'East', 'East', 'East',\n                                'West', 'West', 'West', 'West'],\n                   'data': np.random.randn(8)},\n                   index=['Ohio', 'New York', 'Vermont', 'Florida',\n                          'Oregon', 'Nevada', 'California', 'Idaho'])\ndf.loc[['Vermont', 'Nevada', 'Idaho'], 'data'] = np.nan\ndf\n\n\n\n\n\n\n\n\nlocation\ndata\n\n\n\n\nOhio\nEast\n0.144540\n\n\nNew York\nEast\n-0.108340\n\n\nVermont\nEast\nNaN\n\n\nFlorida\nEast\n-0.071206\n\n\nOregon\nWest\n0.731992\n\n\nNevada\nWest\nNaN\n\n\nCalifornia\nWest\n-1.018345\n\n\nIdaho\nWest\nNaN\n\n\n\n\n\n\n\nWe would like to fill in NA values with the mean from each location group.\n\n\n\n\n\n\nTips\n\n\n\n\n\n\ndf.groupby('location', group_keys=False).apply(lambda x: x.fillna(x.mean()))\n\n\n\n\n\n\n\n\ndata\n\n\n\n\nOhio\n0.144540\n\n\nNew York\n-0.108340\n\n\nVermont\n-0.011668\n\n\nFlorida\n-0.071206\n\n\nOregon\n0.731992\n\n\nNevada\n-0.143177\n\n\nCalifornia\n-1.018345\n\n\nIdaho\n-0.143177\n\n\n\n\n\n\n\nThe argument group_keys=False refers to the setting whether you want to group_keys to be presented. If it is True, the result looks like this.\n\ndf.groupby('location', group_keys=True).apply(lambda x: x.fillna(x.mean()))\n\n\n\n\n\n\n\n\n\ndata\n\n\nlocation\n\n\n\n\n\n\nEast\nOhio\n0.144540\n\n\nNew York\n-0.108340\n\n\nVermont\n-0.011668\n\n\nFlorida\n-0.071206\n\n\nWest\nOregon\n0.731992\n\n\nNevada\n-0.143177\n\n\nCalifornia\n-1.018345\n\n\nIdaho\n-0.143177\n\n\n\n\n\n\n\n\n\n\nWe could also fill in NA values with predefined values, similar to the non-groupby case.\n\n\n\n\n\n\nTips\n\n\n\n\n\n\npredefined = {'East': 0.1, 'West': -0.5}\ndf.groupby('location', group_keys=True).apply(lambda x: x.fillna(predefined[x.name]))\n\n\n\n\n\n\n\n\n\nlocation\ndata\n\n\nlocation\n\n\n\n\n\n\n\nEast\nOhio\nEast\n0.144540\n\n\nNew York\nEast\n-0.108340\n\n\nVermont\nEast\n0.100000\n\n\nFlorida\nEast\n-0.071206\n\n\nWest\nOregon\nWest\n0.731992\n\n\nNevada\nWest\n-0.500000\n\n\nCalifornia\nWest\n-1.018345\n\n\nIdaho\nWest\n-0.500000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChaining commands\n\n\n\nYou may chain commands to a DataFrame, just like the examples shown above. If the commands are too long:\n\na () has to be used to indicate that this is a multiline command, and\nthe line is broken before the . sybmol.\n\nPlease see the following example.\n\n(df.groupby('location', group_keys=False)\n    .apply(lambda x: x.fillna(predefined[x.name]))\n    .reset_index()\n    .groupby('location')\n    .max()\n)\n\n\n\n\n\n\n\n\nindex\ndata\n\n\nlocation\n\n\n\n\n\n\nEast\nVermont\n0.144540\n\n\nWest\nOregon\n0.731992",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Package: `pandas`</span>"
    ]
  },
  {
    "objectID": "contents/4/intro.html#read-and-write-files",
    "href": "contents/4/intro.html#read-and-write-files",
    "title": "4  Package: pandas",
    "section": "4.6 Read and write files",
    "text": "4.6 Read and write files\n\n4.6.1 Read files\nIn most cases we will read data from a csv file or an excel file.\n\n\n\n\n\n\nRead csv files\n\n\n\n\n\nA csv file is a plain txt file, with a fixed format. It consists of rows and columns. Rows are separated by newline symbol, which is usually \\n. Columns are separated by a separator. Common separators include empty spaces, comma ,, semi-column ;, tab space \\t. There might be other speical separators, depending on the creators of the specific csv files.\nIn pandas, you may use pd.read_csv() function to read a csv file.\n\nThe argument sep is used to set separators. The default is ,.\nThe argument names is used to set the column names. Otherwise the column names will be generated and is highly unlikely to be directly usable.\nThe argument header will choose the header row and only parse the lines after it. If there is no header, you may set header=None.\nThe argument index_col is used to set the index column(s). If it is False, the index will be automatically generated from 0. If it is set to a list of columns, the result will be a multi-index system.\n\nYou may read the document for more arguments.\nPlease see the following example.\n\nExample 4.13 The file is yob1880.txt. This is from the US Baby names dataset. It provides the counts of each US baby names born in 1880. You may use any txt editor to open the file. The first few rows are like the following:\nMary,F,7065\nAnna,F,2604\nEmma,F,2003\nElizabeth,F,1939\nMinnie,F,1746\nMargaret,F,1578\nIt seems that sep is the default ,. So you may directly directly read it into a DataFrame by pd.read_csv().\n\nimport pandas as pd\n\ndf = pd.read_csv('assests/datasets/yob1880.txt')\ndf.head()\n\n\n\n\n\n\n\n\nMary\nF\n7065\n\n\n\n\n0\nAnna\nF\n2604\n\n\n1\nEmma\nF\n2003\n\n\n2\nElizabeth\nF\n1939\n\n\n3\nMinnie\nF\n1746\n\n\n4\nMargaret\nF\n1578\n\n\n\n\n\n\n\nPlease look at the header of the DataFrame. It is supposed to be the first data. Therefore there is no header in the original file. So the correct way to read the file is\n\nimport pandas as pd\n\ndf = pd.read_csv('assests/datasets/yob1880.txt',\n                 header=None,\n                 names=['Name', 'Sex', 'Counts'])\ndf.head()\n\n\n\n\n\n\n\n\nName\nSex\nCounts\n\n\n\n\n0\nMary\nF\n7065\n\n\n1\nAnna\nF\n2604\n\n\n2\nEmma\nF\n2003\n\n\n3\nElizabeth\nF\n1939\n\n\n4\nMinnie\nF\n1746\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRead Excel files\n\n\n\n\n\npandas provides pd.read_excel() function to read Excel files. Since Excel files are much more complicated than csv files, it requires more setting. One of the most important different setting is the engine. pandas needs you to specify a way (an engine) to understand Excel files. For the newer Excel file .xlsx, it is recommended to use the engine openpyxl.\nIf you don’t have openpyxl installed, you may use the following code to install it.\npip install openpyxl\nMany options, like header, names and index_col, are very similar to pd.read_csv(). Some additional remarks:\n\nThere is no sep argument since columns are not separated based on separators.\nThe argument sheet_name is used to choose which sheet(s) you want to read.\nThe argument nrows is used to set the number of rows to parse.\n\nYou may read the document for more arguments.\n\nExample 4.14 The file can be downloaded from here. This is the result of the Pre-Post test of a class for the course COURSE1001. You may first use Microsoft Office or other spreadsheet applications to open the file to have some ideas what it look like.\nHere is the screenshot of the first few columns. Last and First refers to the last name and the first name of the student, while Last0X and First0X are students’ fake names.\n\nNote that this files contains two DataFrames.\n\nThe first is the result of the pretest, which is from row 3 to row 11, with the header row 2.\nThe second is the result of the posttest, which is from row 15 to row 23, with the header row 14. To read the file, the code is as follows:\n\n\nimport pandas as pd\n\ndf_pre = pd.read_excel('assests/datasets/prepost.xlsx',\n                       engine='openpyxl',\n                       header=2, \n                       nrows=10)\ndf_pre \n\n\n\n\n\n\n\n\nLast\nFirst\nT#\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nUnnamed: 13\n\n\n\n\n0\nLast01\nFirst01\nT01\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\nNaN\n\n\n1\nLast02\nFirst02\nT02\n0\n0\n1\n0\n0\n0\n0\n0\n1\n1\nNaN\n\n\n2\nLast03\nFirst03\nT03\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n\n\n\n3\nLast04\nFirst04\nT04\n1\n0\n0\n1\n0\n0\n0\n0\n0\n0\nNaN\n\n\n4\nLast05\nFirst05\nT05\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\nNaN\n\n\n5\nLast06\nFirst06\nT06\n0\n0\n1\n0\n0\n0\n1\n0\n0\n1\nNaN\n\n\n6\nLast07\nFirst07\nT07\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNaN\n\n\n7\nLast08\nFirst08\nT08\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\nNaN\n\n\n8\nLast09\nFirst09\nT09\n0\n0\n0\n0\n0\n0\n1\n0\n0\n1\nNaN\n\n\n\n\n\n\n\n\ndf_post = pd.read_excel('assests/datasets/prepost.xlsx',\n                        engine='openpyxl',\n                        header=14,\n                        nrows=10)                      \ndf_post\n\n\n\n\n\n\n\n\nLast\nFirst\nT#\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nUnnamed: 13\n\n\n\n\n0\nLast01\nFirst01\nT01\n1\n1\n0\n1\n0\n0\n0\n0\n1\n1\nNaN\n\n\n1\nLast02\nFirst02\nT02\n0\n0\n0\n1\n0\n0\n1\n0\n0\n0\nNaN\n\n\n2\nLast03\nFirst03\nT03\n1\n1\n1\n1\n1\n1\n0\n0\n1\n0\nNaN\n\n\n3\nLast04\nFirst04\nT04\n1\n1\n0\n1\n0\n1\n0\n0\n1\n0\nNaN\n\n\n4\nLast05\nFirst05\nT05\n1\n1\n1\n1\n1\n1\n0\n0\n0\n0\nNaN\n\n\n5\nLast06\nFirst06\nT06\n1\n0\n0\n0\n0\n0\n0\n0\n0\n1\nNaN\n\n\n6\nLast07\nFirst07\nT07\n1\n1\n0\n1\n0\n0\n0\n0\n0\n0\nNaN\n\n\n7\nLast08\nFirst08\nT08\n0\n1\n1\n0\n1\n0\n0\n1\n1\n0\nNaN\n\n\n8\nLast09\nFirst09\nT09\n1\n1\n1\n1\n1\n1\n0\n1\n0\n0\nNaN\n\n\n\n\n\n\n\nIt seems that the original files have an additional column Unnamed: 13 containing nan values that should be dropped. Then it is not necessary to read it from the original file. Here we could use the argument usecols to select the first 13 columns. We only show the example of pretest result.\n\ndf_pre = pd.read_excel('assests/datasets/prepost.xlsx',\n                       engine='openpyxl',\n                       header=2, \n                       nrows=10,\n                       usecols=list(range(13)))\ndf_pre \n\n\n\n\n\n\n\n\nLast\nFirst\nT#\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\n0\nLast01\nFirst01\nT01\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n\n\n1\nLast02\nFirst02\nT02\n0\n0\n1\n0\n0\n0\n0\n0\n1\n1\n\n\n2\nLast03\nFirst03\nT03\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n\n\n3\nLast04\nFirst04\nT04\n1\n0\n0\n1\n0\n0\n0\n0\n0\n0\n\n\n4\nLast05\nFirst05\nT05\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n5\nLast06\nFirst06\nT06\n0\n0\n1\n0\n0\n0\n1\n0\n0\n1\n\n\n6\nLast07\nFirst07\nT07\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n7\nLast08\nFirst08\nT08\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n\n\n8\nLast09\nFirst09\nT09\n0\n0\n0\n0\n0\n0\n1\n0\n0\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.6.2 Write files\nWe will only talk about writing in csv. The function is df.to_csv(). It is straightforward.\n\nThe argument index is used to control whether you want to write index into the file. The default is True. If the index doesn’t contain any real information, we usually set it to be False.",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Package: `pandas`</span>"
    ]
  },
  {
    "objectID": "contents/4/intro.html#example-movies",
    "href": "contents/4/intro.html#example-movies",
    "title": "4  Package: pandas",
    "section": "4.7 Example: Movies",
    "text": "4.7 Example: Movies\nBelow we explore the MovieLens 1M datasets. You may download it from this link. This is a .dat file, and you may use the following code to read it into a DataFrame.\n\nimport pandas as pd\nmnames = ['movie_id', 'title', 'genres']\nmovies = pd.read_table('assests/datasets/movies.dat', sep='::',\n                       header=None, names=mnames, engine=\"python\",\n                       encoding='ISO-8859-1')\nmovies.head()\n\n\n\n\n\n\n\n\nmovie_id\ntitle\ngenres\n\n\n\n\n0\n1\nToy Story (1995)\nAnimation|Children's|Comedy\n\n\n1\n2\nJumanji (1995)\nAdventure|Children's|Fantasy\n\n\n2\n3\nGrumpier Old Men (1995)\nComedy|Romance\n\n\n3\n4\nWaiting to Exhale (1995)\nComedy|Drama\n\n\n4\n5\nFather of the Bride Part II (1995)\nComedy\n\n\n\n\n\n\n\nIn this example we concentrate on exploring the genres information. We first want to find all genres in this dataset. The idea is:\n\nsplit each item in the genres column by | to get a list.\ngo through each item in the genres column, and union all lists together.\n\nThis can be done by the map function.\n\n\n\n\n\n\nTips\n\n\n\n\n\n\nall_genres = list()\nmovies['genres'].map(lambda x: all_genres.extend(x.split('|')))\n\n0       None\n1       None\n2       None\n3       None\n4       None\n        ... \n3878    None\n3879    None\n3880    None\n3881    None\n3882    None\nName: genres, Length: 3883, dtype: object\n\n\nall_genres is the list of all genres (with duplicates).\nIn the output of the above code you may see many None in each row. This is because the lambda function used in map doesn’t have a return value. However after applying the function to each row, new genres information is added to the list all_genres.\n\n\n\nThen we would like to drop all the duplicates to get the list of all unique genres.\n\n\n\n\n\n\nTips\n\n\n\n\n\n\ngenres = pd.unique(all_genres)\ngenres\n\nC:\\Users\\Xinli\\AppData\\Local\\Temp\\ipykernel_27964\\17161066.py:1: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n  genres = pd.unique(all_genres)\n\n\narray(['Animation', \"Children's\", 'Comedy', 'Adventure', 'Fantasy',\n       'Romance', 'Drama', 'Action', 'Crime', 'Thriller', 'Horror',\n       'Sci-Fi', 'Documentary', 'War', 'Musical', 'Mystery', 'Film-Noir',\n       'Western'], dtype=object)\n\n\ngenres is the list of all unique genres.",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Package: `pandas`</span>"
    ]
  },
  {
    "objectID": "contents/4/intro.html#exercises",
    "href": "contents/4/intro.html#exercises",
    "title": "4  Package: pandas",
    "section": "4.8 Exercises",
    "text": "4.8 Exercises\nMany problems are based on [1].\n\nExercise 4.1 Let df be a DataFrame. Please answer the following questions in a Markdown cell.\n\nWhat does df[0] do?\nWhat does df[[0]] do?\nWhat does df[0:1] do?\n\n\n\nExercise 4.2 Please use the following code to generate a series ser, and then finish the following tasks.\n\nimport pandas as pd\nimport numpy as np\n\n\nmylist = list('abcedfghijklmnopqrstuvwxyz')\nmyarr = np.arange(26)\nmydict = dict(zip(mylist, myarr))\nser = pd.Series(mydict)\n\n\nConvert the series ser into a dataframe df with its index as another column on the dataframe.\nPick the two columns of df and set them into two serieses ser1 and ser2.\nCombine two series ser1 and ser2 to form a new dataframe newdf, and name their columns ser1 and ser2.\n\n\n\nExercise 4.3 Consider two serieses ser1 and ser2. You may use the following ser1 and ser2 as an example. The output of each questions below should be a series. You may want to learn the following commands:\n\nnp.union1d()\nnp.intersect1d()\nnp.isin()\n\n\nimport pandas as pd\n\nser1 = pd.Series([1, 2, 3, 4, 5])\nser2 = pd.Series([4, 5, 6, 7, 8])\n\n\nFind all the elements from ser1 that are also in ser2.\nFind all the elements from ser2 that are also in ser1.\nFrom ser1 remove items present in ser2.\nFind the union of ser1 and ser2.\nFind the intersection of ser1 and ser2.\nFind all the elemetns that are in either ser1 or ser2, but not both.\n\n\n\nExercise 4.4 Consider the following DataFrame.\n\nimport pandas as pd\n\ndata = pd.DataFrame(np.arange(16).reshape((4, 4)),\n                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n                    columns=['one', 'two', 'three', 'four'])\n\n\nPlease select the column two.\nPlease select the second and the third row.\nPlease find the rows that the column three value is bigger than 5.\nPlease find the last row that the column three value is bigger than 5.\nPlease find the rows that the column three value is bigger than 5, and display the resulted DataFrame with only Colorado and Utah row and four and one columns, in the specified order.\n\n\n\n\nExercise 4.5 Consider the following Series.\n\nimport pandas as pd\nimport numpy as np\nser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))\n\n\nPlease use pd.Series.value_counts() to calculte the frequency counts of each unique value of the following Series.\nPlease keep the top 2 most frequent items of ser as it is and replace everything else as Other.\n\n\n\n\n\nExercise 4.6 Consider the Series ser:\n\nimport pandas as pd\nimport numpy as np\nser = pd.Series(np.random.randint(1, 10, 7))\n\nFind the positions of numbers that are multiples of 3 from ser.\n\n\nExercise 4.7 Compute the mean of weights of each fruit.\n\nimport pandas as pd\nfruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\nweights = pd.Series(np.linspace(1, 10, 10))\ndf = pd.DataFrame({'fruit': fruit, 'weights': weights})\n\n\n\nExercise 4.8 Consider the following DataFrame.\n\nimport pandas as pd\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\n\nCheck if df has any missing values.\nPlease count the number of missing values in each column.\nPlease replace all missing values in Min.Price and Max.Price with their mean respectively.",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Package: `pandas`</span>"
    ]
  },
  {
    "objectID": "contents/5/intro.html#matplotlib.pyplot",
    "href": "contents/5/intro.html#matplotlib.pyplot",
    "title": "5  Visualization",
    "section": "5.1 matplotlib.pyplot",
    "text": "5.1 matplotlib.pyplot\nmatplotlib is a modern and classic plot library. Its main features are inspired by MATLAB. In this book we mostly use pyplot package from matplotlib. We use the following import convention:\n\nimport matplotlib.pyplot as plt\n\n\n5.1.1 matplotlib interface\nmatplotlib has two major application interfaces, or styles of using the library:\n\nAn explicit Axes interface that uses methods on a Figure or Axes object to create other Artists, and build a visualization step by step. You may treat this Figure object as a canvas, and Axes as plots on a canvas. There might be one or more plots on one canvas. This has also been called an object-oriented interface.\nAn implicit pyplot interface that keeps track of the last Figure and Axes created, and adds Artists to the object it thinks the user wants.\n\nHere is an example of an explicit interface.\n\nfig = plt.figure()\nax = fig.subplots()\nax.plot([1, 2, 3, 4], [0, 0.5, 1, 0.2])\n\n\n\n\n\n\n\n\nHere is an example of an implicit interface.\n\nplt.plot([1, 2, 3, 4], [0, 0.5, 1, 0.2])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf the plot is not shown, you may want to type plt.show() to force the plot being rendered. However, to make plt.show() work is related to switching matplotlib backends, and is sometimes very complicated.\n\n\nThe purpose to explicitly use fig and ax is to have more control over the configurations. The first important configuration is subplots.\n\n.subplot()\n.subplots()\n.add_subplot()\n\nPlease see the following examples.\n\nExample 5.1  \n\nplt.subplot(1, 2, 1)\nplt.plot([1, 2, 3], [0, 0.5, 0.2])\n\n\n\n\n\n\n\n\n\n\nExample 5.2  \n\nplt.subplot(1, 2, 1)\nplt.plot([1, 2, 3], [0, 0.5, 0.2])\nplt.subplot(1, 2, 2)\nplt.plot([3, 2, 1], [0, 0.5, 0.2])\n\n\n\n\n\n\n\n\n\n\nExample 5.3  \n\nfig, axs = plt.subplots(1, 2)\naxs[0].plot([1, 2, 3], [0, 0.5, 0.2])\naxs[1].plot([3, 2, 1], [0, 0.5, 0.2])\n\n\n\n\n\n\n\n\n\n\nExample 5.4  \n\nimport numpy as np\nfig = plt.figure()\nax1 = fig.add_subplot(2, 2, 1)\nax2 = fig.add_subplot(2, 2, 3)\nax3 = fig.add_subplot(1, 2, 2)\n\nax3.plot([1, 2, 3], [0, 0.5, 0.2])\n\n\n\n\n\n\n\n\nThe auguments 2, 2, 1 means that we split the figure into a 2x2 grid and the axis ax1 is in the 1st position. The rest is understood in the same way.\n\n\nExample 5.5 If you don’t explicitly initialize fig and ax, you may use plt.gcf() and plt.gca() to get the handles for further operations.\n\nplt.subplot(1, 2, 1)\nax = plt.gca()\nax.plot([1, 2, 3], [0, 0.5, 0.2])\n\nplt.subplot(1, 2, 2)\nax = plt.gca()\nax.plot([3, 2, 1], [0, 0.5, 0.2])\n\n\n\n\n\n\n\n\n\nThe purpose to explicitly use fig and ax is to have more control over the configurations. For example, when generate a figure object, we may use figsize=(3, 3) as an option to set the figure size to be 3x3. dpi is another commonly modified option.\n\nfig = plt.figure(figsize=(2, 2), dpi=50)\nplt.plot([1, 2, 3], [0, 0.5, 0.2])\n\n\n\n\n\n\n\n\nIf you would like to change this setting later, you may use the following command before plotting.\n\nfig.set_size_inches(10, 10)\nfig.set_dpi(300)\nplt.plot([1, 2, 3], [0, 0.5, 0.2])\n\n\n\n\n\n\n\n\nYou may use fig.savefig('filename.png') to save the image into a file.\n\n\n5.1.2 Downstream packages\nThere are multiple packages depending on matplotlib to provide plotting. For example, you may directly plot from a Pandas DataFrame or a Pandas Series.\n\nExample 5.6  \n\nimport pandas as pd\nimport numpy as np\ns = pd.Series(np.random.randn(10).cumsum(), index=np.arange(0, 100, 10))\ns.plot()\n\n\n\n\n\n\n\n\n\ndf = pd.DataFrame(np.random.randn(10, 4).cumsum(0),\n                  columns=['A', 'B', 'C', 'D'],\n                  index=np.arange(0, 100, 10))\ndf.plot()\n\n\n\n\n\n\n\n\n\n\n\n5.1.3 plotting\n\n5.1.3.1 plt.plot()\nThis is the command for line plotting. You may use linestyle='--' and color='g' to control the line style and color. The style can be shortened as g--.\nHere is a list of commonly used linestyles and colors.\n\nline styles\n\nsolid or -\ndashed or --\ndashdot or -.\ndotted or :\n\nmarker styles\n\no as circle markers\n+ as plusses\n^ as triangles\ns as squares\n\ncolors\n\nb as blue\ng as green\nr as red\nk as black\nw as white\n\n\nThe input of plt.plot() is two lists x and y. If there is only one list inputed, that one will be recognized as y and the index of elements of y will be used as the dafault x.\n\nExample 5.7  \n\nplt.plot(np.random.randn(30).cumsum(), color='r', linestyle='--', marker='o')\n\n\n\n\n\n\n\n\nYou may compare it with this Example for the purpose of seaborn from next Section.\n\n\n\n5.1.3.2 plt.bar() and plt.barh()\nThe two commands make vertical and horizontal bar plots, respectively.\n\nExample 5.8  \n\nimport pandas as pd\ndata = pd.Series(np.random.rand(16), index=list('abcdefghijklmnop'))\n\nfig, axes = plt.subplots(2, 1)\naxes[0].bar(x=data.index, height=data, color='k', alpha=0.7)\naxes[1].barh(y=data.index, width=data, color='b', alpha=0.7)\n\n\n\n\n\n\n\n\nWe may also directly plot the bar plot from the Series.\n\nfig, axes = plt.subplots(2, 1)\ndata.plot.bar(ax=axes[0], color='k', alpha=0.7)\ndata.plot.barh(ax=axes[1], color='b', alpha=0.7)\n\n\n\n\n\n\n\n\n\nWith a DataFrame, bar plots group the values in each row together in a group in bars. This is easier if we directly plot from the DataFrame.\n\nExample 5.9  \n\ndf = pd.DataFrame(np.random.rand(6, 4),\n                  index=['one', 'two', 'three', 'four', 'five', 'six'],\n                  columns=pd.Index(['A', 'B', 'C', 'D'], name='Genus'))\ndf\n\n\n\n\n\n\n\nGenus\nA\nB\nC\nD\n\n\n\n\none\n0.262462\n0.116656\n0.930068\n0.771102\n\n\ntwo\n0.891918\n0.067489\n0.972940\n0.384689\n\n\nthree\n0.159806\n0.250860\n0.626908\n0.184446\n\n\nfour\n0.201407\n0.272930\n0.896539\n0.478261\n\n\nfive\n0.830620\n0.807160\n0.004148\n0.640755\n\n\nsix\n0.357200\n0.644064\n0.529182\n0.829858\n\n\n\n\n\n\n\n\ndf.plot.bar()\n\n\n\n\n\n\n\n\n\ndf.plot.barh(stacked=True, alpha=0.5)\n\n\n\n\n\n\n\n\n\n\n\n5.1.3.3 plt.scatter()\n\nExample 5.10  \n\nimport numpy as np\n\nN = 100\ndata = 0.9 * np.random.rand(N, 2)\narea = (20 * np.random.rand(N))**2 \nc = np.sqrt(area)\nplt.scatter(data[:, 0], data[:, 1], s=area, marker='^', c=c)\n\n\n\n\n\n\n\n\n\n\n\n5.1.3.4 plt.hist()\nHere are two plots with build-in statistics. The plot command will have statistics as outputs. To disable it we could send the outputs to a temporary variable _.\n\nExample 5.11  \n\nmu, sigma = 100, 15\nx = mu + sigma * np.random.randn(10000)\ny = mu-30 + sigma*2 * np.random.randn(10000)\n_ = plt.hist(x, 50, density=True, facecolor='g', alpha=0.75)\n_ = plt.hist(y, 50, density=True, facecolor='r', alpha=0.75)\n\n\n\n\n\n\n\n\n\n\n\n\n5.1.4 plt.boxplot()\n\nExample 5.12  \n\nspread = np.random.rand(50) * 100\ncenter = np.ones(30) * 50\nflier_high = np.random.rand(10) * 100 + 100\nflier_low = np.random.rand(10) * -100\ndata = np.concatenate((spread, center, flier_high, flier_low)).reshape(50, 2)\n\n_ = plt.boxplot(data, flierprops={'markerfacecolor': 'g', 'marker': 'D'})\n\n\n\n\n\n\n\n\n\n\n\n5.1.5 Titles, labels and legends\n\nTitles\n\nplt.title(label), plt.xlabel(label), plt.ylabel(label) will set the title/xlabel/ylabel.\nax.set_title(label), ax.set_xlabel(label), ax.set_ylabel(label) will do the same thing.\n\nLabels\n\nplt methods\n\nxlim(), ylim(), xticks(), yticks(), xticklabels(), yticklabels()\nall the above with arguments\n\nax methods\n\nget_xlim(), get_ylim(), etc..\nset_xlim(), set_ylim(), etc..\n\n\nLegneds\n\nFirst add label option to each piece when plotting, and then add ax.legends() or plt.legends() at the end to display the legends.\nYou may use handles, labels = ax.get_legend_handles_labels() to get the handles and labels of the legends, and modify them if necessary.\n\n\n\nExample 5.13  \n\nimport numpy as np\nfig, ax = plt.subplots(1, 1)\nax.plot(np.random.randn(1000).cumsum(), 'k', label='one')\nax.plot(np.random.randn(1000).cumsum(), 'r--', label='two')\nax.plot(np.random.randn(1000).cumsum(), 'b.', label='three')\n\nax.set_title('Example')\nax.set_xlabel('x')\nax.set_ylabel('y')\n\nax.set_yticks([-40, 0, 40])\nax.set_yticklabels(['good', 'bad', 'ugly'])\n\nax.legend(loc='best')\n\n\n\n\n\n\n\n\n\n\n\n5.1.6 Annotations\n\nThe command to add simple annotations is ax.text(). The required auguments are the coordinates of the text and the text itself. You may add several options to modify the style.\nIf arrows are needed, we may use ax.annotation(). Here an arrow will be shown from xytext to xy. The style of the arrow is controlled by the option arrowprops.\n\n\nExample 5.14  \n\nfig, ax = plt.subplots(figsize=(5, 5))\nax.plot(np.random.randn(1000).cumsum(), 'k', label='one')\nax.text(500, 0, 'Hello world!', family='monospace', fontsize=15, c='r')\nax.annotate('test', xy=(400, 0), xytext=(400, -10), c='r',\n            arrowprops={'facecolor': 'black',\n                        'shrink': 0.05})\n\nText(400, -10, 'test')\n\n\n\n\n\n\n\n\n\n\n\n\n5.1.7 Example\n\nExample 5.15 The stock data can be downloaded from here.\n\nfrom datetime import datetime\nfig, ax = plt.subplots()\ndata = pd.read_csv('assests/datasets/spx.csv', index_col=0, parse_dates=True)\nspx = data['SPX']\nspx.plot(ax=ax, style='k-')\ncrisis_data = [(datetime(2007, 10, 11), 'Peak of bull market'),\n               (datetime(2008, 3, 12), 'Bear Stearns Fails'),\n               (datetime(2008, 9, 15), 'Lehman Bankruptcy')]\nfor date, label in crisis_data:\n    ax.annotate(label, xy=(date, spx.asof(date) + 75),\n                xytext=(date, spx.asof(date) + 225),\n                arrowprops=dict(facecolor='black', headwidth=4, width=2,\n                                headlength=4),\n                horizontalalignment='left', verticalalignment='top')\nax.set_xlim(['1/1/2007', '1/1/2011'])\nax.set_ylim([600, 1800])\n_ = ax.set_title('Important dates in the 2008-2009 financial crisis')\n\n\n\n\n\n\n\n\n\n\nExample 5.16 Here is an example of arrows with different shapes. For more details please read the official document.\n\nfig, ax = plt.subplots()\n\nx = np.linspace(0, 20, 1000)\nax.plot(x, np.cos(x))\nax.axis('equal')\n\nax.annotate('local maximum', xy=(6.28, 1), xytext=(10, 4),\n            arrowprops=dict(facecolor='black', shrink=0.05))\n\nax.annotate('local minimum', xy=(5 * np.pi, -1), xytext=(2, -6),\n            arrowprops=dict(arrowstyle=\"-&gt;\",\n                            connectionstyle=\"angle3,angleA=0,angleB=-90\",\n                            color='r'))\n\nText(2, -6, 'local minimum')",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "contents/5/intro.html#seaborn",
    "href": "contents/5/intro.html#seaborn",
    "title": "5  Visualization",
    "section": "5.2 seaborn",
    "text": "5.2 seaborn\nThere are some new libraries built upon matplotlib, and seaborn is one of them. seaborn is for statistical graphics.\nseaborn is used imported in the following way.\n\nimport seaborn as sns\n\nseaborn also modifies the default matplotlib color schemes and plot styles to improve readability and aesthetics. Even if you do not use the seaborn API, you may prefer to import seaborn as a simple way to improve the visual aesthetics of general matplotlib plots.\nTo apply sns theme, run the following code.\n\nsns.set_theme()\n\nLet us directly run a few codes from the last section and compare the differences between them.\n\nExample 5.17  \n\nplt.plot(np.random.randn(30).cumsum(), color='r', linestyle='--', marker='o')\n\n\n\n\n\n\n\n\nPlease compare the output of the same code with the previous example\n\n\n5.2.1 Scatter plots with relplot()\nThe basic scatter plot method is scatterplot(). It is wrapped in relplot() as the default plotting method. So here we will mainly talk about relplot(). It is named that way because it is designed to visualize many different statistical relationships.\nThe idea of relplot() is to display points based on the variables x and y you choose, and assign different properties to alter the apperance of the points.\n\ncol will create multiple plots based on the column you choose.\nhue is for color encoding, based on the column you choose.\nsize will change the marker area, based on the column you choose.\nstyle will change the marker symbol, based on the column you choose.\n\n\nExample 5.18 Consider the following example. tips is a DataFrame, which is shown below.\n\nimport seaborn as sns\ntips = sns.load_dataset(\"tips\")\ntips\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n\n\n240\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n\n\n242\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n\n\n243\n18.78\n3.00\nFemale\nNo\nThur\nDinner\n2\n\n\n\n\n244 rows × 7 columns\n\n\n\n\nsns.relplot(data=tips,\n            x=\"total_bill\", y=\"tip\", col=\"time\",\n            hue=\"smoker\", style=\"smoker\", size=\"size\")\n\n\n\n\n\n\n\n\n\nThe default type of plots for relplot() is scatter plots. However you may change it to line plot by setting kind='line'.\n\nExample 5.19  \n\ndots = sns.load_dataset(\"dots\")\nsns.relplot(data=dots, kind=\"line\",\n            x=\"time\", y=\"firing_rate\", col=\"align\",\n            hue=\"choice\", size=\"coherence\", style=\"choice\",\n            facet_kws=dict(sharex=False))\n\n\n\n\n\n\n\n\n\n\n\n5.2.2 regplot()\nThis method is a combination between scatter plots and linear regression.\n\nExample 5.20 We still use tips as an example.\n\nsns.regplot(x='total_bill', y='tip', data=tips)\n\n\n\n\n\n\n\n\n\n\n\n5.2.3 pairplot()\nThis is a way to display the pairwise relations among several variables.\n\nExample 5.21 The following code shows the pairplots among all numeric data in tips.\n\nsns.pairplot(tips, diag_kind='kde', plot_kws={'alpha': 0.2})\n\n\n\n\n\n\n\n\n\n\n\n5.2.4 barplot\n\nExample 5.22  \n\nsns.barplot(x='total_bill', y='day', data=tips, orient='h')\n\n\n\n\n\n\n\n\nIn the plot, there are several total_bill during each day. The value in the plot is the average of total_bill in each day, and the black line stands for the 95% confidence interval.\n\nsns.barplot(x='total_bill', y='day', hue='time', data=tips, orient='h')\n\n\n\n\n\n\n\n\nIn this plot, lunch and dinner are distinguished by colors.\n\n\n\n5.2.5 Histogram\n\nExample 5.23  \n\nmu, sigma = 100, 15\nx = mu + sigma * np.random.randn(10000)\ny = mu-30 + sigma*2 * np.random.randn(10000)\ndf = pd.DataFrame(np.array([x,y]).T)\nsns.histplot(df, bins=100, kde=True)\n\n\n\n\n\n\n\n\nPlease compare this plot with this Example",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "contents/5/intro.html#exercises",
    "href": "contents/5/intro.html#exercises",
    "title": "5  Visualization",
    "section": "5.3 Exercises",
    "text": "5.3 Exercises\n\nExercise 5.1 Please download the mtcars file from here and read it as a DataFrame. Then create a scatter plot of the drat and wt variables from mtcars and color the dots by the carb variable.\n\n\nExercise 5.2 Please read the file as a DataFrame from here. This is the Dining satisfaction with quick service restaurants questionare data provided by Dr. Siri McDowall, supported by DART SEED grant.\n\nPlease pick out all rating columns. Excluding last.visit, visit.again and recommend, compute the mean of the rest and add it to the DataFrame as a new column.\nUse a plot to show the relations among these four columns: last.visit, visit.again, recommend and mean.\nLook at the column Profession. Keep Student, and change everything else to be Professional, and add it as a new column Status to the DataFrame.\nDraw the histogram of mean with respect to Status.\nFind the counts of each recommend rating for each Status and draw the barplot. Do the same to last.visit/Status and visit.again/Status.\nExplore the dataset and draw one plot.\n\n\n\n\n\n\n[1] McKinney, W. (2017). Python for data analysis: Data wrangling with pandas, NumPy, and IPython. O’Reilly Media.",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "contents/6/intro.html#example-1-usa.gov-data-from-bitly",
    "href": "contents/6/intro.html#example-1-usa.gov-data-from-bitly",
    "title": "6  Projects with Python",
    "section": "6.1 Example 1: USA.gov Data From Bitly",
    "text": "6.1 Example 1: USA.gov Data From Bitly\nIn 2011, URL shortening service Bitly partnered with the US government website USA.gov to provide a feed of anonymous data gathered from users who shorten links ending with .gov or .mil. The data is gotten from [1].\nThe data file can be downloaded from here. The file is mostly in JSON. It can be converted into a DataFrame by the following code.\n\nimport pandas as pd\nimport numpy as np\nimport json\npath = 'assests/datasets/example.txt'\ndf = pd.DataFrame([json.loads(line) for line in open(path)])\n\nWe mainly use tz and a columns. So let us clean it.\n\ndf['tz'] = df['tz'].fillna('Missing')\ndf['tz'][df['tz'] == ''] = 'Unknown'\ndf['a'] = df['a'].fillna('Missing')\ndf['a'][df['a'] == ''] = 'Unknown'\n\n\nExample 6.1 We first want to extract the timezone infomation from it. The timezone info is in the column tz. Please count different values in the columns tz.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\ntzone = df['tz']\ntvc = tzone.value_counts()\ntvc\n\ntz\nAmerica/New_York        1251\nUnknown                  521\nAmerica/Chicago          400\nAmerica/Los_Angeles      382\nAmerica/Denver           191\n                        ... \nEurope/Uzhgorod            1\nAustralia/Queensland       1\nEurope/Sofia               1\nAmerica/Costa_Rica         1\nAmerica/Tegucigalpa        1\nName: count, Length: 98, dtype: int64\n\n\n\n\n\n\nExample 6.2 We would like to visulize the value counts. You may just show the top ten results.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nimport seaborn as sns\nsns.barplot(x=tvc[:10].values, y=tvc[:10].index)\n\n\n\n\n\n\n\n\n\n\n\n\nExample 6.3 We then would like to extract information from the column a. This column is about the agent of the connection. The important info is the part before the space ' '. Please get that part out and count values.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nagent = df['a']\nagent = agent.str.split(' ').str[0]\navc = agent.value_counts()\navc.head()\n\na\nMozilla/5.0               2594\nMozilla/4.0                601\nGoogleMaps/RochesterNY     121\nMissing                    120\nOpera/9.80                  34\nName: count, dtype: int64\n\n\n\n\n\n\nExample 6.4 Now let us assume that, if Windows appears in column a the user is using Windows os, if not then not. Please detect os, and classify it as Windows and Not Windows.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\ndf['os'] = np.where(df['a'].str.contains('Windows'), 'Windows', 'Not Windows')\n\n\n\n\nNow make a bar plot about the counts based on os and timezone.\n\nExample 6.5 We first group the data by os and tz.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\ntz_os_counts = df.groupby(['tz', 'os']).size().unstack().fillna(0)\ntz_os_counts.head()\n\n\n\n\n\n\n\nos\nNot Windows\nWindows\n\n\ntz\n\n\n\n\n\n\nAfrica/Cairo\n0.0\n3.0\n\n\nAfrica/Casablanca\n0.0\n1.0\n\n\nAfrica/Ceuta\n0.0\n2.0\n\n\nAfrica/Johannesburg\n0.0\n1.0\n\n\nAfrica/Lusaka\n0.0\n1.0\n\n\n\n\n\n\n\n\n\n\n\nExample 6.6 We then turn it into a DataFrame. You may use any methods.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nWe use the .stack(), .unstack() tricks here.\n\ntovc = tz_os_counts.stack()[tz_os_counts.sum(axis=1).nlargest(10).index]\ntovc.name = 'count'\ndftovc = pd.DataFrame(tovc).reset_index()\ndftovc.head()\n\n\n\n\n\n\n\n\ntz\nos\ncount\n\n\n\n\n0\nAmerica/New_York\nNot Windows\n339.0\n\n\n1\nAmerica/New_York\nWindows\n912.0\n\n\n2\nUnknown\nNot Windows\n245.0\n\n\n3\nUnknown\nWindows\n276.0\n\n\n4\nAmerica/Chicago\nNot Windows\n115.0\n\n\n\n\n\n\n\n\n\n\n\nExample 6.7 We may now draw the bar plot showing tz and os.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nsns.barplot(x='count', y='tz', hue='os', data=dftovc)",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Projects with Python</span>"
    ]
  },
  {
    "objectID": "contents/6/intro.html#example-2-us-baby-names-18802010",
    "href": "contents/6/intro.html#example-2-us-baby-names-18802010",
    "title": "6  Projects with Python",
    "section": "6.2 Example 2: US Baby Names 1880–2010",
    "text": "6.2 Example 2: US Baby Names 1880–2010\nThe United States Social Security Administration (SSA) has made available data on the frequency of baby names from 1880 through the present. Hadley Wickham, an author of several popular R packages, has often made use of this dataset in illustrating data manipulation in R. The dataset can be downloaded from here as a zip file. Please unzip it and put it in your working folder.\n\nExample 6.8 In the folder there are 131 .txt files. The naming scheme is yob + the year. Each file contains 3 columns: name, gender, and counts. We would like to add a column year, and combine all files into a single DataFrame. In our example, the year is from 1880 to 2010.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nimport pandas as pd\n\npath = 'assests/datasets/babynames/'\ndflist = list()\nfor year in range(1880, 2011):\n    filename = path + 'yob' + str(year) + '.txt'\n    df = pd.read_csv(filename, names=['name', 'gender', 'counts'])\n    df['year'] = year\n    dflist.append(df)\ndf = pd.concat(dflist, ignore_index=True)\n\n\n\n\n\nExample 6.9 Plot the total births by sex and year.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nimport seaborn as sns\n\nsns.relplot(data=df.groupby(['gender', 'year']).sum().reset_index(),\n            x='year', y='counts', hue='gender', kind='line')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 6.10 For further analysis, we would like to compute the proportions of each name relative to the total number of births per year per gender.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\ndef add_prop(group):\n    group['prop'] = group.counts / group.counts.sum()\n    return group\n\ndf = df.groupby(['gender', 'year']).apply(add_prop)\ndf.head()\n\n\n\n\n\n\n\n\n\n\nname\ngender\ncounts\nyear\nprop\n\n\n\n\n0\nMary\nF\n7065\n1880\n0.077643\n\n\n1\nAnna\nF\n2604\n1880\n0.028618\n\n\n2\nEmma\nF\n2003\n1880\n0.022013\n\n\n3\nElizabeth\nF\n1939\n1880\n0.021309\n\n\n4\nMinnie\nF\n1746\n1880\n0.019188\n\n\n\n\n\n\n\n\n\n\n\nExample 6.11 Now we would like to keep the first 100 names in each year, and save it as a new DataFrame top100.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\ntop100 = (\n    df.groupby(['year', 'gender'])\n    .apply(lambda x: df.loc[x['counts'].nlargest(100).index])\n    .drop(columns=['year', 'gender'])\n    .reset_index()\n    .drop(columns='level_2')\n)\ntop100.head()\n\n\n\n\n\n\n\n\n\n\nyear\ngender\nname\ncounts\nprop\n\n\n\n\n0\n1880\nF\nMary\n7065\n0.077643\n\n\n1\n1880\nF\nAnna\n2604\n0.028618\n\n\n2\n1880\nF\nEmma\n2003\n0.022013\n\n\n3\n1880\nF\nElizabeth\n1939\n0.021309\n\n\n4\n1880\nF\nMinnie\n1746\n0.019188\n\n\n\n\n\n\n\nNote that level_2 is related to the original index after reset_index(). That’s why we don’t need it here.\n\n\n\n\nExample 6.12 Now we would like to draw the trend of some names: John, Harry and Mary.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nnamelist = ['John', 'Harry', 'Mary']\nsns.relplot(data=top100[top100['name'].isin(namelist)],\n            x='year', y='counts', hue='name', kind='line')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 6.13 Please analyze the ending of names.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\ndf['ending'] = df['name'].str[-1]\nendingcount = df.groupby(['gender', 'year', 'ending']).sum().reset_index()\n\n\n\n\n\nExample 6.14 We would like to draw barplots to show the distributions in year 1910, 1960 and 2010.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\ncertainyear = endingcount[endingcount['year'].isin([1910, 1960, 2010])]\nimport matplotlib.pyplot as plt\n\nfig, axs = plt.subplots(2, 1, figsize=(10,7))\nsns.barplot(data=certainyear[endingcount['gender']=='M'],\n            x='ending', y='prop', hue='year', ax=axs[0])\nsns.barplot(data=certainyear[endingcount['gender']=='F'],\n            x='ending', y='prop', hue='year', ax=axs[1]).legend_.remove()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 6.15 We would also like to draw the line plot to show the trending of certain letters through years.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nsns.relplot(data=endingcount[endingcount.ending.isin(['d', 'n', 'y'])],\n            x='year', y='prop', hue='ending', kind='line')",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Projects with Python</span>"
    ]
  },
  {
    "objectID": "contents/6/intro.html#exercises",
    "href": "contents/6/intro.html#exercises",
    "title": "6  Projects with Python",
    "section": "6.3 Exercises",
    "text": "6.3 Exercises\n\nExercise 6.1 Please use the baby name dataset. We would like to consider the diversity of the names. Please compute the number of popular names in top 50% for each year each gender. Draw a line plot to show the trend and discuss the result.\n\n\nExercise 6.2 Please consider the baby name dataset. Please draw the trends of counts of names ending in a, e, n across years for each gender.\n\n\n\n\n\n[1] McKinney, W. (2017). Python for data analysis: Data wrangling with pandas, NumPy, and IPython. O’Reilly Media.",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Projects with Python</span>"
    ]
  },
  {
    "objectID": "contents/7/intro.html#classes",
    "href": "contents/7/intro.html#classes",
    "title": "7  Classes/Packages for Python",
    "section": "7.1 Classes",
    "text": "7.1 Classes\nA class is an abstract structure that can be used to hold both variables and functions. Variables in a class are called attributes, and functions in a class are called methods.\nA class is defined in the following way.\n\nclass Circle:\n    def __init__(self, radius=1):\n        self.radius = radius\n    \n    def area(self):\n        return self.radius**2*3.14 \n\nIn this example, we define a class Circle, which represents a circle. There is one attribute radius, and one method area. When define a cirlce, we need to specify its radius, and we could use the method area to compute the area of the circle.\n\ncir1 = Circle()\ncir2 = Circle(radius=5)\n\ncir1.area()\n\n3.14\n\n\n\ncir2.area()\n\n78.5\n\n\nHere we define two circles. The first circle cir1 is of radius 1. This 1 comes from the default value. Check the definition of Circle.__init__().\nThe second circle cir2 is of radius 5, and this number is specified when we initialize the Circle instance.\nThen we compute the areas of these two circles by calling the area() method. You can also use cir1.radius to get access the radius of the circle. The syntax difference between attributes and methods is the () at the end.\n\n7.1.1 self\nYou may notice the self variable in the definition of the classes. The self is used to refered to the class its. When you want to get access to the class attributes or the class methods, you may use self.\nTake the code as an example.\n\nclass Circle:\n    def __init__(self, radius=1):\n        self.radius = radius\n\nIn the __init__ function, there are two radius.\n\nradius is the local variable that is used by the function. It is also the input argument.\nself.radius is the class attribute, that is shared by all class methods. For example, we may add another class method to the class Circle.\n\n\nclass Circle:\n    def __init__(self, radius=1):\n        self.radius = radius\n    \n    def area(self):\n        return self.radius**2*3.14 \n    \n    def perimeter(self):\n        return self.radius*3.14*2\n\nBoth area() and perimeter() use the same self.radius.\n\n\n\n\n\n\nNote\n\n\n\nClass attributes are defined in the __init__() function.\n\n\n\n\n7.1.2 A design example\nAssume that we live in a world without Pandas, and we would like to design a table object. Then what do we need?\nA table should have multiple rows and multiple columns. We should be able to get access entries by columns and row index. We should also be able to display the table by using the print funciton.\n\n\n\n\n\n\nNote\n\n\n\nThe .__str__() method will be called when you try to print the object. If you don’t explicitly override it, the type of the object will be shown.\n\n\nTherefore we may write the following class.\n\nclass myTableClass():\n    def __init__(self, listoflist=None):\n        if listoflist is None:\n            listoflist = [[]]\n        self.nrows = len(listoflist)\n        self.ncols = len(listoflist[0])\n        self.data = listoflist\n        self.shape = (self.nrows, self.ncols)\n    \n    def get(self, i, j):\n        return self.data[i][j]\n\n    def __str__(self):\n        tmp = [' '.join([str(x) for x in row]) for row in self.data]\n        return '\\n'.join(tmp)\n\nThis is a very brief table object. We may add more things to it. For example, we could talk about column names.\n\nclass myTableClass():\n    def __init__(self, listoflist=None, columns=None):\n        if listoflist is None:\n            listoflist = [[]]\n        if columns is None:\n            columns = list()\n        self.nrows = len(listoflist)\n        self.ncols = len(listoflist[0])\n        self.data = listoflist\n        self.shape = (self.nrows, self.ncols)\n        self.columns = columns\n    \n    def get(self, i, j):\n        return self.data[i][j]\n\n    def rename(self, columns=None):\n        if columns is not None:\n            self.columns = columns\n\n    def __str__(self):\n        tmp = [' '.join([str(x) for x in row]) for row in self.data]\n        if len(self.columns) != 0:\n            tmp.insert(0, self.columns)\n        return '\\n'.join(tmp)\n\n\n\n\n\n\n\nNote\n\n\n\nIn Jupyter notebook or similar environment, we might directly call df to show a DataFrame and the shown DataFrame is rendered very pretty. This is due to the IPython.display.display() method, and is part of IPython console components.",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classes/Packages for Python</span>"
    ]
  },
  {
    "objectID": "contents/7/intro.html#inheritance",
    "href": "contents/7/intro.html#inheritance",
    "title": "7  Classes/Packages for Python",
    "section": "7.2 Inheritance",
    "text": "7.2 Inheritance\nOne of the most important feature of classes is inheritance. Attributes and methods can be passed from parents to children, and child classes can override those attributes and methods if needed.\nFor example, we would like to first write a people class.\n\nclass people():\n    def __init__(self, name='default', age=20):\n        self.name = name\n        self.age = age\n\n    def eat(self):\n        print('eat something.')\n\nThis people class defines a people who can eat. Then using this people class, we could build a children class: student.\n\nclass student(people):\n    pass\n\n\nstu1 = student('name1', 10)\nstu1.eat()\nstu1.name\n\neat something.\n\n\n'name1'\n\n\n\ntype(stu1)\n\n__main__.student\n\n\nNow you can see that this stu1 is a student, but it has all attributes and methods as a people. However at current stage student and people are exactly the same since we don’t have any new codes for student. Let us improve it a little bit.\n\nclass student(people):\n    def __init__(self, name='default', age=20, grade=1):\n        super().__init__(name, age)\n        self.grade = grade\n\n    def eat(self):\n        print('eat in the cafe.')\n\nstu1 = student('name1', 10)\nstu1.eat()\n\neat in the cafe.\n\n\nNow student class override the eat() method from people. If someone is a student, he or she will eat in the cafe instead of just eat something.\nIn addition, you may also notice that the __init__() constructor function is also overriden. The first part is super().__init__(name, age) which is just call the people’s constructor function. The second part is new in student, that we add a new attribute grade to it. Now stu1 have attributes from people and the new attribute defined in student.\n\nstu1.name, stu1.age\n\n('name1', 10)\n\n\n\nstu1.grade\n\n1",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classes/Packages for Python</span>"
    ]
  },
  {
    "objectID": "contents/7/intro.html#packages-modules",
    "href": "contents/7/intro.html#packages-modules",
    "title": "7  Classes/Packages for Python",
    "section": "7.3 packages / modules",
    "text": "7.3 packages / modules\nMain reference is RealPython and [1].\n\n7.3.1 import\nIn most cases we won’t only write one single Python file. If we want to use codes from other files, we need to import.\n\nIf both files are in the same folder, e.g. file1.py and file2.py, you may just put import file2 in file1.py, and use file2.myfunction() to call functions or variables defined in file2.py.\nIf both files are in the same folder, and you just want to use one function from file1.py in file2.py, you may from file1 import myfunction(), and then directly write myfunction() in file2.py.\n\n\nExample 7.1 This is from file1.py.\n\ns = \"This is from file1.py.\"\na = [100, 200, 300]\nprint(s)\n\ndef foo(arg):\n    print(f'arg = {arg}')\n\nclass Foo:\n    pass\n\nThis is from file1.py.\n\n\nIn file2.py, we could get access to these variables and functions and classes as follows.\n\nimport file1\nfile1.s\n\n\n\n'This is from file1.py.'\n\n\n\nfile1.a\n\n[100, 200, 300]\n\n\n\nfile1.foo(file1.a)\n\narg = [100, 200, 300]\n\n\n\nfile1.Foo()\n\n&lt;assests.codes.file1.Foo at 0x171ff8fbe50&gt;\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAn alternative way is to use from &lt;module&gt; import &lt;names&gt; to directly use the names without the file1. prefix.\n\n\nPlease see the following Example to get a feel about how namespace works.\n\nExample 7.2  \n\ns = 'foo'\na = ['foo', 'bar', 'baz']\n\nfrom file1 import s as string, a as alist\ns\n\n\n\n'foo'\n\n\n\nstring\n\n'This is from file1.py.'\n\n\n\na\n\n['foo', 'bar', 'baz']\n\n\n\nalist\n\n[100, 200, 300]\n\n\n\nWe may use dir() to look at all objects in the current namespace.\n\n\n7.3.2 __name__\n__name__ is a variable to tell you want is the current active namespace. See the following example.\n\nExample 7.3  \n\nimport file1\nfile1.__name__\n\n\n\n'assests.codes.file1'\n\n\nThe result file1 means that the codes in file1.py are now treated as a package and are imported into other files.\n\n__name__\n\n'__main__'\n\n\nThe result __main__ means that the codes we are writing now are treated as in the “active” enviroment.\nYou may see the following codes in a lot of places.\n\nif __name__ == '__main__':\n    pass\n\nIt means that the following codes will only be run in the “active” mode. If you import the codes as a package, these part of codes won’t be run.\n\n\n\n7.3.3 Packages\nPacages is a way to group and organize mutliple modules. It allow for a hierachical structuring of the module namespace using dot notation.\nCreating a package is straightforward, since it makes use of the operating system’s inherent hierarchical file structure.\nPython defines two types of packages, regular packages and namespace packages. The above package is the regular one. Namespace packages allow codes are spread among different folders. We won’t talk about it in this course.\nTo create a regular package, what you need to do is to organize the files in suitable folders, and then add an __init__.py in each folder. The file can be empty, or you could add any initialization codes for the package which is represented by the folder.\n\n\n\n\n\n\nNote\n\n\n\nIn the past __init__.py is required for a package. After Python 3.3 the namespace package is introduced, the __init__.py is not required (but recommended) for regular packages, and cannot be used for namespace packages.\n\n\nLet us put the previous file1.py and file2.py into subfolder assests/codes/. To make it into a package assests and a subpackage codes, we need to put __init__.py in each folder.\n\nimport assests.codes.file1 as f1\nf1.s\n\n'This is from file1.py.'",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classes/Packages for Python</span>"
    ]
  },
  {
    "objectID": "contents/7/intro.html#exercieses",
    "href": "contents/7/intro.html#exercieses",
    "title": "7  Classes/Packages for Python",
    "section": "7.4 Exercieses",
    "text": "7.4 Exercieses\nProblems are based on [2].\n\nExercise 7.1 (Heron’s formula) Consider a triangle whose sides are \\(a\\), \\(b\\) and \\(c\\). Heron’s formula states that the area of this triangle is \\[\\sqrt{s(s−a)(s−b)(s−c)}\\quad\\text{ where } s=\\frac12(a+b+c).\\]\nPlease write a function that given three points computes the area of the triangle with vertices being the given points. The input is required to be a list of three tuples, where each tuple contains two numbers representing the 2d-coordinate of a point.\n\n\nExercise 7.2 (array) Write a function to reverse an 1D NumPy array (first element becomes last).\n\n\nExercise 7.3 (Compare two numpy arraies) Consider two numpy arraies x and y. Compare them entry by entry. We would like to know how many are the same.\nWrite a function that the inputs are x and y, and the output is the number of the same numbers.\n\n\nExercise 7.4 (Comma Code) Say you have a list value like this: spam = ['apples', 'bananas', 'tofu', 'cats'].\nWrite a function that takes a list value as an argument and returns a string with all the items separated by a comma and a space, with and inserted before the last item. For example, passing the previous spam list to the function would return ‘apples, bananas, tofu, and cats’. But your function should be able to work with any list value passed to it. Be sure to test the case where an empty list [] is passed to your function.\n\n\nExercise 7.5 Create a Car class with two instance attributes:\n\n.color, which stores the name of the car’s color as a string.\n.mileage, which stores the number of miles on the car as an integer.\n\nThen instantiate two Car objects — a blue car with 20,000 miles and a red car with 30,000 miles — and print out their colors and mileage. Your expected output are below:\n\ncar1 = mycar(color='blue', mileage=20000)\ncar2 = mycar(color='red', mileage=30000)\n\nprint(car1)\nprint(car2)\n\nA blue car with 20000 mileage.\nA red car with 30000 mileage.\n\n\n\n\nExercise 7.6 Create a GoldenRetriever class that inherits from the Dog class. Give the sound argument of GoldenRetriever.speak() a default value of Bark. Use the following code for your parent Dog class:\n\nclass Dog:\n    species = \"Canis familiaris\"\n\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n\n    def __str__(self):\n        return f\"{self.name} is {self.age} years old\"\n\n    def speak(self, sound):\n        return f\"{self.name} says {sound}\"\n\n\n\n\n\n\n[1] Beuzen, T. and Timbers, T. (2022). Python packages. Taylor & Francis Group.\n\n\n[2] Sweigart, A. (2020). Automate the boring stuff with python, 2nd edition practical programming for total beginners: Practical programming for total beginners. No Starch Press.",
    "crumbs": [
      "Part I: Python",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classes/Packages for Python</span>"
    ]
  },
  {
    "objectID": "contents/8/intro.html#hello-world-for-r",
    "href": "contents/8/intro.html#hello-world-for-r",
    "title": "8  R Fundamentals",
    "section": "8.1 Hello world for R",
    "text": "8.1 Hello world for R\n\nprint('Hello world!')\n#&gt; [1] \"Hello world!\"",
    "crumbs": [
      "Part II: R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>R Fundamentals</span>"
    ]
  },
  {
    "objectID": "contents/8/intro.html#essential-concepts",
    "href": "contents/8/intro.html#essential-concepts",
    "title": "8  R Fundamentals",
    "section": "8.2 Essential concepts",
    "text": "8.2 Essential concepts\n\nIn R, assignments is &lt;-, not =. = actually works, but it may cause confusions. So it is always recommended to use &lt;-. The R Studio keybinding for &lt;- is alt+-.\n. is NOT a special character in R, and can be used in variable names. So is.na() simply means a function called is.na. It is not a function na in a package is as in Python.\nIn R, the block is defined by {}. Indentation is not that important.\nR has a better package management system than Python, and therefore in most cases you don’t need virtual environment for R.\n\n\n8.2.1 R Markdown / Quarto\nThe counterpart of Jupyter notebook in R is .rmd/.qmd file. Similar to a notebook, in a R Markdown / Quarto file, there is a so-called code block that can run the codes inside to produce documents with both texts and codes and codes outputs.\nIn the following two sections about R, you are supposed to submit .rmd/.qmd file.\n\n\n\n\n\n\nNote\n\n\n\nQuarto is an extension/continuation of R Markdown. Most R Markdown file can be directly translated to a Quarto file without many modifications. The main difference between R Markdown and Quarto is that Quarto has better support for other languages such as Python and Julia. You may go to its homepage for more details.\nThis note is produced by Quarto.\n\n\nThe most import part of R Markdown / Quarto is the code block, that is\n```{r}\nprint('Hello world!')\n```\nIn Quarto, you may also write\n```{python}\nprint('Hello world!')\n```\nThere are many options to adjust how the code blocks are excacuted. You don’t need to worry about them right now. Currently just try to write your report together with code blocks.",
    "crumbs": [
      "Part II: R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>R Fundamentals</span>"
    ]
  },
  {
    "objectID": "contents/8/intro.html#data-structures",
    "href": "contents/8/intro.html#data-structures",
    "title": "8  R Fundamentals",
    "section": "8.3 Data structures",
    "text": "8.3 Data structures\nMain reference here is [1] and [2].\n\n8.3.1 Vectors\nVector is one of the basic data structure in R. It is created by c() function. Sometimes it is called atomic vector. You may store any data types in it. R recognizes six basic types: double, integers, characters, logicals, complex and raw.\nThe data type inside a vector can be checked by typeof function.\n\ndie &lt;- c(1, 2, 3, 4, 5, 6)\ntypeof(die)\n#&gt; [1] \"double\"\n\nFor consecutive numbers, an easier way to create vector is to use :.\n\ndie &lt;- 1:6\n\n\n\n\n\n\n\nCaution\n\n\n\nNote that vector index starts from 1 in R, while list index starts from 0 in Python.\n\n\n\ndie[1]\n#&gt; [1] 1\n\nWhen slicing with vectors, don’t forget to use c().\n\ndie[c(2, 3)]\n#&gt; [1] 2 3\n\n\ndie[2:3]\n#&gt; [1] 2 3\n\nYou may use length() function to get its length.\n\nlength(die)\n#&gt; [1] 6\n\n\n\n8.3.2 Attributes\nR objects may have attributes. Attributes won’t be shown by default when you show the object. You may find the attributes of a R object by calling the attributes() function.\nThe following example show that the vector die defined in Section 8.3.1 doesn’t have attributes.\n\nattributes(die)\n#&gt; NULL\n\nAttributes can be read and write using attr function. See the following example.\n\nExample 8.1  \n\nattr(die, 'date') &lt;- '2022-01-01'\ndie\n#&gt; [1] 1 2 3 4 5 6\n#&gt; attr(,\"date\")\n#&gt; [1] \"2022-01-01\"\nattr(die, 'date') &lt;- NULL\ndie\n#&gt; [1] 1 2 3 4 5 6\n\n\nYou may think attributes as metadata attached to a R object. They are used to tell some useful infomation of the object. Some functions will interact with certain attributes. R itself treat attributes class, comment, dim, dimnames, names, row.names and tsp specially. We will only talk about class and names here. dim will be discussed in the next section. Others will be discussed when we use them.\n\nclass: This is different from the class in Python. class in R is an attribute which talks about the class of an object. If the attribute class is not assigned to an object, the object will have an implicit class: matrix, array, function, numeric or the result of typeof.\n\nattr(x, 'class') will show the “external” class of an object. You may also use class(x) to read and write attribute class. If the class is not assigned, class(x) will show the implicit class, while attr(x, 'class') will show NULL.\n\nExample 8.2  \n\nattr(die, 'class')\n#&gt; NULL\nclass(die)\n#&gt; [1] \"integer\"\nclass(die) &lt;- 'a die'\nattr(die, 'class')\n#&gt; [1] \"a die\"\nclass(die)\n#&gt; [1] \"a die\"\n\n\n\nnames: This attribute is used to name each element in a vector. After the names are assigned, it won’t be displayed below the data like other attributes. It will be displayed above the data with correct alignment. Similar to class, you may use names() to read and write the attribute.\n\n\nExample 8.3  \n\nnames(die) &lt;- c('one', 'two', 'three', 'four', 'five', 'six')\ndie\n#&gt;   one   two three  four  five   six \n#&gt;     1     2     3     4     5     6\nattributes(die)\n#&gt; $names\n#&gt; [1] \"one\"   \"two\"   \"three\" \"four\"  \"five\"  \"six\"\nnames(die)\n#&gt; [1] \"one\"   \"two\"   \"three\" \"four\"  \"five\"  \"six\"\nis.vector(die)\n#&gt; [1] TRUE\n\n\n\n\n\n\n\n\nTip\n\n\n\nWhen you store different types of data into a single vector in R, R will convert them into a single type. The default way to do so is\n\nif there are only logicals and numbers, logicals will be converted to numbers by TRUE-&gt;1 and FALSE-&gt;0.\nif characters are presented, all are converted to characters by what it is.\n\n\nc(1, TRUE)\n#&gt; [1] 1 1\nc('1', 1, TRUE)\n#&gt; [1] \"1\"    \"1\"    \"TRUE\"\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe can apply regular operators to vectors. The defaul way is to apply the operators element-wise.\n\n\n\n\n8.3.3 matrices and arrays\n\nm &lt;- matrix(c(1,2,3,4,5,6), nrow=2)\nm[1, ]\n#&gt; [1] 1 3 5\n\nA matrix has dim attribute.\n\ndim(m)\n#&gt; [1] 2 3\n\nNote that by assigning and removing dim attribute, you may change the object between vectors and matrices.\n\nExample 8.4  \n\nm\n#&gt;      [,1] [,2] [,3]\n#&gt; [1,]    1    3    5\n#&gt; [2,]    2    4    6\nis.matrix(m)\n#&gt; [1] TRUE\nis.vector(m)\n#&gt; [1] FALSE\ndim(m)\n#&gt; [1] 2 3\ndim(m) &lt;- NULL\nm\n#&gt; [1] 1 2 3 4 5 6\nis.matrix(m)\n#&gt; [1] FALSE\nis.vector(m)\n#&gt; [1] TRUE\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe dim of a matrix/vector can be a long vector. In this case, it will become an array.\n\n\n\n\n8.3.4 factors\nFactor is speical vector. It is a way to handle categorical data. The idea is the limit the possible values. In a factor all possible values are called level, which is an attribute.\n\nExample 8.5 We would like to talk about all months. We first define a vector of the valid levels:\n\nmonth_levels &lt;- c(\n  \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"\n)\n\nThen we could start to transform some month vector into factors, by the function factor().\n\nx1 &lt;- c(\"Dec\", \"Apr\", \"Jan\", \"Mar\")\ny1 &lt;- factor(x1, level=month_levels)\nsort(x1)\n#&gt; [1] \"Apr\" \"Dec\" \"Jan\" \"Mar\"\nsort(y1)\n#&gt; [1] Jan Mar Apr Dec\n#&gt; Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n\nNote that sorting y1 is based on the levels.\n\nx2 &lt;- c(\"Dec\", \"Apr\", \"Jam\", \"Mar\")\ny2 &lt;- factor(x2, level=month_levels)\ny2\n#&gt; [1] Dec  Apr  &lt;NA&gt; Mar \n#&gt; Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n\nNote that y2 contains NA value since there is an entry in x2 that is not valid.\n\n\n\n8.3.5 Lists\nList is very similar to a vector. The main difference is that vector can only store values, while list can store objects. The most typical example of objects is another vector. Please see the following example.\n\nExample 8.6  \n\nc(1:2, 3:4)\n#&gt; [1] 1 2 3 4\nlist(1:2, 3:4)\n#&gt; [[1]]\n#&gt; [1] 1 2\n#&gt; \n#&gt; [[2]]\n#&gt; [1] 3 4\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe attributes of an object is stored in an array.\n\nm &lt;- matrix(c(1,2,3,4,5,6), nrow=2)\na &lt;- attributes(m)\nclass(a)\n#&gt; [1] \"list\"\n\n\n\n\n\n8.3.6 data.frame\nData.Frame is a list with the class attribute data.frame, together with some restriction on the shape of each columns. You may think about it in terms of tables.\n\ndf &lt;- data.frame(face = c(\"ace\", \"two\", \"six\"),\n                 suit = c(\"clubs\", \"clubs\", \"clubs\"),\n                 value = c(1, 2, 3))\ndf\n#&gt;   face  suit value\n#&gt; 1  ace clubs     1\n#&gt; 2  two clubs     2\n#&gt; 3  six clubs     3\n\n\nData Frame group vectors. Each vector represents a column.\nDifferent column can contain a different type of data, but every cell within one column must be the same type of data.\ndata.frame() can be used to create a data.frame.\nThe type of a data.frame is a list. Similar to matrix comparing to vector, a data.frame is a list with class data.frame, as well as a few other attributes.\n\n\n\n8.3.7 Examples\n\nExample 8.7 Consider a date.frame representing a deck of cards. Here we use expand.grid() to perform the Cartesian product.\n\nsuit &lt;- c('spades', 'hearts', 'clubs', 'diamonds')\nface &lt;- 1:13\ndeck &lt;- expand.grid(suit, face)\nhead(deck)\n#&gt;       Var1 Var2\n#&gt; 1   spades    1\n#&gt; 2   hearts    1\n#&gt; 3    clubs    1\n#&gt; 4 diamonds    1\n#&gt; 5   spades    2\n#&gt; 6   hearts    2\n\nWe may assign names to change the column names.\n\nnames(deck) &lt;- c('suit', 'face')\nhead(deck)\n#&gt;       suit face\n#&gt; 1   spades    1\n#&gt; 2   hearts    1\n#&gt; 3    clubs    1\n#&gt; 4 diamonds    1\n#&gt; 5   spades    2\n#&gt; 6   hearts    2\n\nNote that since suit and face are two vectors, merge() can also do the Cartesian product. expand.grid() is good for both vectors and data.frame.\n\ndeck &lt;- merge(suit, face)\nhead(deck)\n#&gt;          x y\n#&gt; 1   spades 1\n#&gt; 2   hearts 1\n#&gt; 3    clubs 1\n#&gt; 4 diamonds 1\n#&gt; 5   spades 2\n#&gt; 6   hearts 2\n\n\n\n\n8.3.8 Load data\n\n8.3.8.1 build-in datasets\nR has many build-in datasets. You may use data() to see all of them. Here are a few common datasets.\n\nmtcars: Motor Trend Car Road Tests: The data was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973–74 models)\n\n\ndata(mtcars)\n\n\niris: iris data set gives the measurements in centimeters of the variables sepal length, sepal width, petal length and petal width, respectively, for 50 flowers from each of 3 species of iris. The species are Iris setosa, versicolor, and virginica.\n\n\ndata(iris)\n\n\nToothGrowth: ToothGrowth data set contains the result from an experiment studying the effect of vitamin C on tooth growth in 60 Guinea pigs.\n\n\ndata(ToothGrowth)\n\n\nPlantGrowth: Results obtained from an experiment to compare yields (as measured by dried weight of plants) obtained under a control and two different treatment condition.\n\n\ndata(PlantGrowth)\n\n\nUSArrests: This data set contains statistics about violent crime rates by us state.\n\n\ndata(USArrests)\n\n\n\n8.3.8.2 Read from files\nThe build-in read.csv() function can directly read .csv file into a data.frame.\n\nExample 8.8 We use the file yob1880.txt from Chapter 5 here. Put the file in the working folder and run the following code.\n\ndf &lt;- read.csv('yob1880.txt', header = FALSE)\nhead(df)\n\nWe may also manually assign columns names.\n\nnames(df) &lt;- c('name', 'sex', 'counts')\nhead(df)\n#&gt;        name sex counts\n#&gt; 1      Mary   F   7065\n#&gt; 2      Anna   F   2604\n#&gt; 3      Emma   F   2003\n#&gt; 4 Elizabeth   F   1939\n#&gt; 5    Minnie   F   1746\n#&gt; 6  Margaret   F   1578\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo save data is straightforward.\n\nwrite.csv(df, file='df.csv', row.names=FALSE)\n\n\n\n\n\n\n8.3.9 Flow control\n\n8.3.9.1 for loop\n\nExample 8.9  \n\nfor (x in 1:10){\n    print(x)\n}\n#&gt; [1] 1\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n#&gt; [1] 6\n#&gt; [1] 7\n#&gt; [1] 8\n#&gt; [1] 9\n#&gt; [1] 10\n\n\n\n\n8.3.9.2 if-else\n\nExample 8.10  \n\na &lt;- 200\nb &lt;- 33\n\nif (b &gt; a) {\n  print(\"b is greater than a\")\n} else if (a == b) {\n  print(\"a and b are equal\")\n} else {\n  print(\"a is greater than b\")\n}\n#&gt; [1] \"a is greater than b\"\n\n\n\n\n8.3.9.3 Functions\nThe standard format to define a function is my_function &lt;- function(input) {} where the function name is on the left side of &lt;-, the input arguments are in the (), and the function body is in {}. The output of the last line of the function body is the return value of the function.\n\nExample 8.11  \n\nmyfunction &lt;- function() {\n    die &lt;- 1:6\n    sum(die)\n}\n\nmyfunction()\n#&gt; [1] 21\n\nIf you just type the function name without (), R will return the definition of the function.\n\nmyfunction\n#&gt; function() {\n#&gt;     die &lt;- 1:6\n#&gt;     sum(die)\n#&gt; }\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe function sample(x): sample takes a sample of the specified size from the elements of x using either with or without replacement.\nsample(x, size, replace = FALSE, prob = NULL):\n\nx: either a vector of one or more elements from which to choose, or a positive integer.\nsize: a non-negative integer giving the number of items to choose.\nreplace: should sampling be with replacement?\nprob: a vector of probability weights for obtaining the elements of the vector being sampled.",
    "crumbs": [
      "Part II: R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>R Fundamentals</span>"
    ]
  },
  {
    "objectID": "contents/8/intro.html#r-notations",
    "href": "contents/8/intro.html#r-notations",
    "title": "8  R Fundamentals",
    "section": "8.4 R notations",
    "text": "8.4 R notations\n\n8.4.1 Selecting Values\nLet us start from a data.frame df. The basic usage is df[ , ], where the first index is to subset the rows and the second index is to subset the columns. There are six ways to writing indexes.\n\nPositive integers: the regular way.\n\n\ndf[i, j] means the data in the ith row and jth column.\nIf both i and j are vectors, a data.frame will be returned.\nIf i or j are a vector, a vector will be returned. If you still want a data.frame, you may add the option drop=FALSE.\nIf only one index is provided, it refers to the column.\n\n\nExample 8.12 We consider the simplified version of a deck. The deck only contains face values from 1 to 5.\n\ndeck[1:2, 1:2]\n#&gt;     Var1 Var2\n#&gt; 1 spades    1\n#&gt; 2 hearts    1\ndeck[1:2, 1]\n#&gt; [1] spades hearts\n#&gt; Levels: spades hearts clubs diamonds\ndeck[1:2, 1, drop=FALSE]\n#&gt;     Var1\n#&gt; 1 spades\n#&gt; 2 hearts\ndeck[1]\n#&gt;        Var1\n#&gt; 1    spades\n#&gt; 2    hearts\n#&gt; 3     clubs\n#&gt; 4  diamonds\n#&gt; 5    spades\n#&gt; 6    hearts\n#&gt; 7     clubs\n#&gt; 8  diamonds\n#&gt; 9    spades\n#&gt; 10   hearts\n#&gt; 11    clubs\n#&gt; 12 diamonds\n#&gt; 13   spades\n#&gt; 14   hearts\n#&gt; 15    clubs\n#&gt; 16 diamonds\n#&gt; 17   spades\n#&gt; 18   hearts\n#&gt; 19    clubs\n#&gt; 20 diamonds\n\n\n\nNegative integers: remove the related index.\n\nFor example,\n\ndeck[-1, 1:3] means it wants all rows except row 1, and column 1 to 3.\ndeck[-(2:20), 1:2] means it wants all rows ecepte row 2 to row 20, and column 1 to 2.\nNegative index and positive index cannot be used together in the same index.\n\n\nBlank Spaces: want every value in the dimension.\n\n\ndeck[, 1]\n#&gt;  [1] spades   hearts   clubs    diamonds spades   hearts   clubs    diamonds\n#&gt;  [9] spades   hearts   clubs    diamonds spades   hearts   clubs    diamonds\n#&gt; [17] spades   hearts   clubs    diamonds\n#&gt; Levels: spades hearts clubs diamonds\ndeck[1, ]\n#&gt;     Var1 Var2\n#&gt; 1 spades    1\n\n\nLogical values: select the rows or columns according to the value. The dimension should have exactly the same number of elements as the logical vector.\n\n\nrows &lt;- c(TRUE, FALSE, TRUE, FALSE, TRUE, TRUE, FALSE, TRUE, FALSE, TRUE, TRUE, FALSE, TRUE, FALSE, TRUE, TRUE, FALSE, TRUE, FALSE, TRUE)\ndeck[rows,]\n#&gt;        Var1 Var2\n#&gt; 1    spades    1\n#&gt; 3     clubs    1\n#&gt; 5    spades    2\n#&gt; 6    hearts    2\n#&gt; 8  diamonds    2\n#&gt; 10   hearts    3\n#&gt; 11    clubs    3\n#&gt; 13   spades    4\n#&gt; 15    clubs    4\n#&gt; 16 diamonds    4\n#&gt; 18   hearts    5\n#&gt; 20 diamonds    5\ndeck[1:2, c(TRUE, FALSE)]\n#&gt; [1] spades hearts\n#&gt; Levels: spades hearts clubs diamonds\n\n\nNames: select columns based on names attribute.\n\n\ndeck[, 'Var2']\n#&gt;  [1] 1 1 1 1 2 2 2 2 3 3 3 3 4 4 4 4 5 5 5 5\n\n\n\n8.4.2 Dollar signs and double brackets\nList and data.frame obey an optional second system of notation. You can extract values using $ syntax: the data.frame’s name and the column name separated by a $ will select a column and return a vector (since the data in each column is actually a vector).\n\nExample 8.13 Here is an exmaple about data.frames.\n\ndeck[, 1]\n#&gt;  [1] spades   hearts   clubs    diamonds spades   hearts   clubs    diamonds\n#&gt;  [9] spades   hearts   clubs    diamonds spades   hearts   clubs    diamonds\n#&gt; [17] spades   hearts   clubs    diamonds\n#&gt; Levels: spades hearts clubs diamonds\ndeck$Var1\n#&gt;  [1] spades   hearts   clubs    diamonds spades   hearts   clubs    diamonds\n#&gt;  [9] spades   hearts   clubs    diamonds spades   hearts   clubs    diamonds\n#&gt; [17] spades   hearts   clubs    diamonds\n#&gt; Levels: spades hearts clubs diamonds\n\nNote that if we select from the data.frame using index, we will get a data.frame.\n\ndeck[1]\n#&gt;        Var1\n#&gt; 1    spades\n#&gt; 2    hearts\n#&gt; 3     clubs\n#&gt; 4  diamonds\n#&gt; 5    spades\n#&gt; 6    hearts\n#&gt; 7     clubs\n#&gt; 8  diamonds\n#&gt; 9    spades\n#&gt; 10   hearts\n#&gt; 11    clubs\n#&gt; 12 diamonds\n#&gt; 13   spades\n#&gt; 14   hearts\n#&gt; 15    clubs\n#&gt; 16 diamonds\n#&gt; 17   spades\n#&gt; 18   hearts\n#&gt; 19    clubs\n#&gt; 20 diamonds\nclass(deck[1])\n#&gt; [1] \"data.frame\"\n\n\n\nExample 8.14 Here is an example about lists.\n\nlst &lt;- list(numbers = c(1, 2), logical = TRUE, strings = c(\"a\", \"b\", \"c\"))\nlst$numbers\n#&gt; [1] 1 2\n\nNote that if we select from the list using index, we will get a list.\n\nlst[1]\n#&gt; $numbers\n#&gt; [1] 1 2\nclass(lst[1])\n#&gt; [1] \"list\"\n\n\nPlease think through these two examples and figure out the similarity between them.\n\n\n\n\n\n\nCaution\n\n\n\nUnderstanding the return value type is very important. Many of the R function work with vectors, but they don’t work with lists. So using the correct way to get values is very important.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThere is a command called attach() which let you get access to deck$face by just typing face. It is highly recommanded NOT to do this. It is much better to make everything explicit, especially when using IDE, typing is much easier.",
    "crumbs": [
      "Part II: R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>R Fundamentals</span>"
    ]
  },
  {
    "objectID": "contents/8/intro.html#modifying-values",
    "href": "contents/8/intro.html#modifying-values",
    "title": "8  R Fundamentals",
    "section": "8.5 Modifying values",
    "text": "8.5 Modifying values\n\n8.5.1 Changing values in place\nYou can use R’s notation system to modify values within an R object.\n\nIn general when working with vectors, the two vectors should have the same length.\nIf the lengths are different, R will repeat the shorter one to make it match with the longer one. This is called the vector recycling rule. R will throw a warning if the two lengths are not proposional.\n\n\nExample 8.15  \n\n1:4 + 1:2\n#&gt; [1] 2 4 4 6\n1:4 + 1:3\n#&gt; Warning in 1:4 + 1:3: longer object length is not a multiple of shorter object\n#&gt; length\n#&gt; [1] 2 4 6 5\n\n\n\nWe may create values that do not yet exist in the object. R will expand the object to accommodate the new values.\n\n\nExample 8.16  \n\nvec &lt;- 1:6\nvec\n#&gt; [1] 1 2 3 4 5 6\nvec[7] &lt;- 0\nvec\n#&gt; [1] 1 2 3 4 5 6 0\n\n\n\nExample 8.17  \n\ndf &lt;- data.frame(a=c(1,2), b=c('a', 'b'))\ndf\n#&gt;   a b\n#&gt; 1 1 a\n#&gt; 2 2 b\ndf$c &lt;- 3:4\ndf\n#&gt;   a b c\n#&gt; 1 1 a 3\n#&gt; 2 2 b 4\n\n\n\n\n8.5.2 Logical subsetting\nWe could compare two vectors element-wise, and the result is a logical vector. Then we could use this result to subset the vector / data.frame.\n\nExample 8.18  \n\nsuit &lt;- c('spades', 'hearts', 'clubs', 'diamonds')\nface &lt;- 1:5\ndeck &lt;- expand.grid(suit, face)\n\n\ndeck$Var1 == 'hearts'\n#&gt;  [1] FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE\n#&gt; [13] FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE\ndeck$Var2[deck$Var1 == 'hearts']\n#&gt; [1] 1 2 3 4 5\ndeck[deck$Var1 == 'hearts',]\n#&gt;      Var1 Var2\n#&gt; 2  hearts    1\n#&gt; 6  hearts    2\n#&gt; 10 hearts    3\n#&gt; 14 hearts    4\n#&gt; 18 hearts    5\n\nWe could directly assign values to the subset. Note that the following assignment create a new column with NA values.\n\ndeck$Var3[deck$Var1 == 'hearts'] &lt;- 1\ndeck\n#&gt;        Var1 Var2 Var3\n#&gt; 1    spades    1   NA\n#&gt; 2    hearts    1    1\n#&gt; 3     clubs    1   NA\n#&gt; 4  diamonds    1   NA\n#&gt; 5    spades    2   NA\n#&gt; 6    hearts    2    1\n#&gt; 7     clubs    2   NA\n#&gt; 8  diamonds    2   NA\n#&gt; 9    spades    3   NA\n#&gt; 10   hearts    3    1\n#&gt; 11    clubs    3   NA\n#&gt; 12 diamonds    3   NA\n#&gt; 13   spades    4   NA\n#&gt; 14   hearts    4    1\n#&gt; 15    clubs    4   NA\n#&gt; 16 diamonds    4   NA\n#&gt; 17   spades    5   NA\n#&gt; 18   hearts    5    1\n#&gt; 19    clubs    5   NA\n#&gt; 20 diamonds    5   NA\n\n\n\n\n\n\n\n\nTip\n\n\n\nOther than the regualr logical operators, R provides a speical one: %in%.\nx %in% y: Is x in the vector y?\nIf x is a vector, the output is a vector with the same length as x, telling whether each element of x is in y or not.\n\n\n\n\n\n\n\n\nTip\n\n\n\nOther than the regular Boolean operators, R provides two special ones: any and all.\n\nany(cond1, cond2, ...): Are any of these conditions true?\nall(cond1, cond2, ...): Are all of these conditions true?\n\n\n\n\n\n8.5.3 Missing values NA\nIn R, missing values are NA, and you can directly work with NA. Any computations related to NA will return NA.\n\nna.rm: Most R functions come with the optional argument na.rm. If you set it to be TRUE, the function will ignore NA when evaluating the function.\n\n\nExample 8.19  \n\nmean(c(NA, 1:50))\n#&gt; [1] NA\nmean(c(NA, 1:50), na.rm=TRUE)\n#&gt; [1] 25.5\n\n\n\nis.na(): This is a function testing whether an object is NA.",
    "crumbs": [
      "Part II: R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>R Fundamentals</span>"
    ]
  },
  {
    "objectID": "contents/8/intro.html#exercises",
    "href": "contents/8/intro.html#exercises",
    "title": "8  R Fundamentals",
    "section": "8.6 Exercises",
    "text": "8.6 Exercises\n\nExercise 8.1 Start a R Markdown / Quarto file. In the first section write a R code block to print Hello world!.\n\n\nExercise 8.2 Which of these are character strings and which are numbers? 1, \"1\", \"one\".\n\n\nExercise 8.3 Create an atomic vector that stores just the face names of the cards: the ace of spades, king of spades, queen of spades, jack of spades, and ten of spades. Which type of vector will you use to save the names?\nHint: The face name of the ace of spades would be ace and spades is the suit.\n\n\nExercise 8.4 Create the following matrix, which stores the name and suit of every card in a royal flush.\n\n#&gt;      [,1]    [,2]    \n#&gt; [1,] \"ace\"   \"spades\"\n#&gt; [2,] \"king\"  \"spades\"\n#&gt; [3,] \"queen\" \"spades\"\n#&gt; [4,] \"jack\"  \"spades\"\n#&gt; [5,] \"ten\"   \"spades\"\n\n\n\nExercise 8.5 Many card games assign a numerical value to each card. For example, in blackjack, each face card is worth 10 points, each number card is worth between 2 and 10 points, and each ace is worth 1 or 11 points, depending on the final score.\nMake a virtual playing card by combining “ace” “heart” and 1 into a vector. What type of atomic vector will result? Check if you are right, and explain your reason.\n\n\nExercise 8.6 Use a list to store a single playing card, like the ace of hearts, which has a point value of one. The list should save the face of the card, the suit, and the point value in separate elements.\n\n\nExercise 8.7 Consider the following data.frame.\n\nsuit &lt;- c('spades', 'hearts', 'clubs', 'diamonds')\nface &lt;- 1:5\ndeck &lt;- expand.grid(suit, face)\n\nPlease write some codes to count how many rows whose Var1 are equal to hearts.\n\n\nExercise 8.8 Converte the following sentences into tests written with R code.\n\nw &lt;- c(-1, 0, 1). Is w positive?\nx &lt;- c(5, 15). Is x greater than 10 and less than 20?\ny &lt;- 'February'. Is object y the word February?\nz &lt;- c(\"Monday\", \"Tuesday\", \"Friday\"). Is every value in z a day of the week?\n\n\n\nExercise 8.9 Please write a function to shuffle the row of a data.frame. You may use the following data.frame deck for test.\n\nsuit &lt;- c('spades', 'hearts', 'clubs', 'diamonds')\nface &lt;- 1:13\ndeck &lt;- expand.grid(suit, face)\n\n\n\n\n\n\n[1] Grolemund, G. (2014). Hands-on programming with r: Write your own functions and simulations. O’Reilly Media.\n\n\n[2] Wickham, H. and Grolemund, G. (2017). R for data science: Import, tidy, transform, visualize, and model data. O’Reilly Media.",
    "crumbs": [
      "Part II: R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>R Fundamentals</span>"
    ]
  },
  {
    "objectID": "contents/9/intro.html#tibble",
    "href": "contents/9/intro.html#tibble",
    "title": "9  R for Data Sciences",
    "section": "9.1 tibble",
    "text": "9.1 tibble\ntidyverse mainly deals with tibble instead of data.frame. Therefore this is where we start.\ntibble is a data.frame with different attributes and requirements. The package tibble provides support for tibble. It is included in tidyverse. To load it, you just use the code:\n\nlibrary(tidyverse)\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.1\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n9.1.1 Create tibbles\nHere is an example of creating tibbles.\n\nExample 9.1  \n\ntbl &lt;- tibble(x=1:5, y=1, z=x^2+y)\ntbl\n#&gt; # A tibble: 5 × 3\n#&gt;       x     y     z\n#&gt;   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     1     2\n#&gt; 2     2     1     5\n#&gt; 3     3     1    10\n#&gt; 4     4     1    17\n#&gt; 5     5     1    26\nattributes(tbl)\n#&gt; $class\n#&gt; [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n#&gt; \n#&gt; $row.names\n#&gt; [1] 1 2 3 4 5\n#&gt; \n#&gt; $names\n#&gt; [1] \"x\" \"y\" \"z\"\n\nNote that it is more flexible to create a tibble since tibble() will automatically recycle inputs and allows you to refer to variables that you just created.\n\n\n\n\n\n\n\nNote\n\n\n\nIn the past (for a very long time), when using data.frame() to create a data.frame, it will automatically convert strings to factors. This is changed recently that the default setting is not to convert.\nWhen using tibble() to create a tibble, the type of the inputs will never be changed.\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn tibble you may use nonsyntactic names as column names, which are invalid R variable names. To refer to these variables, you need to surround them with backticks `.\n\ntb &lt;- tibble(\n    `:)` = \"smile\",\n    ` ` = \"space\",\n    `2000` = \"number\"\n)\ntb\n#&gt; # A tibble: 1 × 3\n#&gt;   `:)`  ` `   `2000`\n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; \n#&gt; 1 smile space number\n\n\n\n\n\n9.1.2 Differences between tibble and data.frame.\n\n9.1.2.1 Printing\nTibbles have a refined print method that shows only the first 10 rows and all the columns that fit on screen.\n\ndeck &lt;- tibble(suit=rep(c('spades', 'hearts', 'clubs', 'diamonds'), 13), face=rep(1:13, 4))\ndeck\n#&gt; # A tibble: 52 × 2\n#&gt;    suit      face\n#&gt;    &lt;chr&gt;    &lt;int&gt;\n#&gt;  1 spades       1\n#&gt;  2 hearts       2\n#&gt;  3 clubs        3\n#&gt;  4 diamonds     4\n#&gt;  5 spades       5\n#&gt;  6 hearts       6\n#&gt;  7 clubs        7\n#&gt;  8 diamonds     8\n#&gt;  9 spades       9\n#&gt; 10 hearts      10\n#&gt; # ℹ 42 more rows\n\n\n\n9.1.2.2 Subsetting\nTo get a single value, [[]] or $ should be used, just like for data.frame. These two are almost the same. The only difference is that [[]] accepts positions, but $ only accepts names.\nTo be used in a pipe, the special placeholder . will be used.\n\ndeck %&gt;% .$face\n#&gt;  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13  1  2  3  4  5  6  7  8  9 10 11 12\n#&gt; [26] 13  1  2  3  4  5  6  7  8  9 10 11 12 13  1  2  3  4  5  6  7  8  9 10 11\n#&gt; [51] 12 13\n\nWe will talk about pipes later.\n\n\n\n9.1.3 %&gt;% symbol\n%&gt;% is the pipeline symbol, which is another way to connect several functions. Most functions in tidyverse have the first argument data, and both the input data and the output are tibbles. The syntax here is that data %&gt;% function(arguments) is the same as function(data, arguments). The benefit is that it is easier to have many functions consecutively applied to the data. Please see the following example.\n\ndata %&gt;% function1(arguments1)\n    %&gt;% function2(arguments2)\n    %&gt;% function3(arguments3)\n    %&gt;% function4(arguments4)\n\nfunction4(function3(function2(function1(data, arguments1), arguments2), arguments3), arguments4)\n\ndata2 &lt;- function1(data, arguments1)\ndata3 &lt;- function2(data2, arguments2)\ndata4 &lt;- function3(data3, arguments3)\nfunction4(data4, arguments4)\n\nThe readability of the first one is much better than the second one. Comparing to the third one, we don’t need to create a lot of intermedia temporary variables.",
    "crumbs": [
      "Part II: R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>R for Data Sciences</span>"
    ]
  },
  {
    "objectID": "contents/9/intro.html#tidy-data",
    "href": "contents/9/intro.html#tidy-data",
    "title": "9  R for Data Sciences",
    "section": "9.2 Tidy Data",
    "text": "9.2 Tidy Data\nThe same underlying data can be represented in multiple ways. The following example shows the same data organized in four different ways.\n\nExample 9.2 These tibbles are provided by tidyr. You could directly load it from tidyverse.\n\nlibrary(tidyverse)\ndata(table1, package='tidyr')\ndata(table2, package='tidyr')\ndata(table3, package='tidyr')\ndata(table4a, package='tidyr')\ndata(table4b, package='tidyr')\n\n\ntable1\n\n\ntable1\n#&gt; # A tibble: 6 × 4\n#&gt;   country      year  cases population\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n#&gt; 1 Afghanistan  1999    745   19987071\n#&gt; 2 Afghanistan  2000   2666   20595360\n#&gt; 3 Brazil       1999  37737  172006362\n#&gt; 4 Brazil       2000  80488  174504898\n#&gt; 5 China        1999 212258 1272915272\n#&gt; 6 China        2000 213766 1280428583\n\n\ntable2\n\n\ntable2\n#&gt; # A tibble: 12 × 4\n#&gt;    country      year type            count\n#&gt;    &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;\n#&gt;  1 Afghanistan  1999 cases             745\n#&gt;  2 Afghanistan  1999 population   19987071\n#&gt;  3 Afghanistan  2000 cases            2666\n#&gt;  4 Afghanistan  2000 population   20595360\n#&gt;  5 Brazil       1999 cases           37737\n#&gt;  6 Brazil       1999 population  172006362\n#&gt;  7 Brazil       2000 cases           80488\n#&gt;  8 Brazil       2000 population  174504898\n#&gt;  9 China        1999 cases          212258\n#&gt; 10 China        1999 population 1272915272\n#&gt; 11 China        2000 cases          213766\n#&gt; 12 China        2000 population 1280428583\n\n\ntable3\n\n\ntable3\n#&gt; # A tibble: 6 × 3\n#&gt;   country      year rate             \n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;            \n#&gt; 1 Afghanistan  1999 745/19987071     \n#&gt; 2 Afghanistan  2000 2666/20595360    \n#&gt; 3 Brazil       1999 37737/172006362  \n#&gt; 4 Brazil       2000 80488/174504898  \n#&gt; 5 China        1999 212258/1272915272\n#&gt; 6 China        2000 213766/1280428583\n\n\nSpread across two tibbles.\n\n\ntable4a\n#&gt; # A tibble: 3 × 3\n#&gt;   country     `1999` `2000`\n#&gt;   &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 Afghanistan    745   2666\n#&gt; 2 Brazil       37737  80488\n#&gt; 3 China       212258 213766\n\ntable4b\n#&gt; # A tibble: 3 × 3\n#&gt;   country         `1999`     `2000`\n#&gt;   &lt;chr&gt;            &lt;dbl&gt;      &lt;dbl&gt;\n#&gt; 1 Afghanistan   19987071   20595360\n#&gt; 2 Brazil       172006362  174504898\n#&gt; 3 China       1272915272 1280428583\n\n\n\nDefinition 9.1 A dataset is tidy if\n\nEach variable have its own column.\nEach observation have its own row.\nEach value have its oven cell.\n\n\nThese three conditions are interrelated because it is impossible to only satisfy two of the three. In pratical, we need to follow the instructions:\n\nPut each dataset in a tibble.\nPut each variable in a column.\n\nTidy data is a consistent way to organize your data in R. The main advantages are:\n\nIt is one consistent way of storing data. In other words, this is a consistent data structure that can be used in many cases.\nTo placing variables in columns allows R’s vectorized nature to shine.\n\nAll packages in the tidyverse are designed to work with tidy data.\n\n9.2.1 Tidying datasets\nMost datasets are untidy:\n\nOne variable might be spread across multiple columns.\nOne observation might be scattered across multiple rows.\n\n\n9.2.1.1 pivot_longer()\nA common problem is that the column names are not names of variables, but values of a variable. For example, table4a above has columns 1999 and 2000. These two names are actually the values of a variable year. In addition, each row represents two observations, not one.\n\ntable4a\n#&gt; # A tibble: 3 × 3\n#&gt;   country     `1999` `2000`\n#&gt;   &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 Afghanistan    745   2666\n#&gt; 2 Brazil       37737  80488\n#&gt; 3 China       212258 213766\n\nTo tidy this type of dataset, we need to gather those columns into a new pair of variables. We need three parameters:\n\nThe set of columns that represent values. In this case, those are 1999 and 2000.\nThe name of the variable. In this case, it is year. -The name of the variable whose values are spread over the cells. In this case, it is the number of cases.\n\nThen we apply pivot_longer().\n\npivot_longer(table4a, cols=c(`1999`, `2000`), names_to='year', values_to='cases')\n#&gt; # A tibble: 6 × 3\n#&gt;   country     year   cases\n#&gt;   &lt;chr&gt;       &lt;chr&gt;  &lt;dbl&gt;\n#&gt; 1 Afghanistan 1999     745\n#&gt; 2 Afghanistan 2000    2666\n#&gt; 3 Brazil      1999   37737\n#&gt; 4 Brazil      2000   80488\n#&gt; 5 China       1999  212258\n#&gt; 6 China       2000  213766\n\nWe may also use the pipe %&gt;% symbol.\n\ntable4a %&gt;% pivot_longer(cols=c(`1999`, `2000`), names_to='year', values_to='cases')\n#&gt; # A tibble: 6 × 3\n#&gt;   country     year   cases\n#&gt;   &lt;chr&gt;       &lt;chr&gt;  &lt;dbl&gt;\n#&gt; 1 Afghanistan 1999     745\n#&gt; 2 Afghanistan 2000    2666\n#&gt; 3 Brazil      1999   37737\n#&gt; 4 Brazil      2000   80488\n#&gt; 5 China       1999  212258\n#&gt; 6 China       2000  213766\n\nWe can do the similar thing to table4b. Then we could combine the two tibbles together.\n\ntidy4a &lt;- table4a %&gt;% \n    pivot_longer(cols=c(`1999`, `2000`), names_to='year', values_to='cases')\ntidy4b &lt;- table4b %&gt;% \n    pivot_longer(cols=c(`1999`, `2000`), names_to='year', values_to='population')\nleft_join(tidy4a, tidy4b)\n#&gt; Joining with `by = join_by(country, year)`\n#&gt; # A tibble: 6 × 4\n#&gt;   country     year   cases population\n#&gt;   &lt;chr&gt;       &lt;chr&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n#&gt; 1 Afghanistan 1999     745   19987071\n#&gt; 2 Afghanistan 2000    2666   20595360\n#&gt; 3 Brazil      1999   37737  172006362\n#&gt; 4 Brazil      2000   80488  174504898\n#&gt; 5 China       1999  212258 1272915272\n#&gt; 6 China       2000  213766 1280428583\n\npivot_longer() is an updated approach to gather(), designed to be both simpler to use and to handle more use cases. We recommend you use pivot_longer() for new code; gather() isn’t going away but is no longer under active development.\n\n\n9.2.1.2 pivot_wider()\nAnother issuse is that an observation is scattered across multiple rows. Take table2 as an example. An observation is a country in a year, but each observation is spread across two rows.\n\ntable2\n#&gt; # A tibble: 12 × 4\n#&gt;    country      year type            count\n#&gt;    &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;\n#&gt;  1 Afghanistan  1999 cases             745\n#&gt;  2 Afghanistan  1999 population   19987071\n#&gt;  3 Afghanistan  2000 cases            2666\n#&gt;  4 Afghanistan  2000 population   20595360\n#&gt;  5 Brazil       1999 cases           37737\n#&gt;  6 Brazil       1999 population  172006362\n#&gt;  7 Brazil       2000 cases           80488\n#&gt;  8 Brazil       2000 population  174504898\n#&gt;  9 China        1999 cases          212258\n#&gt; 10 China        1999 population 1272915272\n#&gt; 11 China        2000 cases          213766\n#&gt; 12 China        2000 population 1280428583\n\nWe could apply pivot_wider() to make it tidy. Here we need two arguments.\n\nThe column that contains variable names. Here, it’s type.\nThe column that contains values forms multiple variables. Here, it’s count.\n\n\npivot_wider(table2, names_from='type', values_from='count')\n#&gt; # A tibble: 6 × 4\n#&gt;   country      year  cases population\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n#&gt; 1 Afghanistan  1999    745   19987071\n#&gt; 2 Afghanistan  2000   2666   20595360\n#&gt; 3 Brazil       1999  37737  172006362\n#&gt; 4 Brazil       2000  80488  174504898\n#&gt; 5 China        1999 212258 1272915272\n#&gt; 6 China        2000 213766 1280428583\n\nWe can also use the pipe symbol %&gt;%.\n\ntable2 %&gt;% pivot_wider(names_from='type', values_from='count')\n#&gt; # A tibble: 6 × 4\n#&gt;   country      year  cases population\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n#&gt; 1 Afghanistan  1999    745   19987071\n#&gt; 2 Afghanistan  2000   2666   20595360\n#&gt; 3 Brazil       1999  37737  172006362\n#&gt; 4 Brazil       2000  80488  174504898\n#&gt; 5 China        1999 212258 1272915272\n#&gt; 6 China        2000 213766 1280428583\n\npivot_wider() is an updated approach to spread(), designed to be both simpler to use and to handle more use cases. We recommend you use pivot_wider() for new code; spread() isn’t going away but is no longer under active development.\n\n\n9.2.1.3 separate()\nIf we would like to split one columns into multiple columns since there are more than one values in a cell, we could use separate().\n\nseparate(table3, rate, into=c('cases', 'population'))\n#&gt; # A tibble: 6 × 4\n#&gt;   country      year cases  population\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     \n#&gt; 1 Afghanistan  1999 745    19987071  \n#&gt; 2 Afghanistan  2000 2666   20595360  \n#&gt; 3 Brazil       1999 37737  172006362 \n#&gt; 4 Brazil       2000 80488  174504898 \n#&gt; 5 China        1999 212258 1272915272\n#&gt; 6 China        2000 213766 1280428583\n\nWe could also use the pipe symbol %&gt;%.\n\ntable3 %&gt;% separate(rate, into=c('cases', 'population'))\n#&gt; # A tibble: 6 × 4\n#&gt;   country      year cases  population\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     \n#&gt; 1 Afghanistan  1999 745    19987071  \n#&gt; 2 Afghanistan  2000 2666   20595360  \n#&gt; 3 Brazil       1999 37737  172006362 \n#&gt; 4 Brazil       2000 80488  174504898 \n#&gt; 5 China        1999 212258 1272915272\n#&gt; 6 China        2000 213766 1280428583\n\nUsing separate, the first argument is the column to be separated. into is where you store the parsed data. If no arguments are given, separate() will split values wherever it sees a non-alphanumeric character. If you would like to specify a separator, you may use the sep argument.\n\nIf sep is set to be a character, the column will be separated by the character.\nIf sep is set to be a vector of integers, the column will be separated by the positions.\n\n\nseparate(table3, rate, into=c('cases', 'population'), sep='/')\n#&gt; # A tibble: 6 × 4\n#&gt;   country      year cases  population\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     \n#&gt; 1 Afghanistan  1999 745    19987071  \n#&gt; 2 Afghanistan  2000 2666   20595360  \n#&gt; 3 Brazil       1999 37737  172006362 \n#&gt; 4 Brazil       2000 80488  174504898 \n#&gt; 5 China        1999 212258 1272915272\n#&gt; 6 China        2000 213766 1280428583\n\n\nseparate(table3, rate, into=c('cases', 'population'), sep=c(2,5))\n#&gt; # A tibble: 6 × 4\n#&gt;   country      year cases population\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     \n#&gt; 1 Afghanistan  1999 74    5/1       \n#&gt; 2 Afghanistan  2000 26    66/       \n#&gt; 3 Brazil       1999 37    737       \n#&gt; 4 Brazil       2000 80    488       \n#&gt; 5 China        1999 21    225       \n#&gt; 6 China        2000 21    376\n\nNote that in this example, since into only has two columns, the rest of the data are lost.\nAnother useful argument is convert. After separation, the columns are still character columns. If we set convert=TRUE, the columns will be automatically converted into better types if possible.\n\nseparate(table3, rate, into=c('cases', 'population'), convert=TRUE)\n#&gt; # A tibble: 6 × 4\n#&gt;   country      year  cases population\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;int&gt;      &lt;int&gt;\n#&gt; 1 Afghanistan  1999    745   19987071\n#&gt; 2 Afghanistan  2000   2666   20595360\n#&gt; 3 Brazil       1999  37737  172006362\n#&gt; 4 Brazil       2000  80488  174504898\n#&gt; 5 China        1999 212258 1272915272\n#&gt; 6 China        2000 213766 1280428583\n\n\n\n9.2.1.4 unite()\nunite() is the inverse of separate(). The syntax is straghtforward. The default separator is _.\n\ntable3 %&gt;% unite(new, year, rate, sep='_')\n#&gt; # A tibble: 6 × 2\n#&gt;   country     new                   \n#&gt;   &lt;chr&gt;       &lt;chr&gt;                 \n#&gt; 1 Afghanistan 1999_745/19987071     \n#&gt; 2 Afghanistan 2000_2666/20595360    \n#&gt; 3 Brazil      1999_37737/172006362  \n#&gt; 4 Brazil      2000_80488/174504898  \n#&gt; 5 China       1999_212258/1272915272\n#&gt; 6 China       2000_213766/1280428583",
    "crumbs": [
      "Part II: R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>R for Data Sciences</span>"
    ]
  },
  {
    "objectID": "contents/9/intro.html#dplyr",
    "href": "contents/9/intro.html#dplyr",
    "title": "9  R for Data Sciences",
    "section": "9.3 dplyr",
    "text": "9.3 dplyr\ndplyr is a package used to manipulate data. Here we will just introduce the most basic functions. We will use nycflights13::flights as the example. This dataset comes from the US Bureau of Transportation Statistics. The document can be found here.\nTo load the dataset, please use the following code.\n\nlibrary(nycflights13)\nflights\n#&gt; # A tibble: 336,776 × 19\n#&gt;     year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;    &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt;  1  2013     1     1      517            515         2      830            819\n#&gt;  2  2013     1     1      533            529         4      850            830\n#&gt;  3  2013     1     1      542            540         2      923            850\n#&gt;  4  2013     1     1      544            545        -1     1004           1022\n#&gt;  5  2013     1     1      554            600        -6      812            837\n#&gt;  6  2013     1     1      554            558        -4      740            728\n#&gt;  7  2013     1     1      555            600        -5      913            854\n#&gt;  8  2013     1     1      557            600        -3      709            723\n#&gt;  9  2013     1     1      557            600        -3      838            846\n#&gt; 10  2013     1     1      558            600        -2      753            745\n#&gt; # ℹ 336,766 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#&gt; #   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#&gt; #   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n9.3.1 filter()\nfilter() allows you to subset observations based on their values. The first argument is the name of the tibble. The rest are the expressions that filter the data. Please see the following examples.\n\nflights %&gt;% filter(month==1, day==1)\n#&gt; # A tibble: 842 × 19\n#&gt;     year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;    &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt;  1  2013     1     1      517            515         2      830            819\n#&gt;  2  2013     1     1      533            529         4      850            830\n#&gt;  3  2013     1     1      542            540         2      923            850\n#&gt;  4  2013     1     1      544            545        -1     1004           1022\n#&gt;  5  2013     1     1      554            600        -6      812            837\n#&gt;  6  2013     1     1      554            558        -4      740            728\n#&gt;  7  2013     1     1      555            600        -5      913            854\n#&gt;  8  2013     1     1      557            600        -3      709            723\n#&gt;  9  2013     1     1      557            600        -3      838            846\n#&gt; 10  2013     1     1      558            600        -2      753            745\n#&gt; # ℹ 832 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#&gt; #   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#&gt; #   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\n9.3.2 select()\nselect() allows you to filter columns. It is very similar to slicing [].\n\n\n9.3.3 mutate()\nmutate() is used to add new columns that are functions of existing columns.\n\nflights %&gt;% mutate(gain=arr_delay-dep_delay, hours=air_time/60, gain_per_hour=gain/hours)\n#&gt; # A tibble: 336,776 × 22\n#&gt;     year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;    &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt;  1  2013     1     1      517            515         2      830            819\n#&gt;  2  2013     1     1      533            529         4      850            830\n#&gt;  3  2013     1     1      542            540         2      923            850\n#&gt;  4  2013     1     1      544            545        -1     1004           1022\n#&gt;  5  2013     1     1      554            600        -6      812            837\n#&gt;  6  2013     1     1      554            558        -4      740            728\n#&gt;  7  2013     1     1      555            600        -5      913            854\n#&gt;  8  2013     1     1      557            600        -3      709            723\n#&gt;  9  2013     1     1      557            600        -3      838            846\n#&gt; 10  2013     1     1      558            600        -2      753            745\n#&gt; # ℹ 336,766 more rows\n#&gt; # ℹ 14 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#&gt; #   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#&gt; #   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, gain &lt;dbl&gt;, hours &lt;dbl&gt;,\n#&gt; #   gain_per_hour &lt;dbl&gt;\n\nIf you only want to see the new columns, transmute() can be used.\n\nflights %&gt;% transmute(gain=arr_delay-dep_delay, hours=air_time/60, gain_per_hour=gain/hours)\n#&gt; # A tibble: 336,776 × 3\n#&gt;     gain hours gain_per_hour\n#&gt;    &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;\n#&gt;  1     9 3.78           2.38\n#&gt;  2    16 3.78           4.23\n#&gt;  3    31 2.67          11.6 \n#&gt;  4   -17 3.05          -5.57\n#&gt;  5   -19 1.93          -9.83\n#&gt;  6    16 2.5            6.4 \n#&gt;  7    24 2.63           9.11\n#&gt;  8   -11 0.883        -12.5 \n#&gt;  9    -5 2.33          -2.14\n#&gt; 10    10 2.3            4.35\n#&gt; # ℹ 336,766 more rows\n\nHere are an (incomplete) list of supported operators and functions.\n\nArithmetic operators: +, -, *, /, ^.\nModular arithmetic: %/% (integer division), %% (remainder).\nLogs: log(), log2(), log10().\nCumulative and rolling aggregates: cumsum(), cumprod(), cummin(), cummax(), cummean()\nLogical comparisons: &lt;, &lt;=, &gt;, &gt;=, !=.\n\n\n\n9.3.4 summarize() and group_by()\nsummarize() collapses a dataset to a single row. It computes values across all rows. It is usually paired with group_by(). Here are some examples.\n\nExample 9.3  \n\nflights %&gt;% group_by(year, month, day) %&gt;% \n    summarize(delay=mean(dep_delay, na.rm=TRUE))\n#&gt; `summarise()` has grouped output by 'year', 'month'. You can override using the\n#&gt; `.groups` argument.\n#&gt; # A tibble: 365 × 4\n#&gt; # Groups:   year, month [12]\n#&gt;     year month   day delay\n#&gt;    &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n#&gt;  1  2013     1     1 11.5 \n#&gt;  2  2013     1     2 13.9 \n#&gt;  3  2013     1     3 11.0 \n#&gt;  4  2013     1     4  8.95\n#&gt;  5  2013     1     5  5.73\n#&gt;  6  2013     1     6  7.15\n#&gt;  7  2013     1     7  5.42\n#&gt;  8  2013     1     8  2.55\n#&gt;  9  2013     1     9  2.28\n#&gt; 10  2013     1    10  2.84\n#&gt; # ℹ 355 more rows\n\n\n\nExample 9.4  \n\ndelays &lt;- flights %&gt;% \n    group_by(dest) %&gt;% \n    summarize(\n        count=n(), \n        dist=mean(distance, na.rm=TRUE),\n        delay=mean(arr_delay, na.rm=TRUE)\n    ) %&gt;% \n    filter(count&gt;20, dest!='HNL')\ndelays\n#&gt; # A tibble: 96 × 4\n#&gt;    dest  count  dist delay\n#&gt;    &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt;  1 ABQ     254 1826   4.38\n#&gt;  2 ACK     265  199   4.85\n#&gt;  3 ALB     439  143  14.4 \n#&gt;  4 ATL   17215  757. 11.3 \n#&gt;  5 AUS    2439 1514.  6.02\n#&gt;  6 AVL     275  584.  8.00\n#&gt;  7 BDL     443  116   7.05\n#&gt;  8 BGR     375  378   8.03\n#&gt;  9 BHM     297  866. 16.9 \n#&gt; 10 BNA    6333  758. 11.8 \n#&gt; # ℹ 86 more rows\n\n\ngroup_by() can also be used together with mutate() and filter().\n\nExample 9.5  \n\nflights %&gt;%\n    group_by(dest) %&gt;%\n    filter(n() &gt; 365) %&gt;%\n    filter(arr_delay &gt; 0) %&gt;%\n    mutate(prop_delay = arr_delay / sum(arr_delay)) %&gt;%\n    select(year:day, dest, arr_delay, prop_delay)\n#&gt; # A tibble: 131,106 × 6\n#&gt; # Groups:   dest [77]\n#&gt;     year month   day dest  arr_delay prop_delay\n#&gt;    &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n#&gt;  1  2013     1     1 IAH          11  0.000111 \n#&gt;  2  2013     1     1 IAH          20  0.000201 \n#&gt;  3  2013     1     1 MIA          33  0.000235 \n#&gt;  4  2013     1     1 ORD          12  0.0000424\n#&gt;  5  2013     1     1 FLL          19  0.0000938\n#&gt;  6  2013     1     1 ORD           8  0.0000283\n#&gt;  7  2013     1     1 LAX           7  0.0000344\n#&gt;  8  2013     1     1 DFW          31  0.000282 \n#&gt;  9  2013     1     1 ATL          12  0.0000400\n#&gt; 10  2013     1     1 DTW          16  0.000116 \n#&gt; # ℹ 131,096 more rows\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe already use it in the above examples. This is to compute the number of observations in the current group. This function is implemented specifically for each data source and can only be used from within summarise(), mutate() and filter().",
    "crumbs": [
      "Part II: R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>R for Data Sciences</span>"
    ]
  },
  {
    "objectID": "contents/9/intro.html#ggplot2",
    "href": "contents/9/intro.html#ggplot2",
    "title": "9  R for Data Sciences",
    "section": "9.4 ggplot2",
    "text": "9.4 ggplot2\nThis is the graphing package for R in tidyverse. ggplot2 implements the grammar of graphics, a coherent system for describing and building graphs. With ggplot2, you can do more faster by learning one system and applying it in many places. The main function is ggplot().\nggplot2 will be uploaded with tidyverse.\n\nlibrary(tidyverse)\n\nWe use the dataset mpg as the example. This dataset comes with ggplot2. Once you load ggplot2 you can directly find the dataset by typing mpg.\n\nmpg\n#&gt; # A tibble: 234 × 11\n#&gt;    manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class\n#&gt;    &lt;chr&gt;        &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt;  1 audi         a4           1.8  1999     4 auto… f        18    29 p     comp…\n#&gt;  2 audi         a4           1.8  1999     4 manu… f        21    29 p     comp…\n#&gt;  3 audi         a4           2    2008     4 manu… f        20    31 p     comp…\n#&gt;  4 audi         a4           2    2008     4 auto… f        21    30 p     comp…\n#&gt;  5 audi         a4           2.8  1999     6 auto… f        16    26 p     comp…\n#&gt;  6 audi         a4           2.8  1999     6 manu… f        18    26 p     comp…\n#&gt;  7 audi         a4           3.1  2008     6 auto… f        18    27 p     comp…\n#&gt;  8 audi         a4 quattro   1.8  1999     4 manu… 4        18    26 p     comp…\n#&gt;  9 audi         a4 quattro   1.8  1999     4 auto… 4        16    25 p     comp…\n#&gt; 10 audi         a4 quattro   2    2008     4 manu… 4        20    28 p     comp…\n#&gt; # ℹ 224 more rows\n\nThe syntax for ggplot() is ::: {.cell}\nggplot(data = &lt;DATA&gt;) +\n    &lt;GEOM_FUNCTION&gt;(mapping = aes(&lt;MAPPINGS&gt;))\n:::\nggplot(data=&lt;DATA&gt;) create a plot without any geometric elements. It simply creates the canvas paired with the dataset.\nThen you add one or more layers to ggplot() to complete the graph. The function &lt;GEOM_FUNCTION&gt;(mapping = aes(&lt;MAPPINGS&gt;)) adds a layer to the plot. You may add as many layers as you want.\nEach geom function takes a mapping argument. This defines how variables in the dataset are mapped to visual properties. mapping is always paired with aes(x=, y=). This\nHere is a quick example.\n\nggplot(data = mpg) +\n    geom_point(mapping = aes(x = displ, y = hwy))\n\n\n\n\n\n\n\n\n\n9.4.1 Aesthetic mappings\nAn aesthetic is a visual property of the objects in your plot. It include things like the size, the shape or the color of the points. The variables set in aes() will change the aesthetic apperance of the geometric objects according to the variables. If the variables are set outside aes(), the apperance will be fixed. Please see the following examples.\nNote that the variables in aes() other than x and y will automatically get legends.\n\nggplot(data = mpg) +\n    geom_point(mapping = aes(x = displ, y = hwy), color = \"blue\")\n\n\n\n\n\n\n\nggplot(data = mpg) +\n    geom_point(mapping = aes(x = displ, y = hwy, color = class))\n\n\n\n\n\n\n\n\n\n\n9.4.2 facet\nFor categorical data, you can split the plot into facets. This facet function will be attached as a layer followed by a + sign.\n\nTo facet your plot by a single variable, use facet_wrap(). The first argument should be a formula, which you create with ~ followed by a variable name.\nTo facet your plot by two variables, use facet_grid(). The first argument is a formula which contains two variable names separated by a ~.\n\n\nExample 9.6  \n\nggplot(data = mpg) +\n    geom_point(mapping = aes(x = displ, y = hwy)) +\n    facet_wrap(~ class, nrow = 2)\n\n\n\n\n\n\n\n\nYou may look at the variables to see the relations with the plot.\n\nunique(mpg$class)\n#&gt; [1] \"compact\"    \"midsize\"    \"suv\"        \"2seater\"    \"minivan\"   \n#&gt; [6] \"pickup\"     \"subcompact\"\n\n\n\nExample 9.7  \n\nggplot(data = mpg) +\n    geom_point(mapping = aes(x = displ, y = hwy)) +\n    facet_grid(drv ~ cyl)\n\n\n\n\n\n\n\n\nYou may look at the variables to see the relations with the plot.\n\nunique(mpg$drv)\n#&gt; [1] \"f\" \"4\" \"r\"\nunique(mpg$cyl)\n#&gt; [1] 4 6 8 5\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe ~ symbol is used to define a formula. The formula is a R object, which provide the pattern of a “formula”. Therefore drv~cyl means that drv is a function of cyl.\n\n\n\n\n9.4.3 geom objects\nA geom is the geometrical object that a plot uses to represent data. When drawing plots, you just need to attach those geometrical objects to a ggplot canvas with + symbol. Some of the geometrical objects can automatically do statistical transformations. The statistical transformations is short for stat, and the stat argument in those geom will show which statistical transformations are applied.\n\ngeom_point() draws scatter plot.\ngeom_smooth() draws smooth line approximation.\ngeom_bar() draws bar plot.\ngeom_histogram() draws histogram.\n\nThe arguments can be written in ggplot(). All the later geom will get those arguments from ggplot(). If the arguments are written again in geom object, it will override the ggplot() arguments.\n\nExample 9.8  \n\nggplot(data = mpg) +\n    geom_point(mapping = aes(x = displ, y = hwy))\n\n\n\n\n\n\n\n\nggplot(data = mpg) +\n    geom_smooth(mapping = aes(x = displ, y = hwy), formula = y ~ x, method = \"loess\")\n\n\n\n\n\n\n\n\nggplot(data = mpg) +\n    geom_smooth(mapping = aes(x = displ, y = hwy, linetype = drv), formula = y ~ x, method = \"loess\")\n\n\n\n\n\n\n\n\nggplot(data = mpg) +\n    geom_point(mapping = aes(x = displ, y = hwy)) +\n    geom_smooth(mapping = aes(x = displ, y = hwy), formula = y ~ x, method = \"loess\")\n\n\n\n\n\n\n\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +\n    geom_point(mapping = aes(color = class)) +\n    geom_smooth(\n        data = filter(mpg, class == \"subcompact\"),\n        se = FALSE, \n        formula = y ~ x, method = \"loess\"\n        )",
    "crumbs": [
      "Part II: R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>R for Data Sciences</span>"
    ]
  },
  {
    "objectID": "contents/9/intro.html#exercises",
    "href": "contents/9/intro.html#exercises",
    "title": "9  R for Data Sciences",
    "section": "9.5 Exercises",
    "text": "9.5 Exercises\n\nExercise 9.1 How can you tell if an object is a tibble?\n\n\nExercise 9.2 Compare and contrast the following operations on a data.frame and equivalent tibble. What is different? Why might the default data frame behaviors cause you frustration?\n\ndf &lt;- data.frame(abc = 1, xyz = \"a\")\ndf$x\ndf[, \"xyz\"]\ndf[, c(\"abc\", \"xyz\")]\n\n\n\nExercise 9.3 If you have the name of a variable stored in an object, e.g., var &lt;- \"xyz\", how can you extract the reference variable from a tibble? You may use the following codes to get a tibble.\n\ntbl &lt;- tibble(abc = 1, xyz = \"a\")\n\n\n\nExercise 9.4 Practice referring to nonsyntactic names in the following data.frame by:\n\nExtracting the variable called 1.\nCreating a new column called 3, which is 2 divided by 1.\nRenaming the columns to one, two, and three:\n\n\nannoying &lt;- tibble(\n`1` = 1:10,\n`2` = `1` * 2 + rnorm(length(`1`))\n)\n\n\n\nExercise 9.5 Both unite() and separate() have a remove argument. What does it do? Why would you set it to FALSE?\n\n\nExercise 9.6 Use flights dataset. Currently dep_time and sched_dep_time are convenient to look at, but hard to compute with because they’re not really continuous numbers. Convert them to a more convenient representation of number of minutes since midnight.\n\n\n\n\n\nExercise 9.7 Please make the following data tidy.\n\nlibrary(tidyverse)\ndf &lt;- tibble(Day=1:5, `Plant_A_Height (cm)`=c(0.5, 0.7, 0.9, 1.3, 1.8), `Plant_B_Height (cm)`=c(0.7, 1, 1.5, 1.8, 2.2))\n\n\n\nExercise 9.8 Please use the flights dataset. Please find all flights that :\n\nHad an arrival delay of two or more hours.\nFlew to IAH or HOU.\nWere operated by United, American or Delta.\nDeparted in summer (July, August, and September).\nArrived more than two hours late, but didn’t leave late.\nWere delayed by at least an hour, but made up over 30 minutes in flight.\nDeparted between midnight and 6 a.m. (inclusive).\n\n\n\nExercise 9.9 Re-create the R code necessary to generate the following graphs. The dataset is mpg.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[1] Wickham, H. and Grolemund, G. (2017). R for data science: Import, tidy, transform, visualize, and model data. O’Reilly Media.",
    "crumbs": [
      "Part II: R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>R for Data Sciences</span>"
    ]
  },
  {
    "objectID": "contents/10/intro.html#who-tb-dataset",
    "href": "contents/10/intro.html#who-tb-dataset",
    "title": "10  Projects with R",
    "section": "10.1 WHO TB dataset",
    "text": "10.1 WHO TB dataset\nLet us explore the tuberculosis cases data. The dataset is provided by WHO and can be downloaded from here. tidyr also provides the dataset. You may directly get the dataset after you load tidyr from tidyverse. The variable description can be found from tidyr documentations.\n\nlibrary(tidyverse)\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.1\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nwho\n#&gt; # A tibble: 7,240 × 60\n#&gt;    country  iso2  iso3   year new_sp_m014 new_sp_m1524 new_sp_m2534 new_sp_m3544\n#&gt;    &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n#&gt;  1 Afghani… AF    AFG    1980          NA           NA           NA           NA\n#&gt;  2 Afghani… AF    AFG    1981          NA           NA           NA           NA\n#&gt;  3 Afghani… AF    AFG    1982          NA           NA           NA           NA\n#&gt;  4 Afghani… AF    AFG    1983          NA           NA           NA           NA\n#&gt;  5 Afghani… AF    AFG    1984          NA           NA           NA           NA\n#&gt;  6 Afghani… AF    AFG    1985          NA           NA           NA           NA\n#&gt;  7 Afghani… AF    AFG    1986          NA           NA           NA           NA\n#&gt;  8 Afghani… AF    AFG    1987          NA           NA           NA           NA\n#&gt;  9 Afghani… AF    AFG    1988          NA           NA           NA           NA\n#&gt; 10 Afghani… AF    AFG    1989          NA           NA           NA           NA\n#&gt; # ℹ 7,230 more rows\n#&gt; # ℹ 52 more variables: new_sp_m4554 &lt;dbl&gt;, new_sp_m5564 &lt;dbl&gt;,\n#&gt; #   new_sp_m65 &lt;dbl&gt;, new_sp_f014 &lt;dbl&gt;, new_sp_f1524 &lt;dbl&gt;,\n#&gt; #   new_sp_f2534 &lt;dbl&gt;, new_sp_f3544 &lt;dbl&gt;, new_sp_f4554 &lt;dbl&gt;,\n#&gt; #   new_sp_f5564 &lt;dbl&gt;, new_sp_f65 &lt;dbl&gt;, new_sn_m014 &lt;dbl&gt;,\n#&gt; #   new_sn_m1524 &lt;dbl&gt;, new_sn_m2534 &lt;dbl&gt;, new_sn_m3544 &lt;dbl&gt;,\n#&gt; #   new_sn_m4554 &lt;dbl&gt;, new_sn_m5564 &lt;dbl&gt;, new_sn_m65 &lt;dbl&gt;, …\n\nBased on the description of varaibles, we understand that\n\ncountry, iso2, iso3 are all refered to country names (and thus they are redundant).\nColumns after year, like new_sp_m014 etc., are counts of new TB cases recorded by groups. The code has three parts, most of which are separated by _ (but there are some exceptions).\n\nThe first part is always new.\nThe second part is a code for method of diagnosis:\n\nrel = relapse,\nsn = negative pulmonary smear,\nsp = positive pulmonary smear,\nep = extrapulmonary.\n\nThe third part is a code for gender (f = female, m = male) and a code for age group:\n\n014 = 0-14 yrs of age,\n1524 = 15-24 years of age,\n2534 = 25 to 34 years of age,\n3544 = 35 to 44 years of age,\n4554 = 45 to 54 years of age,\n5564 = 55 to 64 years of age,\n65 = 65 years of age or older\n\n\n\nTherefore to clean the data, we need the following steps.\n\nExample 10.1 Gather together all the columns from new_sp_m014 to newrel_f65.\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nwholonger &lt;- who %&gt;% pivot_longer(cols=5:60, names_to='group', values_to='counts')\n\n\n\n\n\nThen we use stringr::str_replace() to replace newrel by new_rel.\n\nwholonger2 &lt;- wholonger %&gt;% mutate(key=str_replace(group, 'newrel', 'new_rel'))\n\n\nExample 10.2 Parse the column group into columns.\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nwholonger3 &lt;- wholonger2 %&gt;% \n        separate(key, into=c('new', 'type', 'genderage'), sep='_') %&gt;% \n        separate(genderage, into=c('gender', 'age'), sep=1)\n\n\n\n\n\n\nExample 10.3 Pick the columns that matters.\n\n\n\n\n\n\nTip\n\n\n\n\n\n\ntidywho &lt;- wholonger3[c('country', 'year', 'type', 'gender', 'age', 'counts')]\n\n\n\n\n\nWe could use the pipe symbol to connect all the above steps.\n\n\n\n\n\n\nTip\n\n\n\n\n\n\ntidywho &lt;- who %&gt;% \n    pivot_longer(cols=5:60, names_to='group', values_to='counts') %&gt;% \n    mutate(key=str_replace(group, 'newrel', 'new_rel')) %&gt;% \n    separate(key, into=c('new', 'type', 'genderage'), sep='_') %&gt;% \n    separate(genderage, into=c('gender', 'age'), sep=1) %&gt;% \n    select('country', 'year', 'type', 'gender', 'age', 'counts')",
    "crumbs": [
      "Part II: R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Projects with R</span>"
    ]
  },
  {
    "objectID": "contents/10/intro.html#us-babynames",
    "href": "contents/10/intro.html#us-babynames",
    "title": "10  Projects with R",
    "section": "10.2 US Babynames",
    "text": "10.2 US Babynames\nLet us use R to solve the babynames dataset again.\nThe first task is to read those files.\n\nExample 10.4 Please read files and put the data into one tibble. The dataset can be downloaded from here as a zip file.\n\n\n\n\n\n\nTip\n\n\n\n\n\n\npath &lt;- 'assessts/datasets/babynames/yob'\ndfs &lt;- map(1880:2010, function(y){\n    filepath &lt;- paste0(path, as.character(y), '.txt')\n    df_individual &lt;- tibble(read.csv(filepath, header=FALSE))\n    names(df_individual) &lt;- c('name', 'gender', 'counts')\n    df_individual$year &lt;- y\n    df_individual\n})\ndf &lt;- bind_rows(dfs)\n\n\n\n\n\n\nExample 10.5 Please plot the total births by gender and year.\n\n\n\n\n\n\nTip\n\n\n\n\n\n\ndf %&gt;% \n    group_by(gender, year) %&gt;% \n    summarize(total_num=sum(counts)) %&gt;% \n    ggplot() +\n        geom_line(mapping = aes(x=year, y=total_num, color=gender))\n#&gt; `summarise()` has grouped output by 'gender'. You can override using the\n#&gt; `.groups` argument.\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 10.6 Please compute the proportions of each name relateive to the total number of births per year per gender.\n\n\n\n\n\n\nTip\n\n\n\n\n\n\ndf %&gt;% \n    group_by(gender, year) %&gt;% \n    mutate(prop=counts/sum(counts))\n#&gt; # A tibble: 1,690,784 × 5\n#&gt; # Groups:   gender, year [262]\n#&gt;    name      gender counts  year   prop\n#&gt;    &lt;chr&gt;     &lt;chr&gt;   &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;\n#&gt;  1 Mary      F        7065  1880 0.0776\n#&gt;  2 Anna      F        2604  1880 0.0286\n#&gt;  3 Emma      F        2003  1880 0.0220\n#&gt;  4 Elizabeth F        1939  1880 0.0213\n#&gt;  5 Minnie    F        1746  1880 0.0192\n#&gt;  6 Margaret  F        1578  1880 0.0173\n#&gt;  7 Ida       F        1472  1880 0.0162\n#&gt;  8 Alice     F        1414  1880 0.0155\n#&gt;  9 Bertha    F        1320  1880 0.0145\n#&gt; 10 Sarah     F        1288  1880 0.0142\n#&gt; # ℹ 1,690,774 more rows\n\n\n\n\n\n\nExample 10.7 We would like to keep the first 100 names (by counts) in each year and save it as a new tibble top100.\n\n\n\n\n\n\nTip\n\n\n\n\n\n\ntop100 &lt;- df %&gt;% \n        group_by(gender, year) %&gt;% \n        top_n(100, wt=counts)\n\n\n\n\n\n\nExample 10.8 Please draw the trend of John, Harry, Mary in top100 by counts.\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nnamelist &lt;- c('John', 'Harry', 'Mary')\ntop100 %&gt;% \n    filter(name %in% namelist) %&gt;% \n    ggplot() +\n        geom_line(mapping=aes(x=year, y=counts, color=name))\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 10.9 Now we would like to analyze the ending of names. Please get a tibble that contains the counts of ending letter per year per gender. We mainly focus on 1910, 1960 and 2010.\n\n\n\n\n\n\nTip\n\n\n\n\n\n\ndf %&gt;% \n    filter(year %in% c(1910, 1960, 2010)) %&gt;% \n    mutate(ending=str_sub(name, -1, -1), \n           year=as.factor(year)) %&gt;% \n    group_by(gender, year, ending) %&gt;% \n    summarise(ending_counts=sum(counts)) %&gt;% \n    ggplot() +\n        geom_col(\n            mapping = aes(\n                x=ending, \n                y=ending_counts, \n                fill=year,\n                ), \n            position = \"dodge\",\n        ) +\n        facet_wrap(~gender, nrow=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 10.10 Please draw the line plot to show the trending of certain letters through years. Here we choose d, n and y.\n\n\n\n\n\n\nTip\n\n\n\n\n\n\ndf %&gt;% \n    mutate(ending=str_sub(name, -1, -1)) %&gt;% \n    group_by(year, ending) %&gt;% \n    summarise(ending_counts=sum(counts)) %&gt;% \n    filter(ending %in% c('d', 'n', 'y')) %&gt;% \n    ggplot() +\n        geom_line(\n            mapping = aes(\n                x=year, \n                y=ending_counts, \n                color=ending\n            )\n        )",
    "crumbs": [
      "Part II: R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Projects with R</span>"
    ]
  },
  {
    "objectID": "contents/10/intro.html#references",
    "href": "contents/10/intro.html#references",
    "title": "10  Projects with R",
    "section": "References",
    "text": "References",
    "crumbs": [
      "Part II: R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Projects with R</span>"
    ]
  },
  {
    "objectID": "contents/app/setup.html#sec-vscode",
    "href": "contents/app/setup.html#sec-vscode",
    "title": "Appendix A — Python Setup",
    "section": "A.1 VS Code + Anaconda",
    "text": "A.1 VS Code + Anaconda\nNote that all the following steps are tested in Windows 10/11. If you use other operation systems please contact me.\n\nGo to Miniconda download page. Download and install Miniconda, and set things up in the following way.\n\n\n\n\n\n\n\nMore details.\n\n\n\n\n\n\nMiniconda is Python + conda, without any unessential packages. We choose this version because it is fast: the download package is small and easy to install.\nAfter you finish installing Miniconda, you may find the Anaconda Prompt (miniconda 3) from the start menu. Click it to start using it.\nYou may use the following command to install packages that is used in this course. More on this will be discussed later.\n\nconda install pandas numpy matplotlib seaborn\n\nIf you feel conda is slow, you may change the conda solver to be libmamba using the following command. It may be faster than the classic conda solver.\n\nconda config --set solver libmamba\n\nOnce these packages are installed, you may close the command prompt window and proceed to the next step.\n\n\n\n\n\n\n\n\n\n\nAn alternative way.\n\n\n\n\n\nIf you have enough time and space, you may go to Anaconda download page, download and install Anaconda.\nAnaconda is Miniconda + tons of preinstalled packages + many other tools that may not be used in this course.\n\n\n\n\nGo to VS Code download page. Download and install VS Code. Actually Anaconda contains one copy of VS Code. Here I just assume that some of you intall VS Code before Anaconda.\nWhen installing VS Code, you may accept all default settings. When installing Anaconda, please pay attention to the PATH setting.\n\n\n\n\n\n\nThe first box is unchecked by default. This setting is related to the ability to easily run Python code in Terminals. I recommend you to check it. If you don’t check it during this step, you may add it to the system environment variable PATH manually later.\n\nThe UI of VS Code looks as follows.\n\n\n\n\n\n\nPlease look at the fifth tab from the left sidebar. It is the Extension tab.\n\n\n\n\n\nPlease search for python and install the first Python extension from Microsoft. It will actually install five extensions. These are all we need for now.\n\nAfter all are installed, go to the first Explorer tab on the left side bar, and Open Folder. This is the working directory for your project.\n\n\n\n\n\n\nChoose one folder and start a new .py file.\n\n\n\n\n\n\nIf everything is setup correctly, you may see the Python version and environment name at the right lower corner. In our case the environment name is base. We will need it in the future.\n\n\n\n\n\n\nNote that we are not looking at the Python for Language Mode. If you see Select Interpreter there, it means that VS Code doesn’t find your Python interpreter. Please restart VS Code or select it manually, or check whether Anaconda is installed correctly.\n\n\n\n\n\nTo check whether everything is setup correctly, please run the following tests.\n\nUse ctrl+shift+p to open the Command Palette, type “Jupyter: Create Interactive Window” and press enter to open the Jupyter interactive window.\n\n\n\n\n\n\nIf the interactive window starts and you see the loading infomation of your kernel as follows, especially you see the environment name on the right upper corner, then you get everything correctly. However we will still do more tests.\n\n\n\n\n\n\nIn the window type import numpy as np to test whether you are able to import packages. If you don’t see any error messages then it means good.\n\n\n\n\n\n\n\nIn the editor window, type import numpy as np and right click the body to choose Run Current File in Interactive Window, and see whether it runs in interactive window.\n\n\n\n\n\n\n\nOpen the terminal. Please use Command Prompt instead of Powershell. Activate the conda environment by type the command conda activate base in the example above. Please change the name to match your own environment. If conda cannot be recognized, please register Python and Anaconda to the system environment path. Please see the next Appendix for details.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Python Setup</span>"
    ]
  },
  {
    "objectID": "contents/app/setup.html#sec-googlecolab",
    "href": "contents/app/setup.html#sec-googlecolab",
    "title": "Appendix A — Python Setup",
    "section": "A.2 Google Colab",
    "text": "A.2 Google Colab\nGoogle Colab is a product from Google Research, that allows anybody to write and execute arbitrary Python code through the browser, and is especially well suited to machine learning, data analysis and education.\nHere is the link to Google Colab. To use it you should have a Google account. Otherwise it is very simple to start, since a lot of packages for our course are already installed.\n\nA.2.1 Install packages\nIf you would like to install more packages, you can type the following code in a code cell and execute it.\n%pip install &lt;pkg name&gt;\n%conda install &lt;pkg name&gt;\nThe drawback here is that Google Colab can only stay for 24 hours. After that, all additionaly installed packages will be earsed. However you may put the installation code mentioned above at the beginning of your notebook and these packages will be installed every time you run the notebook.\n\n\nA.2.2 Upload files\nYou may directly upload files to the working directory of Google Colab. This has to be done in the browser. When working with these files, you may just use relative paths.\nThe drawback here is that Google Colab can only stay for 24 hours. After that, although your .ipynb files will be stores, all other files will be earsed.\n\n\nA.2.3 Mount Google Drive\nOne way to let the uploaded files stay in cloud is to upload them to Google Drive, and then load your Google Drive contents from Google Colab.\nGoole Drive is a cloud storage service provided by Google. When you register a Google account you will be automatically assigned a Google Drive account. You may get access to it from this link.\nHere are the steps to mount Google Drive:\n\nUpload your files to your Google Drive.\nRun the following codes in Colab code cells before you are loading the uploaded files:\n\n\nfrom google.colab import drive\ndrive.mount('/content/gdrive')\n\n\nA window pop up asking you about the permission. Authorize and the drive is mounted.\nTo work in directories, the most popular commands are\n\n%ls: list all files and folders in the working directory.\n%cd + folder name: Get into a specific folder.\n%cd..: Get into the parent folder. Then use these commands to find the files your just uploaded.\n\nFinally you may directly get access to those files just like they are in the working directory.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Python Setup</span>"
    ]
  },
  {
    "objectID": "contents/app/path.html",
    "href": "contents/app/path.html",
    "title": "Appendix B — Environemnt Variable PATH",
    "section": "",
    "text": "Here are the steps to edit the system environment variables in Windows 10/11.\n\nFirst in the start menu search for Edit the system environment variables.\n\n\n\n\n\n\n\nThen click the Environment Variables... button at the right lower corner.\n\n\n\n\n\n\n\nFind the Path variable in either the upper window or the lower window. Use which one depends on whether you want to register the variable for the user or for the machine. In this example I add for the user.\n\n\n\n\n\n\n\nFinally double click the variable and add the following path to it. You need to make changes according to your installation. I recommend you to locate your Anaconda installation first to get the path.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Environemnt Variable `PATH`</span>"
    ]
  },
  {
    "objectID": "contents/app/virtenv.html#package-management",
    "href": "contents/app/virtenv.html#package-management",
    "title": "Appendix C — Python Virtual Environment",
    "section": "C.1 Package management",
    "text": "C.1 Package management\nThere are two most popular package management tools for Python, pip and conda.\n\npip is the official package management tool for Python.\nconda was originally developed by Anaconda Inc., and later became open-sourced.\n\nIn this course, we mainly focus on conda since it is designed towards Data Science.\n\nInstall packages. You may specify the particular version number.\n\nconda install &lt;pkg name&gt;\nconda install &lt;pkg name&gt;=&lt;version number&gt;\n\nList all installed packages, or list several specific installed packages:\n\nconda list\nconda list &lt;pkg names&gt;\n\nUpdate packages.\n\nconda updata &lt;pkg name&gt;\n\nRemove packages.\n\nconda remove &lt;pkg name&gt;\n\nIf the packages you want is in PyPI but not in conda channels, you may use pip to install that package.\n\npip install &lt;pkg name&gt;\nNote that if the package is in both conda channels and PyPI, it is recommended not to mix pip and conda. If you start from conda, just stick to conda. Only use pip when you have to.\n\n\n\n\n\n\nPyPI and conda-forge\n\n\n\n\n\nThe package managemers will download packages from online repository to install in your environment. By default, pip and conda use two different repositories.\n\nPyPI: PyPI stands for Python Package Index. It is the official third-party software repository for Python. pip use it as the default source for packages and their dependencies. Packages on PyPI are typically uploaded by the author of the Python package.\nconda-forge: Anaconda, Inc. provides several channels that host packages. Conda-Forge is one of the most important channels. Although it is a community project, it is now the recommended channel to get packages through conda. In conda-forge, package maintainers can be different than the original author of the package.\n\nUsually PyPI contains more packages than conda-forge, and the versions of packages get to PyPI faster. However, when using conda through conda-forge, more safty checks are done and conda will try its best to make the installed packages compatible.\nTo install from conda-forge using conda, you should add an argument -c:\nconda install -c conda-forge &lt;pkg name&gt;",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Python Virtual Environment</span>"
    ]
  },
  {
    "objectID": "contents/app/virtenv.html#virtual-environments",
    "href": "contents/app/virtenv.html#virtual-environments",
    "title": "Appendix C — Python Virtual Environment",
    "section": "C.2 Virtual environments",
    "text": "C.2 Virtual environments\nVirtual environments provide a project-specific version of installed packages. This both helps you to faithfully reproduce your environment as well as isolate the use of packages so that upgrading a package in one project doesn’t break other projects. In this section we are going to use conda to manage environments. The main reference is the official document. We will just list the minimal working examples here. For more functions please read the official document.\n\nTo create an environment:\n\nconda create --name &lt;env name&gt;\n\nTo activate an environment:\n\nconda activate &lt;env name&gt;\nAfter you create a new environment and activate it, you may start to use the commands from the previous section to install packages.\n\nTo deactivate an environment:\n\nconda deactivate\n\nTo remove an environemnt, both of the following commands work:\n\nconda remove --name &lt;env name&gt; --all\nconda env remove -n &lt;env name&gt;\n\nTo get all enviroments in the system:\n\nconda env list\nconda info --envs\n\n\n\n\n\n\npip and venv\n\n\n\n\n\nUnlike conda, pip is only a package manager, and it doesn’t provide any virtual environment functions. The default virtual environment tool for Python is venv. You may go to the official document for more infomation about venv.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Python Virtual Environment</span>"
    ]
  },
  {
    "objectID": "contents/app/virtenv.html#building-identical-environments",
    "href": "contents/app/virtenv.html#building-identical-environments",
    "title": "Appendix C — Python Virtual Environment",
    "section": "C.3 Building identical environments",
    "text": "C.3 Building identical environments\nSometimes people want to build identical environments. This is done by recording the versions of all packages in the current environment into a spec list file. When rebuilding Python will pull the spec list file out and install the packages of the speicific versions based on the list.\nIn the process, there are two steps. First generate the pacakge spec list file. Second create an environment based on the list. Note that the spec list file generated by different methods have different formats. Therefore you have to use the correct command to restore the environment.\n\nC.3.1 Using conda\nTo produce a spec list, use the following command:\nconda list --explicit &gt; spec-file.txt\nTo install the packages, use the following command:\nconda create --name &lt;env name&gt; --file spec-file.txt\nA typical conda environment file looks like the following example.\n# This file may be used to create an environment using:\n# $ conda create --name &lt;env&gt; --file &lt;this file&gt;\n# platform: win-64\n@EXPLICIT\nhttps://repo.anaconda.com/pkgs/main/win-64/conda-env-2.6.0-1.conda\nhttps://repo.anaconda.com/pkgs/r/win-64/_r-mutex-1.0.0-anacondar_1.conda\nhttps://repo.anaconda.com/pkgs/main/win-64/blas-1.0-mkl.conda\n\n\nC.3.2 Using pip freeze\nThe classic popular way is pip freeze. To produce a spec list, use the following command:\npip freeze &gt; requirements.txt\nTo install the packages, use the following command:\npip install -r requirements.txt\nA typical pip requirements.txt file looks like the following example.\nanyio @ file:///C:/ci/anyio_1644481856696/work/dist\nargon2-cffi @ file:///opt/conda/conda-bld/argon2-cffi_1645000214183/work\nargon2-cffi-bindings @ file:///C:/ci/argon2-cffi-bindings_1644569876605/work\nasttokens==2.0.7\nattrs @ file:///C:/b/abs_09s3y775ra/croot/attrs_1668696195628/work\nBabel @ file:///tmp/build/80754af9/babel_1620871417480/work\nbackcall==0.2.0\n\n\n\n\n\n\nNote\n\n\n\nActually both ways are NOT satisfying. Therefore there are a lot of new tools coming out to deal with this task, like pipreqs and poetry. Here for simplicity we just briefly introduce the most basic ones.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Python Virtual Environment</span>"
    ]
  },
  {
    "objectID": "contents/app/virtenv.html#mamba",
    "href": "contents/app/virtenv.html#mamba",
    "title": "Appendix C — Python Virtual Environment",
    "section": "C.4 mamba",
    "text": "C.4 mamba\nmamba is a reimplementation of the conda package manager in C++. It can be installed directly from conda-forge.\nconda install -c conda-forge mamba\nAfter you install it in one of your environment, you may use it in all your environments.\nmamba can be treated as a drop-in replacement of conda. All commands we mentioned above can be rewritten by replacing conda with mamba. One of the reasons to use mamba over conda is that mamba runs so much faster than conda.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Python Virtual Environment</span>"
    ]
  },
  {
    "objectID": "contents/app/concepts.html#language",
    "href": "contents/app/concepts.html#language",
    "title": "Appendix D — Some Hard Python concepts",
    "section": "D.1 Language",
    "text": "D.1 Language\nPython is a programming language. In other words, it is a collection of syntaxes.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Some Hard Python concepts</span>"
    ]
  },
  {
    "objectID": "contents/app/concepts.html#interpreters",
    "href": "contents/app/concepts.html#interpreters",
    "title": "Appendix D — Some Hard Python concepts",
    "section": "D.2 Interpreters",
    "text": "D.2 Interpreters\nPython needs to be interpreted into codes that computers can understand. Therefore there should be some programs that translate Python scripts. These programs are called interpreters.\nCPython is the refernce interpreter of Python programming language, and it is the most widely used ones for Python. It is written in C and Python. When Python programming language introduces new features, they are developed based on CPython, and are first implemented in CPython. Sometimes an interpreter is also called an implementation.\nThere are alternatives to CPython, like PyPy, Jython, IronPython, etc.. In theory, any Python scripts should be able to run on any of these implementations, and the result should be the same. The differences mainly come from perfamance and compatiblity with non-Python packages. For example, CPython is executed by a C interpreter. Therefore it is very easy to write C-extensions for your Python code. Jython, since it is implemented in Java, makes it very easy to work with other Java programs that you can import any Java classes with no additional effort.\nSince CPython is most-widely used and tested, it is the best choice, at least for beginners. And actually, if you have no idea about this topic, but you use Python, it is highly possible that you are using CPython.\n\n\n\n\n\n\nNote\n\n\n\n\n\nWe mentioned “interpreter” here. There are mainly two types of implimentations of programming langauges: interpreters and compilers. There are also some additional types like just-in-time compilers which can be treated as combinations of the two.\nPython is usually treated as an interpreted language since CPython is an interpreter. One of Python’s most useful features is its interactive interpreter, which allows for very fast testing of ideas without the overhead of creating test files as is typical in most programming languages.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Some Hard Python concepts</span>"
    ]
  },
  {
    "objectID": "contents/app/concepts.html#repl",
    "href": "contents/app/concepts.html#repl",
    "title": "Appendix D — Some Hard Python concepts",
    "section": "D.3 REPL",
    "text": "D.3 REPL\nThere are two ways to use Python interpreter. The default way is that Python interpreter reads a file and execute a script from there. The second way is called the intereactive shell, that Python interpreter read the input from user directly, and print the result immediately. The model is like code example: prompt the user for some code, and when they’ve entered it, execute it in the same process. This model is often called a REPL, or Read-Eval-Print-Loop.\nShell, terminal, console have different meanings in their original contexts. However, nowadays, especially when talking about Python intereactive shell, these terminologies are used interchangeably. They are referred to the frontend of the system. In other words, the main task for the Python intereactive shell is to handle the user inputs and communicate with the backend, which is also called a kernel. We won’t distinguish the real differences between these terminologies. The kernel will be discussed in the next section.\nThe standard interactive Python interpreter can be invoked on the command line with the python command. Note that you should make sure that the PATH system enviroment variable is configured, otherwise you have to specifiy the path to the Python execuatable file. To quit the intereactive shell you can type the commands quit()/exit()/Ctrl+Z then Enter.\n\n\n\n\n\n\nNote\n\n\n\nIn the REPL model, the backend (evaluation) is basically handled by the Python interpreter. The frontend is dealing with the user interface. Some typically tasks include the primary/secondary prompt and multi-line commands. The original REPL is very limited.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Some Hard Python concepts</span>"
    ]
  },
  {
    "objectID": "contents/app/concepts.html#ipython",
    "href": "contents/app/concepts.html#ipython",
    "title": "Appendix D — Some Hard Python concepts",
    "section": "D.4 IPython",
    "text": "D.4 IPython\nIPython was initially designed as an Enhanced interactive Python shell. However after many year’s development, the whole IPython project becomes too big to maintain as one single project. Therefore it is now split into many smaller projects. The two most popular projects are IPython and Jupyter. This is called the Big Split.\nThe current IPython play two fundamental roles:\n\nTerminal IPython as the familiar REPL;\nThe IPython kernel (which is defined below) that provides computation and communication with the frontend interfaces, like the notebook.\n\nThe core idea in the design of IPython is to abstract and extend the notion of a traditional REPL environment by decoupling the evaluation into its own process. We call this process a kernel: it receives execution instructions from clients and communicates the results back to them.\nThis decoupling allows us to have several clients connected to the same kernel, and even allows clients and kernels to live on different machines. This two-process model is now used by most of the Jupyter project.\nYou can launch the IPython shell on the command line with the ipython command (which similar to python case requires PATH configuration), and quit the shell with exit/exit()/quit/quit() commands.\nThe reference Python kernel provided by IPython is called ipykernel. With ipykernel you may create and maintain multiple kernels.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Some Hard Python concepts</span>"
    ]
  },
  {
    "objectID": "contents/app/concepts.html#jupyter",
    "href": "contents/app/concepts.html#jupyter",
    "title": "Appendix D — Some Hard Python concepts",
    "section": "D.5 Jupyter",
    "text": "D.5 Jupyter\nJupyter projects contain many subprojects, which includes Jupyter User Interfaces. The Jupyter user interfaces offer a foundation of interactive computing environments where scientific computing, data science, and analytics can be performed using a wide range of programming languages. This includes Jupyter console, Jupyter qtconsole, and Jupyter notebook. Here we mainly focus on Jupyter notebook.\nJupyter notebooks are structured data that represent your code, metadata, content, and outputs. When saved to disk, the notebook uses the extension .ipynb, and uses a JSON structure. After receiving the user input, the notebook communicates with the kernel using JSON messages sent over ZeroMQ sockets. The protocol used between the frontends and the kernel is described in Messaging in Jupyter.\nA kernel process can be connected to more than one frontend simultaneously. In this case, the different frontends will have access to the same variables.\nThis design was intended to allow easy development of different frontends based on the same kernel, but it also made it possible to support new languages in the same frontends, by developing kernels in those languages. The Jupyter Notebook Application has three main kernels: the ipykernel, irkernel and ijulia kernels. Actually the name of Jupyter comes from these three programming languages for data science: Julia, Python and R.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Some Hard Python concepts</span>"
    ]
  },
  {
    "objectID": "contents/app/concepts.html#multi-kernels-setup",
    "href": "contents/app/concepts.html#multi-kernels-setup",
    "title": "Appendix D — Some Hard Python concepts",
    "section": "D.6 Multi-kernels setup",
    "text": "D.6 Multi-kernels setup\nThis section is mainly following the official document.\nTo install one IPython kernel, you may use conda or pip to install ipykernel in the environment. If you want to have multiple IPython kernels for different virtualenvs or conda environments, you will need to specify unique names for the kernelspecs.\n\nActivate the environment you want.\n\nconda activate myenv\n\nInstall the kernel in the environment.\n\nconda install jupyter\npython -m ipykernel install --user --name myenv --display-name \"Python (myenv)\"\n--user means that the kernel is installed in the user’s folder instead of a system folder, and it can be removed. The --name value (in this case it is myenv) is used by Jupyter internally. These commands will overwrite any existing kernel with the same name. --display-name is what you see in the notebook menus.\n\nYou could use the command to find all kernels installed in your system.\n\njupyter kernelspec list\nAvailable kernels are shown, as well as the path to the kernel configuration file kernel.json. The most important configuration is the path to the Python interpreter executatable file.\n\n\nkernel.json\n\n{\n \"argv\": [\n  \"C:\\\\Users\\\\Xinli\\\\anaconda3\\\\envs\\\\myenv\\\\python.exe\",\n  \"-m\",\n  \"ipykernel_launcher\",\n  \"-f\",\n  \"{connection_file}\"\n ],\n \"display_name\": \"Python (3.10)\",\n \"language\": \"python\",\n \"metadata\": {\n  \"debugger\": true\n }\n}\n\n\nThere is a possibility that Jupyter cannot find the kernel you create in a conda environment. In this case you may want to try nb_conda_kernels. This is a tool to enable a Jupyter notebook in one conda environment to access kernels found in other environments. It should be installed in the environment from which you run Jupyter Notebook or JupyterLab. This might be your base conda environment, but it need not be. After you finish installation, you may use jupyter kernelspec list to check whether it works.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Some Hard Python concepts</span>"
    ]
  },
  {
    "objectID": "contents/app/r.html#rstudio",
    "href": "contents/app/r.html#rstudio",
    "title": "Appendix E — R Setup",
    "section": "E.1 RStudio",
    "text": "E.1 RStudio\nFor R, the almost definite choice of IDE is RStudio. You may download and install it from the homepage. The installation and beginning usage is straightforward. RStudio is using the default R console.\nAlthough the best R IDE is RStudio, there are still some people willing to try other options. In the rest part of this section I will briefly describe how to set up R environment using other IDES/platforms.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>R Setup</span>"
    ]
  },
  {
    "objectID": "contents/app/r.html#radian",
    "href": "contents/app/r.html#radian",
    "title": "Appendix E — R Setup",
    "section": "E.2 radian",
    "text": "E.2 radian\nradian is an alternative console for the R program with multiline editing and rich syntax highlight. One would consider radian as a IPython clone for R, though its design is more aligned to Julia.\nradian is a R console. So to install it you should have an installation of R (version 3.4.0 or above). radian is mainly written in Python. Therefore to install it you should have an installation of Python (version 3.6 or above). Then you may use the following command to install radian.\nconda install -c conda-forge radian\nor\npip install -U radian\n\nE.2.1 Use the console\nFirst find the path to the console. If you use conda to install radian, the path is &lt;anaconda path&gt;/Scripts/radian.exe. When you directly run the executable file radian.exe, the console will be activated. You may start to run R code.\n\nYou may use q() to exit radian.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>R Setup</span>"
    ]
  },
  {
    "objectID": "contents/app/r.html#vs-code-configuration",
    "href": "contents/app/r.html#vs-code-configuration",
    "title": "Appendix E — R Setup",
    "section": "E.3 VS Code Configuration",
    "text": "E.3 VS Code Configuration\nThe main reference is the official document.\nIf you would like to use VS Code as your main IDE for R, it is usually recommended to install the following components.\n\nR extension for VS Code by REditorSupport. You may get it through this link, or search for it within VS Code.\nInstall languageserver in R.\n\n\ninstall.packages(\"languageserver\")\n\n\nradian. This is an alternative R console introduced above. Note that to use radian in VS Code you need to set the rterm variable in VS Code setting to be the path of your radian installation.\nhttpgd. This is a R package which is for better plotting in VS Code.\n\n\ninstall.packages(\"httpgd\")\n\nRunning R code is simply sending code to the R terminal. Before running R code, you could create an R terminal via command R: Create R terminal in the Command Palette. If you set radian path, this R terminal will be radian.\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou may adding the following Keyboard Shortcuts to VS Code. These are the same setting used in RStudio which are commonly used. The first two are using alt+- to produce &lt;- and the latter two are using ctrl+shift+m to produce %&gt;%.\n{\n\"key\": \"alt+-\",\n\"command\": \"type\",\n\"when\": \"editorTextFocus && editorLangId =~ /r|rmd|qmd/\",\n\"args\": {\"text\": \" &lt;- \"}\n},\n{\n\"key\": \"alt+-\",\n\"command\": \"workbench.action.terminal.sendSequence\",\n\"when\": \"terminalFocus\",\n\"args\": {\"text\": \" &lt;- \"}\n},\n{\n\"key\": \"ctrl+shift+m\",\n\"command\": \"type\",\n\"when\": \"editorTextFocus && editorLangId =~ /r|rmd|quarto/\",\n\"args\": {\"text\": \" %&gt;% \"}\n},\n{\n\"key\": \"ctrl+shift+m\",\n\"command\": \"workbench.action.terminal.sendSequence\",\n\"when\": \"terminalFocus\",\n\"args\": {\"text\": \" %&gt;% \"}\n},",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>R Setup</span>"
    ]
  },
  {
    "objectID": "contents/app/r.html#cloud-ide-options",
    "href": "contents/app/r.html#cloud-ide-options",
    "title": "Appendix E — R Setup",
    "section": "E.4 Cloud IDE options",
    "text": "E.4 Cloud IDE options\nThere are tons of online IDEs that supports R. The following two are the biggest names.\n\nE.4.1 Posit Cloud (formally RStudio Cloud)\nYou may directly go to the homepage to use RStudio from cloud. If you don’t use it a lot it should be free.\n\n\nE.4.2 Google Colab\nYou may use R in Google Colab. Note that by default R is disabled. You have to use a specific version of Google Colab through colab.to/r. After you get into the system, you may go to Edit-&gt;Notebook settings to change Runtime type to be R.\nThe rest is similar to Jupyter notebook, while the codes are now R codes.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>R Setup</span>"
    ]
  },
  {
    "objectID": "contents/app/re.html",
    "href": "contents/app/re.html",
    "title": "Appendix F — Regular expression",
    "section": "",
    "text": "Regular expressions provide a flexible way to search or match string patterns in text. A single expression, commonly called a regex, is a string formed according to the regular expression language. Python’s built-in re module is responsible for applying regular expressions to strings.\nFor details of the regular expression language in Python, please read the official documents from here. There are also many great websites for learning regex. This is one example.\nWe will briefly mentioned a few rules here.\n\n.: matches any character except a newline.\n\\d: matches any digit. It is the same as [0-9].\n\\D: matches any characters that are NOT \\d. It is the same as [^0-9].\n\\w: matches any alphabatic or numeric character. It is the same as [a-zA-Z0-9_].\n\\W: matches any characters that are NOT \\w.\n\\s: matches any whitespaces. It is the same as [\\t\\n\\r\\f\\v].\n\\S: mathces any characters that are not \\s.\n\\A: matches the start of the string.\n\\Z: matches the end of the string.\n*: Causes the resulting RE to match 0 or more repetitions of the preceding RE, as many repetitions as are possible.\n+: Causes the resulting RE to match 1 or more repetitions of the preceding RE, as many repetitions as are possible.\n?: Causes the resulting RE to match 0 or 1 repetitions of the preceding RE.\n*?, +?, ??: The *, +, and ? qualifiers are all greedy; they match as much text as possible. Adding ? after the qualifier makes it perform the match in non-greedy or minimal fashion; as few characters as possible will be matched.\n{m}: Specifies that exactly m copies of the previous RE should be matched.\n{m,n}: Causes the resulting RE to match from m to n repetitions of the preceding RE, attempting to match as many repetitions as possible.\n{m,n}?: Causes the resulting RE to match from m to n repetitions of the preceding RE, attempting to match as few repetitions as possible.\n[]: Used to indicate a set of characters.\n(): set groups.\n\n\n\n\n\n\n\nNote\n\n\n\nTo search multiple characters simutanously, you may use []. For example, [abc] means either a or b or c. However, [] doesn’t recognize special characters, so [\\s|\\w] means either \\ or s or \\ or w, instead of the pattern \\s or \\w.\nTo search such a pattern, you may use (|). For example, (\\s|\\w) means either \\s or \\w satisfies the pattern.\n\n\n\nExample F.1  \n\nimport re\ntext = \"foo bar\\t baz \\tqux\"\npattern = '\\s+'\nregex = re.compile(pattern)\nregex.split(text)\n\n['foo', 'bar', 'baz', 'qux']\n\n\n\n\n.match()\n.search()\n.findall()\n.split()\n.sub()\n\nWe can use () to specify groups, and use .groups() to get access to the results.\n\nExample F.2  \n\nimport re\npattern = r'([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\.([A-Z]{2,4})'\nregex = re.compile(pattern, flags=re.IGNORECASE)\nm = regex.match('wesm@bright.net')\nm.groups()\n\n('wesm', 'bright', 'net')\n\n\n\nTo use regex to DataFrame and Series, you may directly apply .match, .findall, .replace after .str, with the regex pattern as one of the arguments.\n.extract is a method that is not from re. It is used to extract the matched groups and make them as a DataFrame.\n\nExample F.3  \n\nimport pandas as pd\nimport numpy as np\nmnames = ['movie_id', 'title', 'genres']\nmovies = pd.read_table('assests/datasets/movies.dat', sep='::',\n                       header=None, names=mnames, engine=\"python\",\n                       encoding='ISO-8859-1')\n\npattern = r'([a-zA-Z0-9_\\s,.?:;\\']+)\\((\\d{4})\\)'\nmovies = movies.join(movies.title.str.extract(pattern).rename(columns={0: 'movie title', 1: 'year'}))\n\n\n\n\nExercise F.1 (Regular expressions) Please use regular expressions to finish the following tasks.\n\nMatch a string that has an a followed by zero or more b’s.\nMatch a string that has an a followed by one or more b’s.\nMatch a string that has an a followed by zero or one b.\nMatch a string that has an a followed by three b’s.\n\n\n\nExercise F.2 (More regex) Find all words starting with a or e in a given string:\n\ntext = \"The following example creates an ArrayList with a capacity of 50 elements. Four elements are then added to the ArrayList and the ArrayList is trimmed accordingly.\"\n\n\n\nExercise F.3 (More regex) Write a Python code to extract year, month and date from a url1:\n\nurl1= \"https://www.washingtonpost.com/news/football-insider/wp/2016/09/02/odell-beckhams-fame-rests-on-one-stupid-little-ball-josh-norman-tells-author/\"\n\n\n\nExercise F.4 (More regex) Please use regex to parse the following str to create a dictionary.\n\ntext = r'''\n{\n    name: Firstname Lastname;\n    age: 100;\n    salary: 10000 \n}\n'''\n\n\n\nExercise F.5 Consider the following DataFrame.\n\ndata = [['Evert van Dijk', 'Carmine-pink, salmon-pink streaks, stripes, flecks.  Warm pink, clear carmine pink, rose pink shaded salmon.  Mild fragrance.  Large, very double, in small clusters, high-centered bloom form.  Blooms in flushes throughout the season.'],\n        ['Every Good Gift', 'Red.  Flowers velvety red.  Moderate fragrance.  Average diameter 4\".  Medium-large, full (26-40 petals), borne mostly solitary bloom form.  Blooms in flushes throughout the season.'], \n        ['Evghenya', 'Orange-pink.  75 petals.  Large, very double bloom form.  Blooms in flushes throughout the season.'], \n        ['Evita', 'White or white blend.  None to mild fragrance.  35 petals.  Large, full (26-40 petals), high-centered bloom form.  Blooms in flushes throughout the season.'],\n        ['Evrathin', 'Light pink. [Deep pink.]  Outer petals white. Expand rarely.  Mild fragrance.  35 to 40 petals.  Average diameter 2.5\".  Medium, double (17-25 petals), full (26-40 petals), cluster-flowered, in small clusters bloom form.  Prolific, once-blooming spring or summer.  Glandular sepals, leafy sepals, long sepals buds.'],\n        ['Evita 2', 'White, blush shading.  Mild, wild rose fragrance.  20 to 25 petals.  Average diameter 1.25\".  Small, very double, cluster-flowered bloom form.  Blooms in flushes throughout the season.']]\n  \ndf = pd.DataFrame(data, columns = ['NAME', 'BLOOM']) \ndf \n\n\n\n\n\n\n\n\nNAME\nBLOOM\n\n\n\n\n0\nEvert van Dijk\nCarmine-pink, salmon-pink streaks, stripes, fl...\n\n\n1\nEvery Good Gift\nRed. Flowers velvety red. Moderate fragrance...\n\n\n2\nEvghenya\nOrange-pink. 75 petals. Large, very double b...\n\n\n3\nEvita\nWhite or white blend. None to mild fragrance....\n\n\n4\nEvrathin\nLight pink. [Deep pink.] Outer petals white. ...\n\n\n5\nEvita 2\nWhite, blush shading. Mild, wild rose fragran...\n\n\n\n\n\n\n\nPlease use regex methods to find all the () in each columns.\n\n\nExercise F.6 From ser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money']), find the words that contain at least 2 vowels.\n\n\nExercise F.7 Please download the given file with sample emails, and use the following code to load the file and save it to a string content.\n\nwith open('assests/datasets/test_emails.txt', 'r') as f:\n    content = f.read()\n\nPlease use regex to play with content.\n\nGet all valid email address in content, from both the header part or the body part.\nThere are two emails in content. Please get the sender’s email and the receiver’s email from content.\nPlease get the sender’s name.\nPlease get the subject of each email.\n\n\n\nExercise F.8 Extract the valid emails from the series emails. The regex pattern for valid emails is provided as reference.\n\nimport pandas as pd\nemails = pd.Series(['buying books at amazom.com',\n                    'rameses@egypt.com',\n                    'matt@t.co',\n                    'narendra@modi.com'])\npattern = '[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Regular expression</span>"
    ]
  }
]